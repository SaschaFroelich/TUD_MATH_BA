Seien eine reguläre Matrix $A \in \R^{n \times n}$ und $b \in Rn$ gegeben. In diesem Kapitel werden iterative Verfahren zur Lösung des linearen Gleichungssystems
\begin{align}
Ax = b\label{eq_2_2_1}
\end{align}
betrachtet.
%TODO fix counter, this equation should be the 1 and the one in the following section, 2!
\section{Fixpunktiteration}

Grundidee dieser Verfahren ist die geeignete Umformulierung des System $Ax = b$ als Fixpunktaufgabe und die Anwendung des gewöhnlichen Iterationsverfahrens. Die hier betrachtete (zu \eqref{eq_2_2_1} äquivalente) Fixpunktaufgabe lautet
\begin{align}
	x = x - B^{-1}(Ax - b),\notag
\end{align}
wobei $B \in \R^{n \times n}$ eine noch zu wählende reguläre Matrix ist. Bei Wahl eines Startpunktes $x^0 \in \Rn$ ergibt sich das gewöhnliche Iterationsverfahren damit zu
\begin{align}
	x^{k+1} := x^{k} - B^{-1}(A x^k -b) = (I - B^{-1}A)x^{k} + B^{-1}b, \qquad k = 0,1,2,\dots \label{eq_2_2_2} %TODO add underbraces for M = I - B^{-1}A and c = B^{-1}b
\end{align}
Mit den Bezeichnung $M := I - B^{-1}A$ und $c:= B^{-1}b$ untersuchen wir deshalb die Iterationsverschrift
\begin{align}
	x^{k+1} := Mx^k + c. \label{eq_2_2_3}
\end{align}
Die zugehörige Fixpunktabbildung $\Phi: \Rn \to \Rn$ ist damit offenbar gegeben durch
\begin{align}
	\Phi(x) := Mx + c.\notag
\end{align}
\begin{proposition}
	\proplbl{2_2_1}
	Es sei $B \in \Rnn$ regulär und mit $M:= I - B^{-1}A$ gelte
	\begin{align}
		\lambda := \norm{M}_{\ast} < 1 \label{eq_2_1_4}
	\end{align}
	wobei $\norm{\cdot}_{\ast}$ die einer Vektornorm $\norm{\cdot}$ zugeordnete Matrixnorm bezeichnet. Dann gilt:
	\begin{enumerate} %TODO add alph
		\item Die für eine beliebiges $x^0 \in \Rn$ durch \eqref{eq_2_2_3} erzeugte Folge $\set{x^k}$ konvergiert gegen die eindeutige Lösung $x*$ des linearen Gleichungssystems \eqref{eq_2_2_1}.
		\item Die Abschätzungen \eqref{eq_1_2_2} - \eqref{eq_1_2_4} sind für alle $k \in \N$ erfüllt.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Direkte Folgerung aus dem Banachschen Fixpunktsatz (\propref{1_1_1})
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 3rd lecture %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{remark}
	In \propref{2_2_1}a) kann die Folgerung \eqref{eq_2_1_4} durch die Bedingung
	\begin{align}
	\rho(M) < 1\label{eq_2_1_5}
	\end{align}
	ersetzt werden. Da
	\begin{align}
		\rho(C) \le \norm{C}_{\ast} \quad \text{ für alle } C \in \Rnn \notag
	\end{align}
	für jede beliebige zugeordnete Matrixnorm $\norm{\cdot}_{\ast}$ gilt (vgl. Übungsaufgabe), ist \eqref{eq_2_1_5} eine schwächere Forderung als \eqref{eq_2_1_4}. Andererseits gibt es zu jedem Paar $(C,\epsilon) \in \Rnn \times (0,\infty)$ eine zugeordnete Matrixnorm $\norm{\cdot}_{(C,\epsilon)}$, so dass
	\begin{align}
		\norm{C}_{(C,\epsilon)} \le \rho(C) + \epsilon. \notag
	\end{align}
	Dabei ist $\rho(C)$ der \begriff{Spektralradius} der Matrix $C \in \Rnn$, d.h.
	\begin{align}
		\rho(C) := \max_{i = 1,\dots,n}\abs{\lambda_i}, \notag
	\end{align}
	wobei $\lambda_1,\dots,\lambda_n \in \C$ die Eigenwerte der Matrix $C \in \Rnn$ bezeichnen. Man kann weiter zeigen, dass \eqref{eq_2_1_5} auch notwendig dafür ist, dass die durch \eqref{eq_2_2_2} erzeugte Folge $\set{x^k}$ für jedes $x^0$ gegen $x*$ konvergiert.
\end{remark}

Um eine Matrix $B$ zu finden, so dass einerseits der Aufwand pro Iteration \eqref{eq_2_2_2} niedrig und andererseits die Bedingung \eqref{eq_2_1_4} bzw. \eqref{eq_2_1_5} erfüllt ist, betrachten wir die folgende Zerlegung
\begin{align}
	A = L + D + R \notag
\end{align}

der Matrix $A$, wobei $D:= \diag(a_{11}, \dots, a_{nn})$ die aus den Diagonalelementen von $A$ bestehende Diagonalmatrix bezeichnet und $L$ bzw. $R$ eine untere bzw. obere Dreiecksmatrix ist mit

\begin{align}
	L = 
	\begin{pmatrix}
		0      &        &        &           & \\
		a_{21} & 0      &        &           & \\
		a_{31} & a_{32} & 0      &           & \\
		\vdots &        & \ddots & \ddots    & \\
		a_{n1} & \cdots & \cdots & a_{n,n-1} & 0
	\end{pmatrix}
	 \bzw R = 
	 \begin{pmatrix}
	 0      & a_{12} & a_{13} & \dots     & a_{1n}\\
	        & 0      & a_{23} & \dots     & a_{2n}\\
	        &        & \ddots & \ddots    & \vdots\\
	        &        &        & 0         & a_{n-1,n}\\
	        &        &        & a_{n,n-1} & 0
	 \end{pmatrix}.\notag
\end{align}

\subsection{Das \person{Jacobi}-Verfahren}
Wir setzen hier voraus, dass $D$ regulär ist und wählen
\begin{align}
	B:= D \label{eq_1_2_6}
\end{align}
Damit ergibt sich die Iterationsvorschrift
\begin{align}
	x^{k+1} = x^k - D^{-1}(Ax^k - b) = -D^{-1}(L+R)x^k+D^{-1}b. \label{eq_1_2_7}
\end{align}
In \eqref{eq_2_2_3} ist entsprechend
\begin{align}
	M:= M_J := -D^{-1}(L+R) \text{ und } c:= c_J := D^{-1}b\notag 
\end{align}
zu wählen. Dieses Verfahren heißt \begriff{Gesamtschrittverfahren} oder \begriff{Jacobi-Verfahren}. Der Aufwand pro Schritt (Brechnung von $x^{k+1}$ aus $x^k$) beträgt $\Landau(n^2)$ bei voll besetzter Matrix $A$ und mindestens $\Landau(n)$, falls $A$ schwach besetzt ist.

\begin{proposition}
	Die Matrix $A$ sei streng diagonaldominant (vgl. Definition 3.1 der Vorlesung ENM). Dann ist die Matrix $B$ aus \eqref{eq_1_2_6} regulär und es gilt
	\begin{align}
	\norm{M_J}_{\infty} \le \lambda_{SD} := \max_{i = 1,\dots,n} \frac{1}{\abs{a_{ii}}} \sum_{\substack{j =1 \\ j\neq i}^{n}} \abs{a_{ij}} < 1.
	\end{align}
\end{proposition}

\begin{proof}
	Die Regularität von $B$ ergibt sich sofort aus der strengen Diagonaldominanz von $A$. Nutzt man die Definition der Zeilensummennorm $\norm{\cdot}_{\infty}$ erhält man sofort
	\begin{align}
		\norm{M_J}_{\infty} = \norm{D^{-1}(L+R)}_{\infty} =\max_{i = 1,\dots,n} \frac{1}{\abs{a_{ii}}} \sum_{\substack{j =1 \\ j\neq i}^{n}} \abs{a_{ij}}  = \lambda_{SD}.
	\end{align}
	Die vorrausgesetzte strenge Diagonaldominanz von $A$ sichert $\lambda_{SD} < 1$.
\end{proof}

\subsection{Das \person{Gauss-Seidel}-Verfahren}
Wir setzen hier voraus, dass $L + D$ regulär ist und wählen

\begin{align}
	B := L + D \label{1_2_8}
\end{align}

Damit ergibt sich die Iterationsvorschrift

\begin{align}
	x^{k+1} = x^k - (L+D)^{-1}(Ax^k - b) = - (L+D)^{-1}R x^k + (L+D)^{-1}b. \label{1_2_9}.
\end{align}

In \eqref{eq_2_2_3} ist entsprechend

\begin{align}
	M:= M{GS} := - (L+D)^{-1}R \text{ und } c:= c_{GS} := (L+D)^{-1}b \notag
\end{align}

zu wählen. Dieses Verfahren heißt \begriff{Einzelschrittverfahren} oder \begriff{Gauß-Seidel-Verfahren}. Der Aufwand pro Schritt beträgt im ungünstigsten Fall $\Landau(n^2)$. Verbesserungen sind möglich, wenn eine Sparse-Struktur in $A$ ausgenutzt werden kann.

\begin{proposition}
	Die Matrix $A$ sei streng diagonaldominant ($\nearrow$ Definition 3.1 der Vorlesung ENM). Dann ist die Matrix $B$ aus \eqref{1_2_8} regulär und es gilt
	\begin{align}
		\norm{M_{GS}}_{\infty} \le \lambda_{SD} <1.
	\end{align}
\end{proposition}

\begin{proof}
	Die Regularität von $B$ folgt sofort aus der strengen Diagonaldominanz von $A$. Weiter ergibt sich
	\begin{align}
		\norm{M_{GS}}_{\infty} = \norm{(L+D)^{-1}R}_{\infty} = \sup_{\norm{y}_{\infty}=1} \norm{(L+D)^{-1}Ry}_{\infty}. \notag
	\end{align}
	Um für einen festen Vektor $y$ mit $\norm{y}_{\infty} = 1$ eine Abschätzung für die rechte Seite zu erhalten, setzen wir $z:= (L+D)^{-1}Ry$. Damit gilt
	\begin{align}
		(D+L)z = Ry \label{1_2_10}
	\end{align}
	und
	\begin{align}
	z_1 = \frac{1}{a_{11}} \sum_{j=1}^{n} a_{1j}y_j. \notag
	\end{align}
	Daraus folgt (da $\lambda_{SD} < 1$ wegen der strengen Diagonaldominanz von $A$)
	\begin{align}
		\abs{z_1} 
		\le \frac{1}{\abs{a_{11}}} \sum_{j=2}^{n} \abs{a_{1j}}\abs{y_j} 
		\le \sum_{j=2}^{n} \abs{a_{1j}} \le \lambda_{SD} < 1.\notag
	\end{align}
	Nehmen wir nun an, dass
	\begin{align}
		\abs{z_1} \le \text{ für } i = 1, \dots, k-1, \notag
	\end{align}
	für ein $k \in \set{2,\dots,n}$ gilt. Dann folgt wegen \eqref{1_2_10} und $\norm{y}_{\infty} = 1$
	\begin{align}
		\abs{z_k} = \frac{1}{\abs{a_{kk}}} \abs{-\sum_{i=1}^{k-1} a_{ki}z_i + \sum_{i=k+1}^{n} a_{ki}y_i} 
		\le \frac{1}{\abs{a{kk}}} \brackets{\sum_{i=1}^{k-1} \abs{a_{ki}} + \sum_{i=k+1}^{n} \abs{a_{ki}}} \le \lambda_{SD}. \notag
	\end{align}
	Somit hat man induktiv $\abs{z_k} \le \lambda_{SD}$ für $k = 1, \dots, n$ und damit
	\begin{align}
		\norm{(L+D)^{-1}Ry}_{\infty} = \norm{z}_{\infty} \le \lambda_{SD} \notag
	\end{align}
	für beliebige $y$ mit $\norm{y}_{\infty} = 1$.
\end{proof}

\subsection{SOR-Verfahren}

