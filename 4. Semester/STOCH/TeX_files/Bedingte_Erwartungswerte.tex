\section{Bedingte Erwartungswerte}
\begin{proposition}
	\propref{6_2_8}
	$(\O, \F, \P)$ Wahrscheinlichkeitsraum und $X\colon (\O,\F) \to (\R, \borel(\R))$ und $Y\colon (\O,\F) \to (\O_Y, \F_Y)$ Zufallsvariable, so dass $\E[X]$ existiert ($X \in \Ln{1}(\P) \oder X \ge 0$). Dann existiert eine messbare Funktion $g\colon (\O_Y, \F_Y) \to (\bar{\R}, \borel(\bar{\R}))$, so dass gilt
	\begin{align*}
		\E[X\indi_{y\in B}]=\int_{y \in B} X \d \P = \int_B g(y) \P_Y(\d y) \quad \forall B \in \F_Y
	\end{align*}
	Dieses $g$ ist $\P_Y$-f.s. (fast sicher) eindeutig bestimmt. Wir nennen $\E[X \mid Y = y] = g(y)$ \begriff{bedingten Erwartungswert}/\begriff{bedingte Erwartung} von $X$ gegeben $Y=y$.
\end{proposition}
\begin{proof}\
	\begin{enumerate}
		\item Sei $X \ge 0$. Definiere ein Maß $\mu$ auf $\F_Y$ durch
		\[
			\mu(B) = \E[X \indi_{y\in B}]
		\]
		dann ist $\mu \ll\P_Y$. Aus dem Satz von \person{Radon}-\person{Nikodym} (\propref{6_1_1:Radon}) folgt die Existenz einer $\P_Y$-f.s. bestimmten Dichte $g$.
		\item Sei $X \in \Ln{1}(\P)$. Es gilt $\E[X^-] < \infty \oder \E[X^+] < \infty$. Sei oBdA $\E[X^-] < \infty$, dann folgt auch $\E[X^-\mid Y=y] < \infty\;\P_Y$ f.s.. Setze
		\begin{align*}
			\E[X \mid Y = y] := \begin{cases}
			\E[X^+ \mid Y = y] - \E[X^-\mid Y=y] &\quad \E[X^- \mid Y =y] < \infty\\
			0 &\quad \sonst.
			\end{cases}
		\end{align*}
		Dann folgt
		\begin{align*}
			\E[X\indi_{y\in B}] &=\E[X^+ \indi_{y\in B}] - \E[X^-\indi_{y\in B}]\\
			&= \int_B \E[X^+ \mid Y=y]\P_Y(\d y) - \int_B \E[X^- \mid Y=y] \P_Y(\d y)\\
			&= \int_B \E[X \mid Y=y]\P_Y(\d y) \quad \forall B \in \F_Y.
		\end{align*} 
		Sind $g_1,g_2$ zwei Versionen der bedingten Erwartung, dann gilt wegen $\E[X^-]<\infty$ auch $\int_{\O_Y} g_1^- (y)\P_Y(\d y) < \infty$ für $i=1,2$ und dann folgt
		\begin{align*}
		\int_B g^+_1(y)\P_Y(\d y) &= \int_B g_1^-(y)\P_Y(\d y)\\
		&= \int_B g_1(y) \P_Y(\d y)\\
		&= \int_B g_2 (y)\P_Y (\d y)\\
		&= \int_B g_2^+ (y) \P_Y(\d y) - \int_B g_2^-(y) \P_Y(\d y)\\
		&\implies \int_B (g_1^+(y) + g_2^+(y)) \P_Y(\d y) \\
		&= \int_B (g_2^+ (y) + g_1^- (y))\P_Y(\d y) \quad \forall B \in \F_Y
		\intertext{also}
		g_1^+ + g_2^+ = g_2^+ + g_1^- \P_Y \text{-f.s.}
		\intertext{impliziert}
		g_1^+ - g_1^- = g_1 = g_2 = g_2^+ - g_2^- \P_Y \text{-fast-sicher.}
		\end{align*}
	\end{enumerate}
\end{proof}
\begin{*remark}
	Bedingte Erwartung und bedingte Verteilung hängen zusammen:
	\begin{itemize}
		\item Sind $X,Y$ so dass $\E X$ existiert und eine reguläre bedingte Verteilung\\ $\P_{X \mid Y = y}(B) = \P(X \in B \mid Y =y)$ existiert, dann folgt
		\[
			\E[X \mid Y=y] = \int_{\R} x \P_{X \mid Y = y} (\d x).
		\]
		Für Treppenfunktionen $X = \sum_{i=1}^n \alpha_i \indi_{A_i},\alpha_i > 0, A_i$ disjunkt, folgt dies aus
		\begin{align*}
			\E[X\indi_{y\in B}] &= \sum_{i=1}^n \alpha_i \E[\indi_{A_i} \indi_{y\in B}]\\
			&= \sum_{i=1}^n \alpha_i \P(X= \alpha_i, y \in B)\\
			&= \sum \alpha_i \int_B \P(X=\alpha_i \mid Y=y)\P_Y(\d y)\\
			&= \int_B \sum \alpha_i \P(X = \alpha_i \mid Y=y)\P_Y(\d y)\\
			&= \int_B \int_{\R} x \P_{X \mid Y = y} (\d x)\P(\d y)
		\end{align*}
		Für allgemeines $X$ folgt die Aussage mittels maßtheoretischer Induktion.
	\end{itemize}
\end{*remark}
Durch Einsetzen von $X=\indi_{A}$ in Gleichung in \propref{6_1_8} folgt
\begin{align*}
	\int_B \E[\indi_{A}\mid Y=y]\P_Y(\d y) &= \int_{Y \in B} \indi_{A} \d \P\\
	&= \E[\indi_{A} \indi_{y\in B}]\\
	&= \P(A \cap \set{Y\in B})
\end{align*}
und durch Vergleich mit Definition der bedingten Verteilung (\propref{6_1_4})
\begin{align*}
	\E[\indi_{A} \mid Y=y] = \P(A \mid Y=y) \quad \P\text{-f.s.}.
\end{align*}
\begin{example}
	Betrachte \propref{6_1_7}, d.h. gegeben seien zwei Zufallsvariablen $X,Y$ mit Dichte
	\begin{align*}
		f(x,y) = x e^{-x(y+1)} \quad x,y > 0
	\end{align*}
	Die Erwartungswerte von $X \und Y$ folgen aus den Randdichten:
	\begin{align*}
		\E[X] = 1\quad \text{ da } X \sim \EXP(1)
		\intertext{und}
		\E[Y] &= \int_0^{\infty} y f_y (y) \d y = \int_0^{\infty} y \frac{1}{(y+1)^2}\\
		&= \int_0^{\infty} (z-1) \frac{1}{z^2}\d z\\
		&= \int_1^{\infty}\frac{1}{z} \d z - \int_1^{\infty} \frac{1}{z^2}\d z = \infty
	\end{align*}
	Der bedingte Erwartungswert von $X$ gegeben $Y = y_0 > 0$ ist
	\begin{align*}
		\E[X \mid Y=y_0] &= \int_0^{\infty} x f_{X\mid Y=y_0}(x) \d x\\
		&= \int_0^{\infty} x^2 (y_0 +1)^2 e^{-x(y_0+1)} \d x\\ 
		&= \frac{2}{y_0 + 1}
	\end{align*}
	da $X \mid Y = y_0 \sim \Gam(y_0 +1,2)$.
\end{example}
\subsection*{Der bedingte Erwartungswert als Zufallsvariable}
\begin{enumerate}[label=]
	\item Bisher: Bedingung der Form: $Y=y$
	$\implies$ Sowohl bedingte Verteilung
	\begin{align*}
		\mu_A: (\O_Y,\F_Y) \to ([0,1],\borel([0,1]))
		\intertext{als auch bedingte Erwartung}
		g: (\O_Y, \F_Y) \to (\bar{\R}, \borel(\bar{\R}))
	\end{align*}
	sind \emph{messbar}.
\end{enumerate}
Wir können also auch die Zufallsvariablen
\begin{align*}
	\mu_A (Y) &=: \P(X \in A \mid Y)\\
	g(Y) &=: \E[X \mid Y] 
\end{align*}
betrachten.
\begin{definition}[bedingte Erwartung und Wahrscheinlichkeit]
	$(\O, \F, \P)$ Wahrscheinlichkeitsraum, $X: (\O, \F) \to (\R, \borel(\R))$ und $Y: (\O, \F) \to (\O_Y, \F_Y)$ Zufallsvariablen, so dass $\E[X]$ existiert. Die \begriff{bedingte Erwartung von $X$ gegeben $Y$} ist die Zufallsvariable $g(Y)$ mit
	\begin{align*}
		\int_{\set{y \in B}} X(\omega)\P(\d \omega) &= \int_{\set{Y \in B}} g(Y)(\omega) \P(\d \omega)\\
		&= \int_B g(y)\P_Y(\d y) \quad \forall B \in \F_Y.
	\end{align*}
	Schreibe $g(Y) =: \E[Y \mid Y] =: \E[X \mid \sigma(Y)]$.
	\begin{align*}
		\P(A \mid \sigma(Y)) := \P(A \mid Y) = \E[\indi_{A} \mid Y]
	\end{align*}
	ist die \begriff{bedingte Wahrscheinlichkeit von $A$ gegeben $Y$}.
\end{definition}
\subsection*{Bedingen auf beliebige $\sigma$-Algebren}
\begin{definition}[]
	$(\O, \F, \P)$ Wahrscheinlichkeitsraum, $X: (\O, \F) \to (\R, \borel(\R))$ Zufallsvariablen, so dass $\E[X]$ existiert und $\G \subset \F$ $\sigma$-Algebra. Die \begriff{bedingte Erwartung von $X$ gegeben $\G$} ist die $\G$-messbare Zufallsvariable $X_{\G}$ mit
	\begin{align*}
		\int_G X(\omega)\P(\d \omega) = \int_G X_{\G}(\omega)\P(\d \omega) \quad \forall G \in \G \label{eq:6_2_11}\tag{$\star$}
	\end{align*}
	Schreibe: $X_{\G} = \E[X \mid \G]$. $\P(A \mid \G) := \E[\indi_A \mid \G]$ heißt \begriff{bedingte Wahrscheinlichkeit von $A$ gegeben $\G$}.
\end{definition}
\begin{*remark}
	\begin{itemize}
		\item Existenz und Eindeutigkeit (bis auf $\G$-Nullmengen) der Bedingten Erwartung folgen wieder aus \person{Radon}-\person{Nikodym} (\propref{6_1_1:Radon}).
		\item Die Gleichung\eqref{eq:6_2_11} können wir umschreiben:
		\begin{align*}
			\E[\E[X \mid \G]\indi_G] = \E[X \indi_G] \quad \forall G \in \G
		\end{align*}
		\item $\E[X \mid \G]$ ist nur bis auf $\G$-Nullmengen bestimmt.  Spreche daher von ``Versionen'' der bedingten Erwartung.
	\end{itemize}
\end{*remark}
Die bedingte Erwartung übernimmt Eigenschaften der Erwartung:
\begin{lemma}[Rechenregeln bedingter Erwartungswert 1]
	\proplbl{6_2_12}
	$(\O,\F, \P)$ Wahrscheinlichkeitsraum, $\G \subseteq \F$ $\sigma$-Algebra, $X,Y: (\O, \F) \to (\R, \borel(\R))$ Zufallsvariablen, so dass $\E[Y],\E[Y]$ existieren.
	\begin{enumerate}
		\item Positivität:
		\[
			X \ge 0 \quad \P\text{-f.s. } \implies \E[X\mid \G] \ge 0\quad \P\text{-f.s.}
		\]
		\item Konservativität:
		\[
			X \equiv c \in \R \implies \E[X \mid \G] = c \quad \P\text{-f.s.}
		\]
		\item Linearität: Für $a,b \in \R$ und $X,Y \in \Ln{1}(\P)$
		\[
			\E[aX + bY \mid \G] = a\E[X \mid \G] + b \E[Y \mid \G] \quad \P\text{-f.s.}
		\]
		\item Monotonie:
		\[
			X \subseteq Y \implies \E[X \mid \G] \ge \E[Y \mid \G] \quad \P\text{-f.s.}
		\]
	\end{enumerate}
\end{lemma}
\begin{proof}
	\begin{enumerate}
		\item Folgt aus \propref{eq:6_2_11}.
		\item Betrachte
			\begin{align*}
				\int_G X(\omega) \P(\d \omega) = \int_G x \P(\d \omega)
			\end{align*}
		$\implies c$ ist Version der bedingten Erwartung.
		\item Betrachte
			\begin{align*}
				\int_G (aX + bY) \d \P 
				&= a \int_G X\d \P + b\int_G Y \P \text{ nutze Linearität des Integrals}\\
				\overset{\eqref{eq:6_2_11}}&{=} 
a \int_G \E[X \mid \G]\d \P + b \int_G \E[Y \mid \G]\d \P\\
				&= \int_G (a\E[X \mid \G] + b\E[Y \mid \G])\d \P
			\end{align*}
			$\implies a \E[X \mid \G] + b\E[Y \mid \G]$ ist Version von $\E[aX + bY \mid \G]$
		\item $X \le Y \implies Y - X \ge 0$ und mit 1) und 3) $\implies$ Behauptung. % TODO refs
	\end{enumerate}
\end{proof}
\begin{proposition}[Konvergenzsätze der bedingten Erwartung]
	$(\O,\F, \P)$ Wahrscheinlichkeitsraum $\G \subseteq \F$ $\sigma$-Algebra, $X,X_1,X_2, \dots : (\O, \F) \to (\R, \borel(\R))$ Zufallsvariablen
	\begin{enumerate}
		\item \person{Beppo}-\person{Levi} bedingt:
		\begin{align*}
			X_n \ge 0 \quad X_n \in \Ln{1}(\P) \quad X_n \uparrow X \und \sup_{n \in \N} \E[X_n] < \infty \quad \P\text{-f.s.} 
		\end{align*}
		Dann gilt: $\E[X \mid \G] = \sup_{n \in \N} \E[X_n \mid \G] = \lim_{n \to \infty} \E[X_n \mid \G] \quad \P\text{-f.s.}$
		\item \person{Fatou} bedingt $X_n \ge 0, X_n \in \Ln{1}(\P)$ und $\liminf_{n \to \infty} \E[X_n] < \infty$\\
		Dann gilt
		\begin{align*}
			\E\sqbrackets{\liminf_{n \to \infty} X_n \mid \G} \le \liminf_{n \to \infty} \E[X_n \mid \G] \quad \P\text{-f.s.}
		\end{align*}
		\item Dominierte-KOnvergenz bedingt: $\lim_{n \to \infty} X_n = X \quad \P\text{-f.s.}$ und 
		$\abs{X_n} \le Y \quad \P\text{-f.s.} \mit Y \in \Ln{1}(\P)$, dann gilt $X \in \Ln{1}(\P)$ und
		\begin{align*}
			\lim_{n \to \infty} \E[X_n \mid \G] = \E[X \mid \G] \quad \P\text{-f.s.}
		\end{align*}
	\end{enumerate}
\end{proposition}
\begin{proof}
	\begin{enumerate}
		\item Aus \person{Beppo}-\person{Levi} (klassisch) folgt:
		\begin{align*}
			\E[X] = \sup_{n \in \N} \E[X_n] < \infty
		\end{align*}
		also $X \in \Ln{1}(\P)$ und damit existiert $\E[X \mid \G]$.
		$\E[X_n \mid \G]$ ist monoton wachsend (\propref{6_2_12}) Also
		\begin{align*}
			\int_G \sup_{n \in \N} \E[X_n \mid \G] \d \P &= \sup_{n \in \N} \int_G \E[X_n \mid \G]\d \P\\
			\overset{\text{Def.}}&{=} \sup_{n \in \N} \int_G X_n \d \P \\
			&= \int_G \sup_{n \in \N} X_n \d \P
		\end{align*}
	\end{enumerate}
\end{proof}