\section{Bedingte Erwartungswerte}
\begin{proposition}
	$(\O, \F, \P)$ Wahrscheinlichkeitsraum und $X\colon (\O,\F) \to (\R, \borel(\R))$ und $Y\colon (\O,\F) \to (\O_Y, \F_Y)$ Zufallsvariable, so dass $\E[X]$ existiert ($X \in \Ln{1}(\P) \oder X \ge 0$). Dann existiert eine messbare Funktion $g\colon (\O_Y, \F_Y) \to (\bar{\R}, \borel(\bar{\R}))$, so dass gilt
	\begin{align*}
		\E[X\indi_{y\in B}]=\int_{y \in B} X \d \P = \int_B g(y) \P_Y(\d y) \quad \forall B \in \F_Y
	\end{align*}
	Dieses $g$ ist $\P_Y$-f.s. (fast sicher) eindeutig bestimmt. Wir nennen $\E[X \mid Y = y] = g(y)$ \begriff{bedingten Erwartungswert}/\begriff{bedingte Erwartung} von $X$ gegeben $Y=y$.
\end{proposition}
\begin{proof}\
	\begin{enumerate}
		\item Sei $X \ge 0$. Definiere ein Maß $\mu$ auf $\F_Y$ durch
		\[
			\mu(B) = \E[X \indi_{y\in B}]
		\]
		dann ist $\mu \ll\P_Y$. Aus dem Satz von \person{Radon}-\person{Nikodym} (\propref{6_1_1:Radon}) folgt die Existenz einer $\P_Y$-f.s. bestimmten Dichte $g$.
		\item Sei $X \in \Ln{1}(\P)$. Es gilt $\E[X^-] < \infty \oder \E[X^+] < \infty$. Sei oBdA $\E[X^-] < \infty$, dann folgt auch $\E[X^-\mid Y=y] < \infty\;\P_Y$ f.s.. Setze
		\begin{align*}
			\E[X \mid Y = y] := \begin{cases}
			\E[X^+ \mid Y = y] - \E[X^-\mid Y=y] &\quad \E[X^- \mid Y =y] < \infty\\
			0 &\quad \sonst.
			\end{cases}
		\end{align*}
		Dann folgt
		\begin{align*}
			\E[X\indi_{y\in B}] &=\E[X^+ \indi_{y\in B}] - \E[X^-\indi_{y\in B}]\\
			&= \int_B \E[X^+ \mid Y=y]\P_Y(\d y) - \int_B \E[X^- \mid Y=y] \P_Y(\d y)\\
			&= \int_B \E[X \mid Y=y]\P_Y(\d y) \quad \forall B \in \F_Y.
		\end{align*} 
		Sind $g_1,g_2$ zwei Versionen der bedingten Erwartung, dann gilt wegen $\E[X^-]<\infty$ auch $\int_{\O_Y} g_1^- (y)\P_Y(\d y) < \infty$ für $i=1,2$ und dann folgt
		\begin{align*}
		\int_B g^+_1(y)\P_Y(\d y) &= \int_B g_1^-(y)\P_Y(\d y)\\
		&= \int_B g_1(y) \P_Y(\d y)\\
		&= \int_B g_2 (y)\P_Y (\d y)\\
		&= \int_B g_2^+ (y) \P_Y(\d y) - \int_B g_2^-(y) \P_Y(\d y)\\
		&\implies \int_B (g_1^+(y) + g_2^+(y)) \P_Y(\d y) \\
		&= \int_B (g_2^+ (y) + g_1^- (y))\P_Y(\d y) \quad \forall B \in \F_Y
		\intertext{also}
		g_1^+ + g_2^+ = g_2^+ + g_1^- \P_Y \text{-f.s.}
		\intertext{impliziert}
		g_1^+ - g_1^- = g_1 = g_2 = g_2^+ - g_2^- \P_Y \text{-fast-sicher.}
		\end{align*}
	\end{enumerate}
\end{proof}
\begin{*remark}
	Bedingte Erwartung und bedingte Verteilung hängen zusammen:
	\begin{itemize}
		\item Sind $X,Y$ so dass $\E X$ existiert und eine reguläre bedingte Verteilung\\ $\P_{X \mid Y = y}(B) = \P(X \in B \mid Y =y)$ existiert, dann folgt
		\[
			\E[X \mid Y=y] = \int_{\R} x \P_{X \mid Y = y} (\d x).
		\]
		Für Treppenfunktionen $X = \sum_{i=1}^n \alpha_i \indi_{A_i},\alpha_i > 0, A_i$ disjunkt, folgt dies aus
		\begin{align*}
			\E[X\indi_{y\in B}] &= \sum_{i=1}^n \alpha_i \E[\indi_{A_i} \indi_{y\in B}]\\
			&= \sum_{i=1}^n \alpha_i \P(X= \alpha_i, y \in B)\\
			&= \sum \alpha_i \int_B \P(X=\alpha_i \mid Y=y)\P_Y(\d y)\\
			&= \int_B \sum \alpha_i \P(X = \alpha_i \mid Y=y)\P_Y(\d y)\\
			&= \int_B \int_{\R} x \P_{X \mid Y = y} (\d x)\P(\d y)
		\end{align*}
		Für allgemeines $X$ folgt die Aussage mittels maßtheoretischer Induktion.
	\end{itemize}
\end{*remark}