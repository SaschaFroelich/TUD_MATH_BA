\documentclass[11pt]{article}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=4cm,bindingoffset=5mm]{geometry}
\usepackage{scrpage2}
\usepackage{amsmath}
\usepackage{paralist}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{booktabs}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{mathtools,bm}
\usepackage{stmaryrd} % Widerspruch symbol
\usepackage[framed, hyperref, thmmarks, amsmath]{ntheorem}
\usepackage[framemethod=tikz]{mdframed}
\usepackage[autostyle]{csquotes}
\usepackage{lipsum}
\usepackage{enumerate}

\title{\textbf{Lineare Algebra 1. Semester (WS2017/18)}}
\author{Dozent: Prof. Dr. Arno Fehm}
\date{}
\begin{document}

\maketitle
\renewcommand*{\arraystretch}{1.4}

\raggedright 
\section{Grundgegriffe der Linearen Algebra}
	\subsection{Logik und Mengen}
		Wir werden die Grundlagen der Logik und der Mengenlehre kurz ansprechen.
		\subsubsection{\"Uberblick \"uber die Aussagenlogik}
			Jede mathematisch sinnvolle Aussage ist entweder wahr oder falsch, aber nie beides!
			\begin{compactitem}
				\item "$1+1=2$" $\to$ wahr
				\item "$1+1=3$" $\to$ falsch
				\item "Es gibt unendlich viele Primzahlen" $\to$ wahr
			\end{compactitem}
			Man ordnet jeder mathematischen Aussage $A$ einen Wahrheitswert "wahr" oder "falsch" zu. Aussagen
			lassen sich mit logischen Verkn\"upfungen zu neuen Aussagen zusammensetzen.
			\begin{compactitem}
				\item $\lor \to$ oder
				\item $\land \to$ und
				\item $\lnot \to$ nicht
				\item $\Rightarrow \to$ impliziert
				\item $\iff \to$ \"aquivalent
			\end{compactitem}
			Sind also $A$ und $B$ zwei Aussagen, so ist auch $A \lor B$, $A \land B$, $\lnot A$, 
			$A \Rightarrow B$ und $A \iff B$ Aussagen. Der Wahrheitswert einer zusammengesetzen Aussage ist
			eindeutig bestimmt durch die Wahrheitswerte ihrer Einzelaussagen.
			\begin{compactitem}
				\item $\lnot (1+1=3) \to$ wahr
				\item "2 ist ungerade" $\Rightarrow$ "3 ist gerade" $\to$ wahr
				\item "2 ist gerade" $\Rightarrow$ "Es gibt unendlich viele Primzahlen" $\to$ wahr
			\end{compactitem}
			$\newline$
			\begin{center}
				\begin{tabular}{|c|c|c|c|c|c|c|}
					\hline
						$A$ & $B$ & $A \lor B$ & $A \land B$ & $\lnot A$ & $A \Rightarrow B$ & $A \iff B$\\
					\hline
						w & w & w & w & f & w & w\\
					\hline
						w & f & w & f & f & f & f\\
					\hline
						f & w & w & f & w & w & f\\
					\hline
						f & f & f & f & w & w & w\\
					\hline
				\end{tabular}
			\end{center}
			
		\subsubsection{\"Uberblick \"uber die Pr\"adikatenlogik}
			Wir werden die Quantoren
			\begin{compactitem}
				\item $\forall$ (Allquantor, "f\"ur alle") und
				\item $\exists$ (Existenzquantor, "es gibt") verwenden.
			\end{compactitem}
			Ist $P(x)$ eine Aussage, deren Wahrheitswert von einem unbestimmten $x$ abh\"angt, so ist \\
			$\forall x: P(x)$ genau dann wahr, wenn $P(x)$ f\"ur alle $x$ wahr ist, \\
			$\exists x: P(x)$ genau dann wahr, wenn $P(x)$ f\"ur mindestens ein $x$ wahr ist. \\
			$\newline$
			Insbesondere ist $\lnot \forall x: P(x)$ genau dann wahr, wenn $\exists x: \lnot P(x)$ wahr ist. \\
			Analog ist $\lnot \exists x: P(x)$ genau dann wahr, wenn $\forall x: \lnot P(x)$ wahr ist.
			
		\subsubsection{\"Uberblick \"uber die Beweise}
			Unter einem Beweis verstehen wir die l\"uckenlose Herleitung einer mathematischen Aussage aus einer
			Menge von Axiomen, Vorraussetzungen und schon fr\"uher bewiesenen Aussagen. \\
			Einige Beweismethoden:
			\begin{compactitem}
				\item \textbf{Widerspruchsbeweis} \\
				Man nimmt an, dass eine zu beweisende Aussage $A$ falsch sei und leitet daraus ab, dass eine 
				andere Aussage sowohl falsch als auch wahr ist. Formal nutzt man die G\"ultigkeit der Aussage
				$\lnot A \Rightarrow (B \land \lnot B) \Rightarrow A$.
				\item \textbf{Kontraposition} \\
				Ist eine Aussage $A \Rightarrow B$ zu beweisen, kann man stattdessen die Implikation 
				$\lnot B \Rightarrow \lnot A$ beweisen.
				\item \textbf{vollst\"andige Induktion} \\
				Will man eine Aussage $P(n)$ f\"ur alle nat\"urlichen Zahlen zeigen, so gen\"ugt es, zu zeigen,
				dass $P(1)$ gilt und dass unter der Induktionsbehauptung $P(n)$ stets auch $P(n+1)$ gilt 
				(Induktionschritt). Dann gilt $P(n)$ f\"ur alle $n$. \\
				Es gilt also das Induktionsschema: $P(1) \land \forall n: (P(n) \Rightarrow P(n+1)) \Rightarrow
				\forall n: P(n)$.
			\end{compactitem}
			
		\subsubsection{\"Uberblick \"uber die Mengenlehre}
			Jede Menge ist eine Zusammenfassung bestimmter wohlunterscheidbarer Objekte zu einem Ganzen. Eine
			Menge enth\"alt also solche Objekte, die Elemente der Menge. Die Menge ist durch ihre Elemente
			vollst\"andig bestimmt. Diese Objekte k\"onnen f\"ur uns verschiedene mathematische Objekte, wie
			Zahlen, Funktionen oder andere Mengen sein. Man schreibt $x \in M$ bzw. $x \notin M$, wenn x ein
			bzw. kein Element der Menge ist. \\
			$\newline$
			Ist $P(x)$ ein Pr\"adikat, so bezeichnet man eine Menge mit $X := \{x \mid P(x)\}$. Hierbei muss
			man vorsichtig sein, denn nicht immer lassen sich alle $x$ f\"ur die $P(x)$ gilt, widerspruchsfrei
			zu einer Menge zusammenfassen. \\
			$\newline$
			
			\textbf{Beispiel: endliche Mengen} \\
			Eine Menge hei{\ss}t endlich, wenn sie nur endlich viele Elemente enth\"alt. Endliche Mengen
			notiert man oft in aufz\"ahlender Form: $M = \{1;23;4;5;6\}$. Hierbei ist die Reihenfolge
			der Elemente nicht relevant, auch nicht die H\"aufigkeit eines Elements. \\
			Sind die Elemente paarweise verschieden, dann ist die Anzahl der Elemente die M\"achtigkeit
			(oder Kardinalit\"at) der Menge, die wir mit $|M|$ bezeichnen. \\
			$\newline$
			\textbf{Beispiel: unendliche Mengen} \\
			\begin{compactitem}
				\item Menge der nat\"urlichen Zahlen: $\mathbb N := \{1,2,3,4,...\}$
				\item Menge der nat\"urlichen Zahlen mit der 0: $\mathbb N_0 := \{0,1,2,3,4,...\}$
				\item Menge der ganzen Zahlen: $\mathbb Z := \{...,-2,-1,0,1,2,...\}$
				\item Menge der rationalen Zahlen: $\mathbb Q := \{\frac p q \mid p,q \in \mathbb Z, q 
				\neq 0\}$
				\item Menge der reellen Zahlen: $\mathbb R := \{x \mid x$ ist eine reelle Zahl$\}$
			\end{compactitem}
			Ist $M$ eine Menge, so gilt $|M|=\infty$ \\
			$\newline$
			
			\textbf{Beispiel: leere Mengen} \\
			Es gibt genau eine Menge, die keine Elemente hat, die leere Menge $0 := \{\}$.
			
			\begin{framed}
				\textbf{Definition Teilmenge:} Sind $X$ und $Y$ zwei Mengen, so heißt $X$ eine Teilmenge von 
				$Y$, wenn jedes Element von $X$ auch Element von $Y$ ist, dass heißt wenn für alle 
				$x$ $(x \in X \Rightarrow x \in Y)$ gilt.
			\end{framed}
			
			Da eine Menge durch ihre Elemente bestimmt ist, gilt $X = Y \Rightarrow (X \subset Y)\land
			(Y \subset X)$. Will man Mengengleichheit beweisen, so gen\"ugt es, die beiden Inklusionen
			$X \subset Y$ und $Y \subset X$ zu beweisen. \\
			$\newline$
			
			Ist $X$ eine Menge und $P(x)$ ein Pr\"adikat, so bezeichnet man mit $Y:= \{x \in X \mid
			P(x)\}$ die Teilmenge von $X$, die das Pr\"adikat $P(x)$ erf\"ullen. \\
			
			\begin{framed}
				\textbf{Definition Mengenoperationen:} Seien $X$ und $Y$ Mengen. Man definiert daraus 
				weitere Mengen wie folgt:
				\begin{compactitem}
					\item $X \cup Y := \{x \mid x \in X \lor x \in Y\}$
					\item $X \cap Y := \{x \mid x \in X \land x \in Y\}$
					\item $X \backslash Y := \{x \in X \mid x \notin Y\}$
					\item $X \times Y := \{(x,y) \mid x \in X \land y \in Y\}$
					\item $\mathcal P(X) := \{Y \mid Y \subset X\}$
				\end{compactitem}
			\end{framed}
			
			Neben den offensichtlichen Mengengesetzen, wie dem Kommutaivgesetz, gibt es auch weniger 
			offensichtliche Gesetze, wie die Gesetze von de Morgan: F\"ur $X_1, X_2 \subset X$ gilt:
			\begin{compactitem}
				\item $X \backslash (X_1 \cup X_2) = (X \backslash X_1) \cap (X \backslash X_2)$
				\item $X \backslash (X_1 \cap X_2) = (X \backslash X_1) \cup (X \backslash X_2)$
			\end{compactitem}
			$\newline$
			
			Sind $X$ und $Y$ endliche Mengen, so gilt:
			\begin{compactitem}
				\item $|X \times Y| = |X| \cdot |Y|$
				\item $|\mathcal P(X)| = 2^{|X|}$
			\end{compactitem}
			
	\subsection{Abbildungen}
		\subsubsection{\"Uberblick \"uber Abbildungen}
			Eine Abbildung $f$ von eine Menge $X$ in einer Menge $Y$ ist eine Vorschrift, die jedem $x \in X$
			auf eindeutige Weise genau ein Element $f(x) \in Y$ zuordnet. Man schreibt dies als 
			\begin{equation*}
			f:
				\begin{cases}
					X \to Y \\ x \mapsto y
				\end{cases}
			\end{equation*}
			oder $f: X \to Y, x \mapsto y$ oder noch einfacher $f: X \to Y$. Dabei hei{\ss}t $X$ die
			Definitions- und $Y$ die Zielmenge von $f$. Zwei Abbildungen heißen gleich, wenn ihre
			Definitionsmengen und Zielmengen gleich sind und sie jedem $x \in X$ das selbe Element
			$y \in Y$ zuordnen. Die Abbildungen von $X$ nach $Y$ bilden wieder eine Menge, welche wir 
			mit \textbf{Abb($X$,$Y$)} bezeichnen. \\
			$\newline$
			
			Beispiele: \\
			\begin{compactitem}
				\item Abbildungen mit Zielmenge $\mathbb R$ nennt man Funktion: $f: \mathbb R \to \mathbb
				R, x \mapsto x^2$
				\item Abbildungen mit Zielmenge $\subset$ Definitionsmenge: $f: \mathbb R \to \mathbb
				R_{\le 0}, x \mapsto x^2$ \\
				$\to$ Diese Abbildungen sind verschieden, da sie nicht die selbe Zielmenge haben.
				\item $f: \{0,1\} \to \mathbb R, x \mapsto x^2$
				\item $f: \{0,1\} \to \mathbb R, x \mapsto x$ \\
				$\to$ Diese Funktionen sind gleich. Sie haben die gleichen Definitions- und Zielmengen 
				und sie ordnen jedem Element der Definitionsmenge das gleiche Element der Zielmenge zu.
			\end{compactitem}
			$\newline$
			
			Beispiele: \\
			\begin{compactitem}
				\item auf jeder Menge $X$ gibt es die identische Abbildung (Identit\"at) \\ $id: X \to X, x 
				\mapsto x$
				\item allgemein kann man zu jeder Teilmenge $A \subset X$ die Inklusionsabbildung zuordnen
				$\iota_A: A \to X, x \mapsto x$
				\item zu je zwei Mengen $X$ und $Y$ und einem festen $y_0 \in Y$ gibt es die konstante
				Abbildung $c_{y_0}: X \to Y x \mapsto y_0$
				\item zu jder Menge $X$ und Teilmenge $A \subset X$ definiert man die charackteristische 
				Funktion\\ $\chi_A: X \to \mathbb R,
				\begin{cases}
					x \mapsto 1 \quad(x \in A) \\ x \mapsto 0 \quad(x \notin A)
				\end{cases}
				$
				\item zu jeder Menge $X$ gibt es die Abbildung \\ $f: X \times X \to \mathbb R, (x,y) \mapsto
				\delta_{x,y} \begin{cases} 1 \quad (x=y) \\ 0 \quad (x \neq y) \end{cases}$
			\end{compactitem}
			$\newline$
			
			\textbf{Eigenschaften von Funktionen:} \\
			\begin{compactitem}
				\item injektiv: Zuordnung ist eindeutig: $F(m_1) = F(m_2) \Rightarrow m_1=m_2$ \\
				Bsp: $x^2$ ist nicht injektiv, da $F(-2)=F(2)=4$
				\item surjektiv: $F(M)=N$ ($\forall n \in N \; \exists m \in M \mid F(m)=n$) \\
				Bsp: $sin(x)$ ist nicht surjektiv, da es kein $x$ f\"ur $y=27$ gibt
				\item bijektiv: injektiv und surjektiv
			\end{compactitem}
			
			\begin{framed}
				\textbf{Definition Einschr\"ankung:} Sei $f: x \mapsto y$ eine Abbildung. F\"ur $A \subset X$
				definiert man die Einschr\"ankung/Restrikton von $f$ auf $A$ als die Abbildung $f \mid_A 
				A \to Y, a \mapsto f(a)$. \\
				Das Bild von $A$ unter $f$ ist $f(A) := \{f(a): a \in A\}$. \\
				Das Urbild einer Menge $B \subset Y$ unter $f$ ist $f^{-1} := \{x \in X: f(x) \in B\}$. \\
				Man nennt $Image(f) := f(X)$ das Bild von $f$.
			\end{framed}
			
			\textbf{Bemerkungen zur abstrakteren Betrachtungsweise:} \\
			Man ordnet der Abbildung $f: X \to Y$ auch die Abbildungen $\mathcal P(X) \to \mathcal P(Y)$ und
			$\mathcal P(Y) \to \mathcal P(X)$ auf den Potenzmengen zu. Man benutzt hier das gleiche 
			Symbol $f(…)$ sowohl für die Abbildung $f: X \to Y$ als auch f\"ur $f: P(X) \to P(Y)$, was 
			unvorsichtig ist, aber keine Probleme bereiten sollte. \\
			In anderen Vorlesungen wird f\"ur $y \in Y$ auch $f^{-1}(y)$ statt $f^{-1}(\{y\})$ geschrieben. \\
			$\newline$
			
			\textbf{Bemerkungen:} \\
			Genau dann ist $f: X \to Y$ surjektiv, wenn $Image(f)=Y$ \\
			Genau dann ist $f: X \to Y \begin{cases} $injektiv$ \\ $surjektiv$ \\ $bijektiv$ \end{cases}$, wenn
			$|f^{-1}(\{y\})| = \begin{cases} \le 1 \\ \ge 1 \\ =1  \end{cases} \quad \forall y \in Y$ \\
			
			\begin{framed}
				\textbf{Definition Komposition:} Sind $f: X \to Y$ und $g: Y \to Z$ Abbildungen, so ist die
				Komposition $g \circ f$ die Abbildung $g \circ f := X \to Z, x \mapsto g(f(x))$. Man kann 
				die Komposition auffassen als eine Abbildung $\circ: Abb(Y,Z) \times Abb(X,Y) \to Abb(X,Z)$.
			\end{framed}
			
			\begin{framed}
				\textbf{Satz:} Die Abbildung von Kompositionen ist assotiativ, d.h. es gilt: $h \circ (g 
				\circ f) = (h \circ g)\circ f$.
			\end{framed}
			
			\begin{framed}
				\textbf{Definition Umkehrabbildung:} Ist $f: X \to Y$ bijektiv, so gibt es zu jedem $y \in Y$
				genau ein $x_y \in X$ mit $f(x_y)=y$, durch $f^{-1}: Y \to X, y \mapsto x_y$ wird also eine 
				Abbildung definiert, die Umkehrabbildung zu $f$. 
			\end{framed}
			
			\begin{framed}
				\textbf{Satz:} Ist die Abbildung $f: X \to Y$ bijektiv, so gilt $f^{-1} \circ f = id_x$ und
				$f \circ f^{-1} = id_y$.
			\end{framed}
			
			\textbf{Bemerkung:} \\
			Achtung, wir verwenden hier das selbe Symbol $f^{-1}$ f\"ur zwei verschiedene Dinge: Die Abbildung
			$f^{-1}: \mathcal P(X) \to \mathcal P(Y)$ existiert f\"ur jede Abbildung $f: X \to Y$, aber die
			Umkehrabbildung $f^{-1}: Y \to X$ existiert nur f\"ur bijektive Abbildungen $f: X \to Y$. \\
			
			\begin{framed}
				\textbf{Definition Familie:} Seien $I$ und $X$ Mengen. Eine Abbildung $x: I \to X, i \mapsto
				x_i$ nennt man Familie von Elementen von $X$ mit einer Indexmenge I (oder I-Tupel von 
				Elementen von $X$) und schreibt diese auch als $(x_i)_{i \in I}$. Im Fall $I=\{1,2,...,n\}$
				identifiziert man die I-Tupel auch mit den n-Tupeln. Ist $(x_i)_{i \in I}$ eine Familie von
				Teilmengen einer Menge $X$, so ist 
				\begin{compactitem}
					\item $\bigcup X_i = \{x \in X \mid \exists i \in I(x \in X)\}$
					\item $\bigcap X_i = \{x \in X \mid \forall i \in I(x \in X)\}$
					\item $\prod X_i = \{f \in Abb(I,X) \mid \forall i \in I(f(i) \in X_i)\}$
				\end{compactitem}
				Die Elemente von $\prod X_i$ schreibt man in der Regel als Familien $(x_i)_{i \in I}$.
			\end{framed}
			
			\textbf{Beispiel: } Eine Folge ist eine Familie $(x_i)_{i \in I}$ mit der Indexmenge $\mathbb N_0$.
			
			\begin{framed}
				\textbf{Definition Graph:} Der Graph einer Abbildung $f: X \to Y$ ist die Menge $\Gamma f: 
				\{(x,y) \in X \times Y \mid y=f(x)\}$.
			\end{framed}
			
			\textbf{Bemerkung: Formal korrekte Definition einer Abbildung:} \\
			Eine Abbildung $f$ ist ein Tripel $(X,Y,\Gamma)$, wobei $\Gamma \subset X \times Y \quad \forall
			x \in X$ genau ein Paar $(x,y)$ mit $y \in Y$ enth\"alt. Die Abbildungsvorschrift schickt dann
			$x \in X$ auf das eindeutig bestimmte $y \in Y$ mit $(x,y) \in \Gamma$. Es ist dann $\Gamma =
			\Gamma_f$.
			
	\subsection{Gruppen}
		\begin{framed}
			\textbf{Definition Gruppe:} Sei $G$ eine Menge. Eine (innere, zweistellige) Verkn\"upfung
			auf $G$ ist eine Abbildung $*: G \times G \to G, (x,y) \mapsto x*y$. Das Paar $(G,*)$ ist eine
			Halbgruppe, wenn das folgende Axiom erf\"ullt ist: \\
			(G1) F\"ur $x,y,z \in G$ ist $(x*y)*z=x*(y*z)$. \\
			Eine Halbgruppe $(G,*)$ ist ein Monoid, wenn zus\"atzlich das folgende Axiom gilt: \\
			(G2) Es gibt ein Element $e \in G$, welches f\"ur alle $x \in G$ die Gleichung $x*e=e*x=x$
			erf\"ullt. Dieses Element hei{\ss}t dann neutrales Element der Verkn\"upfung $*$.  
		\end{framed}
		
		\textbf{Beispiele:} \\
		\begin{compactitem}
			\item F\"ur jede Menge $X$ ist $(Abb(X,Y), \circ)$ eine Halbgruppe mit dem neutralen Element
			$id_x$, also ein Monoid.
			\item $\mathbb N$ bildet mit der Addition eine Halbgruppe $(\mathbb N,+)$, aber kein Monoid,
			da die 0 nicht in Fehm's Definition der nat\"urlichen Zahlen geh\"orte
			\item $\mathbb N_0$ bildet mit der Addition ein Monoid $(\mathbb N_0,+)$
			\item $\mathbb N$ bildet mit der Multiplikation ein Monoid $(\mathbb N, \cdot)$
			\item $\mathbb Z$ bildet mit der Multiplikation ein Monoid $(\mathbb Z, \cdot)$
		\end{compactitem}
		
		\begin{framed}
			\textbf{Satz: (Eindeutigkeit des neutralen Elements)} Ein Monoid $(G,*)$ hat genau ein neutrales
			Element. 
		\end{framed}
		
		\begin{framed}
			\textbf{Definition abelsche Gruppe:} Eine Gruppe ist ein Monoid $(G,*)$ mit dem neutralen Element
			$e$, in dem zus\"atzlich das folgende Axiom gilt: \\
			(G3) F\"ur jedes $x \in G$ gibt es ein $x' \in G$ mit $x'*x=x*x'=e$. \\
			Gilt weiterhin \\
			(G4) F\"ur alle $x,y \in G$ gilt $x*y=y*x$, so hei{\ss}t diese Gruppel abelsch.
		\end{framed}
		
		Ein $x'$ hei{\ss}t inverses Element zu $x$. \\
		$\newline$
		
		\textbf{Beispiele:} \\
		\begin{compactitem}
			\item $\mathbb N_0$ bildet mit der Addition keine Gruppe $(\mathbb N_=,+)$
			\item $\mathbb Z$ bildet mit der Addition eine abelsche Gruppe $(\mathbb Z,+)$
			\item Auch $(\mathbb Q,+)$ und $(\mathbb R,+)$ sind abelsche Gruppen
			\item $(\mathbb Q,\cdot)$ ist keine Gruppe, aber $(\mathbb Q\backslash\{0\},\cdot)$ schon
		\end{compactitem}
		
		\begin{framed}
			\textbf{Satz: (Eindeutigkeit des Inversen)} Ist $(G,*)$ eine Gruppe, so hat jedes $x \in G$
			genau ein inverses Element.
		\end{framed}
		
		\textbf{Beispiele:} \\
		\begin{compactitem}
			\item Eine triviale Gruppe besteht nur aus ihrem neutralen Element. Tats\"achlich ist $G=\{e\}$ mit
			$e*e=e$ eine Gruppe.
			\item Sei $X$ eine Menge. Die Menge $Sym(X) := \{f \in Abb(X,X) \mid f$ ist bijektiv$\}$ der
			Permutationen von $X$ bildet mit der Komposition eine Gruppe $(Sym(X),\circ)$, die 
			symmetrsiche Gruppe auf $X$. F\"ur $n \in \mathbb N$ schreibt man $S_n := Sym(\{1,2,...,n\})$. 
			F\"ur $n \ge 3$ ist $S_n$ nicht abelsch.
		\end{compactitem}
		$\newline$
		
		\textbf{Bemerkung:} H\"aufig benutzte Notationen f\"ur die Gruppenverkn\"upfung $\cdot$:\\
		\begin{compactitem}
			\item In der multiplikativen Notation schreibt man $\cdot$ statt $*$ (oft auch $xy$ statt 
			$x \cdot y$), bezeichnet das neutrale Element mit $1$ oder $1_G$ und das Inverse zu $x$ mit
			$x^{-1}$.
			\item In der additiven Notation schreibt man $x$ f\"ur $*$, bezeichnet das neutrale Element
			mit $0$ oder $0_G$ und das Inverse zu $x$ mit $-x$. Die additive Notation wird nur verwendet,
			wenn die Gruppe abelsch ist.
		\end{compactitem}
		$\newline$
		
		In abelschen Gruppen notiert man Ausdr\"ucke auch mit dem Summen- und Produktzeichen. \\
		
		\begin{framed}
			\textbf{Satz:} Sei $(G,\cdot)$ eine Gruppe. F\"ur $x,y \in G$ gelten $(x^{-1})^{-1}=x$ und
			$(xy)^{-1}=x^{-1} \cdot x^{-1}$.
		\end{framed}
		
		\begin{framed}
			\textbf{Satz:} Sei $(G,\cdot)$ eine Gruppe. F\"ur $a,b \in G$ haben die Gleichungen $ax=b$ und
			$ya=b$ eindeutige L\"osungen in $G$, n\"amlich $x=a^{-1} \cdot b$ und $y=b \cdot a^{-1}$. 
			Insbesondere gelten die folgenden K\"urzungsregeln: $ax=ay \Rightarrow x=y$ und $xa=ya 
			\Rightarrow x=y$.
		\end{framed}
		
		\textit{Beweis: \\
		Es ist $a \cdot a^{-1} \cdot b = 1b=b$, also ist $x=a^{-1} \cdot b$ eine L\"osung. Ist umgekehrt
		$ax=b$ mit $x \in G$, so ist $a^{-1} \cdot b = a^{-1]} \cdot ax = 1x = x$ die L\"osung und somit
		eindeutig. F\"ur die zweite Gleichung argumentiert man analog. Den "Insbesondere"-Fall erh\"alt
		man durch Einsetzen von $b=ay$ bzw. $b=xa$.} \\
		$\newline$
		
		\textbf{Bemerkung:} \\
		Wenn aus dem Kontext klar ist, welche Verkn\"upfung gemeint ist, schreibt man auch einfach
		$G$ anstatt $(G, \cdot)$ bzw. $(G,+)$. Eine Gruppe $G$ hei{\ss}t endlich, wenn die Menge $G$ endlich
		ist. Die Mächtigkeit $|G|$ von $G$ nennt man dann die Ordnung von $G$. Eine endliche Gruppe kann 
		durch ihre Verkn\"upfungstafel vollst\"andig beschrieben werden. \\
		$\newline$
		
		\textbf{Beispiele:} \\
		a) die triviale Gruppe $G=\{e\}$
		\begin{center}
			\begin{tabular}{|c|c|}
				\hline
				$\cdot$ & $e$\\
				\hline
				$e$ & $e$ \\
				\hline
			\end{tabular}
		\end{center}
		b) die Gruppe $\mu_2 = \{1,-1\}$ der Ordnung 2
		\begin{center}
			\begin{tabular}{|c|c|c|}
				\hline
				$\cdot$ & $1$ & $-1$\\
				\hline
				$1$ & $1$ & $-1$ \\
				\hline
				$-1$ & $-1$ & $1$ \\
				\hline
			\end{tabular}
		\end{center}
		c) die Gruppe $S_2= Sym(\{1,2\}) = \{id_{\{1,2\}},f\}$, wobei $f(1)=2$ und $f(2)=1$
		\begin{center}
			\begin{tabular}{|c|c|c|}
				\hline
				$\circ$ & $id_{\{1,2\}}$ & $f$\\
				\hline
				$id_{\{1,2\}}$ & $id_{\{1,2\}}$ & $f$ \\
				\hline
				$f$ & $f$ & $id_{\{1,2\}}$ \\
				\hline
			\end{tabular}
		\end{center}
		
		\begin{framed}
			\textbf{Definition Untergruppe:} Eine Untergruppe einer Gruppe $(G,\cdot)$ ist eine 
			nichtleere Teilmenge $H \subset G$, f\"ur die gilt: \\
			(UG1) F\"ur alle $x,y \in H$ ist $x \cdot y \in H$ (Abgeschlossenheit unter Multiplikation) \\
			(UG2) F\"ur alle $x \in H$ ist $x^{-1} \in H$ (Abgeschlossenheit unter Inversen)
		\end{framed}
		
		\begin{framed}
			\textbf{Satz:} Sei $(G,\cdot)$ eine Gruppe und $\emptyset \neq H \subset G$. Genau dann ist
			$H$ eine Untergruppe von $G$, wenn sich die Verkn\"upfung $\cdot: G \times G \to G$ zu einer
			Abbildung $\cdot_H: H \times H \to H$ einschr\"anken l\"asst (d.h. $\cdot|_{H \times H}=
			\iota_H \circ \cdot_H$, wobei $\iota_H \cdot \cdot_H \to G$ die Inklusionsabbildung ist) und
			$(H,\cdot_H)$ eine Gruppe ist.
		\end{framed}
		
		\textit{Beweis: \\
		Hinrichtung: Sei $H$ eine Untergruppe von $G$. Nach (UG1) ist $Image(\cdot|_{H \times H}) \subset H$
		und somit l\"asst sich $\cdot$ zu einer Abbildung $\cdot_H: H \times H \ to H$ einschr\"anken. Wir 
		betrachten jetzt $H$ mit dieser Verkn\"upfung. Da $G$ (G1) erf\"ullt, erf\"ullt auch H (G1). Da
		$H \neq \emptyset$ existiert ein $x \in H$. Nach (UG1) und (UG2) ist $x \cdot x^{-1}=e \in H$. Da 
		$e_G \cdot y=y \cdot e_G=y$ f\"ur alle $y \in G$, insbesondere auch f\"ur alle $y \in H$ (G2). Wegen
		(UG2) erf\"ullt $H$ auch das Axiom (G3). $H$ ist somit eine Gruppe. \\
		R\"uckrichtung: Sei nun umgekehrt $(H,\cdot_H)$ eine Gruppe. F\"ur $x,y \in H$ ist dann $xy=x \cdot_H
		y \in H$, also er\"ullt $H$ (UG1). Aus $e_H \cdot e_H=e_H=e_H \cdot e_G$ folgt $e_H=e_G$. Ist also
		$x'$ das Inverse zu $x$ aus der Gruppe $H$, so ist $x'x=xx'=e_G=e_H$, also $x^{-1}=x' \in H$ und
		somit erf\"ullt $H$ auch (UG2). Wir haben gezeigt, dass $H$ eine Untergruppe von $G$ ist.} \\
		$\newline$
		
		\textbf{Bemerkung:} \\
		Wir nennen nicht nur die Menge $H$ eine Untergruppe von $G$, sondern auch die Gruppe $(H,\cdot_H)$.
		Wir schreiben $H \le G$. \\
		$\newline$
		
		\textbf{Beispiele:} \\
		\begin{compactitem}
			\item Jede Gruppe $G$ hat die triviale Untergruppe $H=\{e_G\}$ und $H=G$
			\item Ist $H \le G$ und $K \le H$, so ist $K \le G$ (Transitivit\"at)
			\item Unter Addition ist $\mathbb{Z} \le \mathbb{Q} \le \mathbb{R}$ eine Kette von Untergruppen
			\item Unter Multiplikation ist $\mu_2 \le \mathbb{Q}^+ \le \mathbb{R}^+$ eine Kette von 
			Untergruppen
			\item F\"ur $n \in \mathbb{N}_0$ ist $n\mathbb{Z} := \{nx \mid x \in \mathbb{Z}\} \le \mathbb{Z}$ 
		\end{compactitem}
		
		\begin{framed}
			\textbf{Lemma:} Ist $G$ eine Gruppe und $(H_i)_{i \in I}$ eine Familie von Untergruppen von $G$,
			so ist auch $H := \bigcap H_i$ eine Untergruppe von $G$.
		\end{framed}
		
		\textit{Beweis: Wir haben 3 Dinge zu zeigen\\
		\begin{compactitem}
			\item $H \neq \emptyset:$ F\"ur jedes $i \in I$ ist $e_G \in H$, also auch $e_G \in \bigcap
			H_i =H$
			\item (UG1): Seien $x,y \in H$. F\"ur jedes $i \in I$ ist $x,y \in H_i$, somit $xy \in H_i$,
			da $H_i \le G$. Folglich ist $xy \in \bigcap H_i=H$.
			\item (UG2): Sei $x \in H$. F\"ur jedes $i \in I$ ist $x \in H_i$, somit $x^{-1} \in H_i$,
			da $H_i \le G$. Folglich ist $x^{-1} \in \bigcap H_i=H$.
		\end{compactitem}
		}
		
		\begin{framed}
			\textbf{Satz:} Ist $G$ eine Gruppe und $X \subset G$. so gibt es eine eindeutig bestimmte
			kleinste Untergruppe $H$ von $G$, die $X$ enth\"alt, d.h. $H$ enth\"alt $X$ und ist $H'$
			eine weitere Untergruppe von $G$, die $X$ enth\"alt, so ist $H \subset H'$.
		\end{framed}
		
		\textit{Beweis: \\
		Sei $\mathcal{H}$ die Menge aller Untergruppen von $G$, die $X$ enthalten. Nach dem Lemma ist $H:=
		\bigcap \mathcal{H} := \bigcap H$ eine Untergruppe von $G$. Da $X \subset H'$ f\"ur jedes $H' \in 
		\mathcal H$ ist auch $X \subset H$. Nach Definition ist $H$ in jedem $H' \le G$ mit $X \subset H'$
		enhalten.} \\
		$\newline$
		
		\begin{framed}
			\textbf{Definition erzeugte Untergruppe:} Ist $G$ eine Gruppe und $X \le G$, so nennt man diese
			kleinste Untergruppe von $G$, die $X$ enth\"alt, die von $X$ erzeugte Untergruppe von $G$ und
			bezeichnet diese mit $<X>$, falls $X = \{x_1,x_2,...,x_n\}$ enth\"alt auch mit $<x_1,x_2,
			...,x_n>$. Gibt es eine endliche Menge $X \subset G$ mit $G=<X>$, so nennt man $G$ endlich
			erzeugt.
		\end{framed}
		
		\textbf{Beispiele:}
		\begin{compactitem}
			\item Die leere Menge $X=\emptyset \le G$ erzeugt stets die trivale Untergruppe $<\emptyset>
			=\{e\} \le G$
			\item Jede endliche Gruppe $G$ ist endlich erzeugt $G=<G>$
			\item F\"ur $n \in \mathbb{N}_0$ ist $n\mathbb{Z}=<n> \le \mathbb{Z}$. Ist $H \le \mathbb{Z}$
			mit $n \in H$, so ist auch $kn=nk=n+n+...+n \in H$ und somit auch $n\mathbb{Z} \le H$.
		\end{compactitem}
		
	\subsection{Ringe}
		\begin{framed}
			\textbf{Definition Ring:} Ein Ring ist ein Tripel $(R,+,\cdot)$ bestehend aus einer Menge
			$R$, einer Verkn\"upfung $+: R \times R \to R$ (Addition) und einer anderen Verkn\"upfung
			$\cdot: R \times R \to R$ (Multiplikation), sodass diese zusammen die folgenden Axiome 
			erf\"ullen: \\
			(R1) $(R,+)$ ist eine abelsche Gruppe \\
			(R2) $(R,\cdot)$ ist eine Halbgruppe \\
			(R3) F\"ur $a,x,y \in R$ gelten die Distributivgesetze $a(x+y)=ax+ay$ und $(x+y)a=xa+ya$. \\
			Ein Ring hei{\ss}t kommutativ, wenn $xy=yx$ f\"ur alle $x,y \in R$.\\
			Ein neutrales Element der Multiplikation hei{\ss}t Einselement von $R$.\\
			Ein Unterrrig eines Rings $(R,+,\cdot)$ ist eine Teilmenge, die mit der geeigneten
			Einschr\"ankung von Addition und Multiplikation wieder ein Ring ist.
		\end{framed}
		
		\textbf{Bemerkungen:} \\
		Hat ein Ring ein Einselement, so ist dieses eindeutig bestimmt. Notationelle Konfektionen: Das 
		neutrale Element der Addition wird h\"aufig mit 0 bezeichnet; die Multiplikation wird nicht immer
		notiert; Multiplikation bindet st\"arker als die Addition. \\
		Wenn die Verkn\"upfungen aus dem Kontext klar sind, schreibt ma $R$ statt $(R,+,\cdot)$. \\
		$\newline$
		
		\textbf{Beispiele:} \\
		\begin{compactitem}
			\item Der Nullring ist $R=\{0\}$ mit den einzig m\"oglichen Verkn\"upfungen $+$ und $\cdot$
			auf $R$. Der Nullring ist sogar kommutativ und hat ein Einselement, n\"amlich die 0.
			\item $(\mathbb{Z},+,\cdot)$ ist ein kommutativer Ring mit Einselement 1, ebenso
			$(\mathbb{Q},+,\cdot)$ und $(\mathbb{R},+,\cdot)$. 
			\item $(2\mathbb{Z},+,\cdot)$ ist ein kommutativer Ring, aber ohne Einselement.
		\end{compactitem}
		$\newline$
		
		\textbf{Bemerkungen:} Ist $R$ ein Ring, dann gelten die folgenden Aussagen f\"ur $x,y \in R$\\
		\begin{compactitem}
			\item $0 \cdot x=x \cdot 0 = 0$
			\item $x \cdot (-y) = (-x) \cdot y = -xy$
			\item $(-x) \cdot (-y) = xy$
		\end{compactitem}
		$\newline$
		
		\textbf{Bemerkung:} \\
		Wir f\"uhren eine wichtige Klassen endlicher Ringe ein. Hierf\"ur erinnern wir uns eine der Grundlagen
		der Arithmetik in $\mathbb{Z}$. \\
		
		\begin{framed}
			\textbf{Theorem:} Sei $b \neq 0 \in \mathbb{Z}$. F\"ur jedes $a \in \mathbb{Z}$ gibt es 
			eindeutig bestimmte $q,r \in \mathbb{Z}$ ($r$ ist "Rest"), mit $a=qb+r$ und $0 \le r < |b|$.
		\end{framed}
		\textit{Beweis: Existenz und Eindeutigkeit \\
		Existenz: oBdA nehmen wir an, dass $b>0$ (denn ist $a=qb+r$, so ist auch $a=(-q)(-b)+r$). Sei $q \in
		\mathbb{Z}$ die gr\"o{\ss}te Zahl mit $q \le \frac{a}{b}$, und sei $r=a-qb \in \mathbb{Z}$. Dann ist
		$a \le \frac{a}{b}-q < 1$, woraus $0 \le r < b$ folgt. \\
		Eindeutigkeit: Sei $a=qb+r=q'b+r'$ mit $q,q',r,r' \in \mathbb{Z}$ und $0 \le r,r' < |b|$. Dann ist
		$(q-q')b=r-r'$ und $|r-r'|<|b|$. Da $q-q' \in \mathbb{Z}$ ist, folgt $r-r'=0$ und daraus wegen 
		$b \neq 0$, dann $q-q'=0$.}\\
		$\newline$
		
		\textbf{Beispiel (Restklassenring):} Wir fixieren $n \in \mathbb{N}$. F\"ur $a \in \mathbb{Z}$ sei
		$\overline(a) := a+n\mathbb{Z} := \{a+nx \mid x \in \mathbb{Z}\}$ die Restklasse von "$a \bmod n$". 
		F\"ur $a,a' \in \mathbb{Z}$ sind \"aquivalent:
		\begin{compactitem}
			\item $a+n\mathbb{Z}=a'+n\mathbb{Z}$
			\item $a' \in a+n\mathbb{Z}$
			\item $n$ teilt $a'-a$ (in Zeichen $n|a'-a$), d.h. $a'=a+nk$ f\"ur $k \in \mathbb{Z}$
		\end{compactitem}
		\textit{Beweis: \\
		$1) \Rightarrow 2)$: klar, denn $0 \in \mathbb{Z}$ \\
		$2) \Rightarrow 3)$: $a' \in a+n\mathbb{Z} \Rightarrow a'=a+nk$ mit $k \in \mathbb{Z}$ \\
		$3) \Rightarrow 1)$: $a'=a+nk$ mit $k \in \mathbb{Z} \Rightarrow a+n\mathbb{Z}=\{a+nk+nx \mid 
		x \in \mathbb{Z}\}=\{a+n(k+x) \mid x \in \mathbb{Z}\}=a+n\mathbb{Z}$ \\
		Insbesondere besteht $a+n\mathbb{Z}$ nur aus den ganzen Zahlen, die bei der Division durch $n$ den
		selben Rest lassen wie $a$.}\\
		$\newline$
		
		Aus dem Theorem folgt weiter, dass $\mathbb{Z}/n\mathbb{Z} := \{\overline{a} \mid a \in \mathbb{Z}\}
		= \{\overline{0}, \overline{1},..., \overline{n-1}\}$ eine Menge der M\"achtigkeit n ist (sprich: 
		"$\mathbb{Z} \bmod n\mathbb{Z}$"). \\
		$\newline$
		
		Wir definieren Verkn\"upfungen auf $\mathbb{Z}/n\mathbb{Z}$ durch $\overline{a}+\overline{b} :=
		\overline{a+b}$, $\overline{a} \cdot \overline{b} := \overline{ab}$ $a,b \in \mathbb{Z}$. Hierbei
		muss man zeigen, dass diese Verkn\"upfungen wohldefiniert sind, also nicht von den gew\"ahlten
		Vertretern $a,b$ der Restklassen $\overline{a}$ und $\overline{b}$ abh\"angen. Ist etwa $\overline{a}
		= \overline{a'}$ und $\overline{b}= \overline{b'}$, also $a'=a+nk_1$ und $b'=b+nk_2$ mit $k_1,k_2 \in
		\mathbb{Z}$, so ist \\
		$a'+b' = a+b+n(k_1+k_2)$, also $\overline{a'+b'} = \overline{a+b}$ \\
		$a' \cdot b' = ab+n(bk_1+ak_2+nk_1k_2)$, also $\overline{a'b'} = \overline{ab}$ \\
		Man pr\"uft nun leicht nach, dass $\mathbb{Z}/n\mathbb{Z}$ mit diesen Verkn\"upfungen ein kommutativer
		Ring mit Einselement ist, da dies auch f\"ur $(\mathbb{Z},+,\cdot)$ gilt. Das neutrale Element der
		Addition ist $\overline{0}$, das Einselement ist $\overline{1}$. \\
		$\newline$
		
		\textbf{Beispiel:} Im Fall $n=2$ ergeben sich die folgenden Verkn\"upfungstafeln f\"ur $\mathbb{Z}
		/2\mathbb{Z} = \{\overline{0}, \overline{1}\}$ \\
		\begin{center}
			\begin{tabular}{|c|c|c|}
				\hline
				$+$ & $\overline{0}$ & $\overline{1}$\\
				\hline
				$\overline{0}$ & $\overline{0}$ & $\overline{1}$\\
				\hline
				$\overline{1}$ & $\overline{1}$ & $\overline{2}=\overline{0}$ \\
				\hline
			\end{tabular}
		\end{center}
		\begin{center}
			\begin{tabular}{|c|c|c|}
				\hline
				$\cdot$ & $\overline{0}$ & $\overline{1}$\\
				\hline
				$\overline{0}$ & $\overline{0}$ & $\overline{0}$\\
				\hline
				$\overline{1}$ & $\overline{0}$ & $\overline{1}$ \\
				\hline
			\end{tabular}
		\end{center}
		
		\begin{framed}
			\textbf{Definition Charakteristik:} Sei $R$ ein Ring mit Einselement. Man definiert die Charakteristik von
			$R$ als die kleinste nat\"urliche Zahl $n$ mit $1+1+...+1=0$, falls so ein $n$ existiert, andernfalls
			ist die Charakteristik $0$.
		\end{framed}
		
		\begin{framed}
			\textbf{Definition Nullteiler:} Sei $R$ ein Ring mit Einselement. Ein $0 \neq x \in R$ ist ein Nullteiler von 
			$R$, wenn er ein $0 \neq y \in R$ mit $xy=0$ oder $yx=0$ gibt. Ein Ring ohne Nullteiler ist
			nullteilerfrei.
		\end{framed}
		
		\begin{framed}
			\textbf{Definition Einheit:} Sei $R$ ein Ring mit Einselement. Ein $x \in R$ hei{\ss}t invertierbar (oder
			 Einheit von $R$), wenn es ein $x' \in R$ mit $xx'=x'x=1$ gibt. Wir bezeichnen die invertierten
			 Elemente von $R$ mit $R^{\times}$
		\end{framed}
		
		\textbf{Beispiele:}\\
		\begin{compactitem}
			\item reelle Zahlen ist ein nullteilerfreier Ring der Charakteristik $0$ mit $\mathbb R^{\times}=
			\mathbb R\backslash\{0\}$
			\item $\mathbb Z$ ist ein nullteilerfreier Ring der Charakteristik $0$ mit $\mathbb Z^{\times}=
			\{1,-1\}$
			\item $\mathbb Z/n \mathbb Z$ ist ein Ring der Charakteristik $n$. Ist $n$ keine Primzahl, so
			ist $\mathbb Z$ nicht nullteilerfrei.
		\end{compactitem}
		
		\begin{framed}
			\textbf{Satz:} Sei $R$ ein Ring mit Einselement. 
			\begin{compactitem}
				\item Ist $x \in R$ invertierbar, so ist $x$ kein Nullteiler in $R$
				\item Die invertierbaren Elemente von $R$ bilden mit der Multiplikation eine Gruppe
			\end{compactitem}
		\end{framed}
		
		\textit{Beweis: \\
		\begin{compactitem}
			\item Ist $xx'=x'x=1$ und $xy=0$ mit $x',y \in R$, so ist $0=x'\cdot 0=x\cdot xy=1\cdot y=y$, aber
			$y \neq 0$ f\"ur Nullteiler
			\item Sind $x,y \in R^{\times}$, also $xx'=x'x=yy'=y'y=1$. Dann ist $(xy)(y'x')=x\cdot 1\cdot x'=1$
			und $(y'x')(xy)=y'\cdot 1\cdot y=1$, somit $R^{\times}$ abgeschlossen unter der Multiplikation. Da 
			$1 \cdot 1=1$ gilt, ist auch $1 \in R^{\times}$. Nach Definition von $R^{\times}$ hat jedes $x \in 
			R^{\times}$ ein Inverses $x' \in R^{\times}$.
		\end{compactitem}}
		$\newline$
		
	\subsection{K\"orper}
		\begin{framed}
			\textbf{Definition K\"orper:} Ein K\"orper ist ein kommutativer Ring $(K,+,\cdot)$ mit Einselement 
			$1 \neq 0$, in dem jedes Element $x \neq x \in K$ invertierbar ist.
		\end{framed}
		
		\textbf{Bemerkungen:} Ein K\"orper ist stets nullteilerfrei und $(K\backslash\{0\}, \cdot)$ ist eine abelsche
		Gruppe. Ein k\"orper ist also ein Tripel $(K,+,\cdot)$ bestehend aus einer Menge $K$ und 2 Verkn\"upfungen
		$+: K \times K \to K$ und $\cdot: K \times K \to K$, f\"ur die gelten: \\
		(K1): $(K,+)$ ist eine abelsche Gruppe \\
		(K2): $(K\backslash\{0\}, \cdot)$ ist eine abelsche Gruppe, deren neutrales Element wir mit 1 bezeichnen \\
		(K3): Es gelten die Distributivgesetze. \\
		$\newline$
		
		\textbf{Bemerkungen:} Sei $K$ ein K\"orper und $a,x,y \in K$. Ist $ax=ay$ und $a \neq 0$, so ist $x=y$. \\
		
		\begin{framed}
			\textbf{Definition Teilk\"orper:} Ein Teilk\"orper eines K\"orpers $(K,+,\cdot)$ ist die Teilemenge $L 
			\subset K$, die mit der geeigneten Einschr\"ankung von Addition und Multiplikation wieder ein
			K\"orper ist.
		\end{framed}
		
		\textbf{Beispiele:}
		\begin{compactitem}
			\item Der Nullring ist kein K\"orper.
			\item Der K\"orper $\mathbb Q$ der rationalen Zahlen ist ein Teilk\"orper des K\"orpers $\mathbb R$ der
			reellen Zahlen.
			\item $(\mathbb Z, + ,\cdot)$ ist kein K\"orper
		\end{compactitem}
		$\newline$
		
		\textbf{Beispiel (Komplexe Zahlen)} \\
		Wir definieren die Menge $\mathbb C = \mathbb R \times \mathbb R$ und darauf Verkn\"upfungen wie folgt:
		F\"ur $(x_1,y_1), (x_2,y_2) \in \mathbb C$ ist: \\
		\begin{compactitem}
			\item$(x_1,y_1)+(x_2,y_2) := (x_1+x_2,y_1+y_2)$
			\item$(x_1,y_1)\cdot (x_2,y_2) := (x_1x_2-y_1y_2,x_1y_2+x_2y_1)$
		\end{compactitem}
		Wie man nachpr\"ufen kann, ist $(\mathbb C,+,\cdot)$ ein K\"orper, genannt K\"orper der komplexen Zahlen.
		Da $(x_1,0)+(x_2,0)=(x_1+x_2,0)$ und $(x_1,0)\cdot (x_2,0)=(x_1x_2,0)$, k\"onnen wir $\mathbb R$ durch
		"$x=(x,0)$" mit dem Teilk\"orper $\mathbb R \times \{0\}$ von $\mathbb C$ identifizieren. \\
		Die imagin\"are Einheit $i=(0,1)$ erf\"ullt $i^2=-1$ und jedes $z \in \mathbb C$ kann eindeutig geschrieben
		werden als $z=x+iy$ mit $x,y \in \mathbb R$
		
		\begin{framed}
			\textbf{Lemma:} Sei $a \in \mathbb Z$ und sei $p$ eine Primzahl, die $a$ nicht teilt. Dann gibt es $b,k \in
			 \mathbb Z$ mit $ab+kp=1$.
		\end{framed}
		\textit{Beweis: \\
		Sei $n \in \mathbb N$ die kleinste nat\"urliche Zahl der Form $n=ab+kp$. Angenommen, $n \ge 2$. Schreibe
		$a=qp+r$ mit $q,r \in \mathbb Z$ und $0 \le r < p$. Aus der Nichtteilbarkeit von $a$ folgt $r \neq 0$, also 
		$r \in \mathbb N$. Wegen $r=a\cdot 1-qp$ ist $n\le r$. Da $p$ Primzahl ist und $2\le n\le r < p$, gilt $n$ teilt
		nicht $p$. Schreibe $p=c\cdot n+m$ mit $c,m \in \mathbb Z$ und $0 \le m<n$. Aus $n$ teilt nicht $p$ folgt
		$m \neq 0$, also $m \in \mathbb N$. Da $m=p-cn=-abc+(1-kc)p$, ist $m<n$ ein Widerspruch zur Minimalit\"at
		 von $n$. Die Annahme $n \ge 2$ war somit falsch. Es gilt $n=1$.} \\
		$\newline$
		
		\textbf{Beispiel (Endliche Primk\"orper)} \\
		F\"ur jede Primzahl $p$ ist $\mathbb Z /p \mathbb Z$ ein K\"orper. Ist $\overline{a}\neq \overline{0}$, so gilt 
		$p$ teilt nicht $a$ und somit gibt es $b,k \in \mathbb Z$ mit \\
		$ab+kp=1$ \\
		$\overline{(ab+kp)}=\overline{1} = \overline{(ab)} = \overline{a} \cdot \overline{b}$ \\
		und somit ist $\overline{a}$ invertierbar in $\mathbb Z /p \mathbb Z$. Somit sind f\"ur $n \in \mathbb N$
		\"aquivalent:
		\begin{compactitem}
			\item $\mathbb Z /n \mathbb Z$ ist ein K\"orper
			\item $\mathbb Z /n \mathbb Z$ ist nullteilerfrei
			\item $n$ ist Primzahl
		\end{compactitem}
		\textit{Beweis: 1 $\to$ 2: 4.13; 2 $\to$ 3: 4.12; 3 $\to$ 1: gegeben} \\
		Insbesondere ist $\mathbb Z /p \mathbb Z$ nullteilerfrei, d.h. aus $p$ teilt $ab$ folgt $p$ teilt $a$ oder
		$p$ teilt $b$
		
	\subsection{Polynome}
		In diesem Abschnitt sei $R$ ein kommutativer Ring mit Einselement. \\
		$\newline$
		
		\textbf{Bemerkung:} Unter einem Polynom in der "Unbekannte" $x$ versteht man einen Ausdruck der Form
		$f(x)=a_0+a_1x+a_2x^2+...+a_nx^n = \sum \limits_{k=0}^{n} a_kx^k$ mit $a_0,...,a_n \in R$. Fasst man $x$
		als ein beliebiges Element von $R$ auf, gelten einige offensichtliche Rechenregeln: \\
		Ist $f(x)=\sum \limits_{k=0}^{n} a_kx^k$ und $g(x)=\sum \limits_{k=0}^{n} b_kx^k$ so ist
		\begin{compactitem}
			\item $f(x)+g(x)=\sum \limits_{k=0}^{n} (a_k+b_k)x^k$
			\item $f(x)\cdot g(x)=\sum \limits_{k=0}^{2n} c_kx^k$ mit $c_k=\sum \limits_{j=0}^{k} a_jb_{k-j}$
		\end{compactitem}
		Dies motiviert die folgende pr\"azise Definition f\"ur den Ring der Polynome \"uber $R$ in einer "Unbestimmten"
		$x$.
		
		\begin{framed}
			\textbf{Definition Polynom:} Sei $R[X]$ die Menge der Folgen in $R$, die fast \"uberall 0 sind, also
			$R[X]:=\{(a_k)_{k \in \mathbb N_0} \mid \forall k(a_k \in R) \land \exists n_0: \forall k>n_0(a_k=0)\}$
		\end{framed}
		
		Wir definieren Addition und Multiplikation auf $R[X]$:
		\begin{compactitem}
			\item $(a_k)_{k \in \mathbb N_0}+(b_k)_{k \in \mathbb N_0}=(a_k+b_k)_{k \in \mathbb N_0}$
			\item $(a_k)_{k \in \mathbb N_0}\cdot (b_k)_{k \in \mathbb N_0}=(c_k)_{k \in \mathbb N_0}$ mit 
			$c_k = \sum \limits_{j=0}^{k} a_jb_{k-j}$
		\end{compactitem}
		$\newline$
		
		Mit diesen Verkn\"upfungen wird $R[X]$ zu einem kommutativen Ring mit Einselement. Diesen Ring nennt man
		Polynomring (in einer Variablen $X$) \"uber $R$. Ein $(a_k)_{k \in \mathbb N_0} \in R[X]$ hei{\ss}t Polynom mit
		den Koeffizienten $a_0,...,a_n$. Wenn wir $a \in R$ mit der Folge $(a,0,0,...,0) := (a,\delta_{k,0})_{k \in \mathbb N_0}$
		identifizieren, wird $R$ zu einem Unterrring von $R[X]$. 
		$\newline$
		
		Definiert man $X$ als die Folge $(0,1,0,..,0) := (\delta_{k,1})_{k \in \mathbb N_0}$ (die Folge hat an der $k$-ten 
		Stelle eine 1, sonst nur Nullen). Jedes $f(a_k)_{k \in \mathbb N_0}$ mit $a_k=0$ f\"ur $k>n_0$ l\"asst sich eindeutig
		schreiben als $f(X)=\sum \limits_{k=0}^{n_0} a_kX^k$.\\
		Alternativ schreiben wir auch $f=\sum \limits_{k \ge 0} a_kX^k$ mit dem Verst\"andnis, dass diese unendliche
		Summe nur endlich von 0 verschiedene Summanden enth\"alt.
		$\newline$
		
		Sei $0 \neq f(X)=\sum \limits_{k \ge 0} a_kX^k \in R[X]$. Der Grad von $f$ ist das gr\"o{\ss}te $k$ mit $a_k
		\neq 0$, geschrieben $deg(f):= max\{k \in \mathbb N_0 \mid a_k \neq 0\}$. Man definiert den Grad des
		Nullpolynoms als $deg(0)=-\infty$, wobei $-\infty < k \forall k \in \mathbb N_0$ gelten soll. Man nennt $a_0$
		den konstanten Term und $a_{deg(f)}$ den Leitkoeffizienten von $f$. Hat $f$ den Grad 0, 1 oder 2, so nennt
		man $f$ konstant, linear bzw. quadratisch.
		$\newline$
		
		\textbf{Beispiel:} Das lineare Polynom $f(X)=X-2 \in R[X]$ hat den Leitkoeffizent 1 und den konstanten Term $-2$.
		
		\begin{framed}
			\textbf{Satz:} Seien $f,g \in R[X]$
			\begin{compactitem}
				\item Es ist $deg(f+g)\le max\{deg(f), deg(g)\}$
				\item Es ist $deg(f\cdot g) \le deg(f)+deg(g)$
				\item Ist $R$ nullteilerfrei, so ist $deg(f\cdot g) = deg(f)+deg(g)$ und auch $R[X]$ ist nullteilerfrei.
			\end{compactitem}
		\end{framed}
		\textit{Beweis: \\
		\begin{compactitem}
			\item offenbar
			\item Ist $deg(f)=n$ und $deh(g)=m$, $f=\sum \limits_{i \ge 0} f_iX^i$, $g=\sum \limits_{ij\ge 0} g_jX^j$, 
			so ist auch $h=fg=\sum \limits_{k \ge 0} h_kX^k$ mit $h_k=\sum \limits_{i+j=k} f_i\cdot g_j$ f\"ur alle $k \ge 0$.
			Ist  $k>n+m$ und $i+j=k$, so ist $i>n$ oder $j>m$, somit $f_i=0$ oder $g_k=0$ und somit $h_k=0$. 
			Folglich ist $deg(h) \le n+m$.
			\item Ist $f=0$ oder $g=0$, so ist die Aussage klar, wir nehmen als $n,m \ge 0$ an. Nach b) ist $deg(h) \le 
			n+m$ und $h_{m+n}=\sum \limits_{i+j=n+m} f_ig_j=f_ng_m$. Ist $R$ nullteilerfrei, so folgt aus $f_n \neq 0$
			und $g_m\neq 0$ schon $f_ng_m\neq 0$, und somit $deg(h)=n+m$.
		\end{compactitem}}
		
		\begin{framed}
			\textbf{Theorem (Polynomdivision):} Sei $K$ ein K\"orper und sei $0 \neq g \in K[X]$. F\"ur jedes Polynom
			 $f \in K[X]$ gibt es eindeutig bestimmte $g,h,r \in K[X]$ mit $f=gh+r$ und $deg(r)<deg(g)$. 
		\end{framed}
		\textit{Beweis: Existenz und Eindeutigkeit\\
		Existenz: Sei $n=deg(f)$, $m=deg(g)$, $f=\sum \limits_{k=0}^{n} a_kX^k$, $g=\sum \limits_{k=0}^{m} b_kX^k$ \\
		Induktion nach $n$ bei festem $g$. \\
		IA: Ist $n<m$, so w\"ahlt man $h=0$ und $r=f$.\\
		IB: Wir nehmen an, dass die Aussage f\"ur alle Polynome vom Grad kleiner als $n$ gilt.\\
		IS: Ist $n \ge m$, so betrachtet man $f_1=f-\frac{a_n}{b_m}\cdot X^{n-m}\cdot g(X)$. Da $\frac{a_n}{b_m}\cdot 
		X^{n-m}\cdot g(X)$ ein Polynom vom Grad $n-m+deg(g)=n$ mit Leitkoeffizient $\frac{a_n}{b_m}\cdot b_m=a_n$ ist, ist
		$deg(f_1)<n$. Nach IB gibt es also $h_1, r_1 \in K[X]$ mit $f_1=gh_1+r_1$ und $deg(r)<deg(g)$. Somit ist 
		$f(X)=f_1(X)+\frac{a_n}{b_m}\cdot X^{n-m}\cdot g(X)=gh+r$ mit $h(X)=h_1(X)+\frac{a_n}{b_m}\cdot X^{n-m}, r=r_1$. \\
		Eindeutigkeit: Sei $n=deg(f), m=deg(g)$. Ist $f=gh+r=gh'+r'$ und $deg(r),deg(r')<m$, so ist $(h-h')g=r'-r$ und
		$deg(r'-r)<m$. Da $deg(h-h')=deg(h'-h)+m$ muss $deg(h-h')<0$, also $h'-h=0$ sein. Somit $h'=h$ und $r'=r$} \\
		$\newline$
		
		\textbf{Bemerkung:} Der Existenzbeweis durch Induktion liefert uns ein konstruktives Verfahren, diese sogenannte
		 Polynomdivision durchzuf\"uhren. \\
		$\newline$
		
		\textbf{Beispiel:} in $\mathbb Q[X]$: $(x^3+x^2+1):(x^2+1)=x+1$ Rest $-x$ \\
		
		\begin{framed}
			\textbf{Definition Nullstelle:} Sei $f(X)=\sum \limits_{k \ge 0} a_kX^k \in \mathbb R[X]$. F\"ur $\lambda \in
			\mathbb R$ definiert man die Auswertung von $f$ in $\lambda$ $f(\lambda)=\sum \limits_{k \ge 0} a_k\lambda^k
			\in \mathbb R$. Das Polynom $f$ liefert auf diese Weise eine Abbildung $\tilde f: \mathbb R \to \mathbb R$ und
			$\lambda \mapsto f(\lambda)$. \\
			Ein $\lambda \in \mathbb R$ $f(\lambda)=0$ ist eine Nullstelle von $f$
		\end{framed}
		
		\begin{framed}
			\textbf{Lemma:} F\"ur $f,g \in \mathbb R[X]$ und $\lambda \in \mathbb R$i ist $(f+g)(\lambda)=f(\lambda)+
			g(\lambda)$ und $(fg)(\lambda)=f(\lambda) \cdot g(\lambda)$.
		\end{framed}
		\textit{Beweis: Ist $f=\sum \limits_{k \ge 0} a_kX^k$ und $g=\sum \limits_{k\ge 0} b_kX^k$, so ist \\
		$f(\lambda)+g(\lambda)=\sum \limits_{k \ge 0} a_k\lambda^k + \sum \limits_{k\ge 0} b_k\lambda^k = \sum 
		\limits_{k\ge 0} (a_k+b_k)\lambda^k=(f+g)(\lambda)$ \\
		$f(\lambda)\cdot g(\lambda)= \sum \limits_{k\ge 0} a_k\lambda^k \cdot \sum \limits_{k\ge 0} b_k\lambda^k = 
		\sum \limits_{k \ge 0} \sum \limits_{i+j=k} (a_i+b_j)\lambda^k = (fg)(\lambda)$)}
		
		\begin{framed}
			\textbf{Satz:} Ist $K$ ein K\"orper und $\lambda \in K$ eine Nullstelle von $f \in K[X]$ so gibt es ein
			eindeutig bestimmtes $h \in K[X]$ mit $f(X)=(X-\lambda)\cdot h(x)$
		\end{framed}
		\textit{Beweis: \\
		Es gibt $h,r \in K[X]$ mit $f(X)=(X-\lambda)\cdot h(x)+r(x)$ und $deg(r)<deg(X-\lambda)=1$, also $r \in
		K$. Da $\lambda$ Nullstelle von $f$ ist, gilt $0=f(\lambda)=(\lambda-\lambda)*h(\lambda)+r(\lambda)=
		r(\lambda)$. Hieraus folgt $r=0$. Eindeutigkeit folgt aus Eindeutigkeit der Polynomdivision.}
		
		\begin{framed}
			\textbf{Korollar:} Sei $K$ ein K\"orper. Ein Polynom $0\neq f \in K[X]$ hat h\"ochstens $deg(f)$ viele
			Nullstellen.
		\end{framed}
		\textit{Beweis: \\
		Induktion nach $deg(f)=n$ \\
		Ist $n=0$, so ist $f \in K^{\times}$ und hat somit keine Nullstellen. \\
		Ist $n>0$ und hat f eine Nullstelle $\lambda \in K$, so ist $f(X)=(X-\lambda)*h(x)$ mit $h(x) \in K[X]$ und
		$deg(f)=deg(X-\lambda)+deg(h)=n-1$. Nach IV besitzt $h$ h\"ochstens $deg(h)=n-1$ viele Nullstellen. Ist
		$\lambda'$ eine Nullstelle von $f$, so ist $0=f(\lambda’)=(\lambda’-\lambda)*h(\lambda’)$, also $\lambda'=
		\lambda$ oder $\lambda'$ ist Nullstelle von $h$. Somit hat $f$ h\"ochstens $n$ viele Nullstellen in $K$.}
		
		\begin{framed}
			\textbf{Korollar:} Ist $K$ ein unendlicher K\"orper, so ist die Abbildung $K[X] \to Abb(K,K)$ und $f \mapsto
			\tilde f$ injektiv.
		\end{framed}
		\textit{Beweis: \\
		Sind $f,g \in K[X]$ mit $\tilde f = \tilde g$, also $f(\lambda)=g(\lambda)$ f\"ur jedes $\lambda \in K$, so ist
		jedes $\lambda$ Nullstelle von $h:= f-g \in K[X]$. Da $|K|=\infty$ ist, so ist $h=0$, also $f=g$.}
		$\newline$
		
		\textbf{Bemerkung:} Dieses Korollar besagt uns, dass man \"uber einem unendlichen K\"orper Polynome als
		polynomiale Abbildungen auffassen kann. Ist $K$ aber endlich, so ist dies im Allgemeinen nicht richtig.
		Beispiel: $K=\mathbb Z\backslash 2\mathbb Z$, $f(X)=X$, $g(X)=X^2 \Rightarrow f \neq g$, aber 
		$\tilde f=\tilde g$.
		$\newline$
		
		\textbf{Beispiel:} Sei $f(X)=X^2+1 \in \mathbb R[X] \subset \mathbb C[X]$ \\
		In $K=\mathbb R$ hat $f$ keine Nullstelle: Für $\lambda \in \mathbb R f(\lambda)=\lambda^2+1 \ge1 >0$. \\
		In $K=\mathbb C$ hat $f$ die beiden Nullstellen $\lambda_1=i$ und $\lambda_2=-i$ und zerfällt dort in Linearfaktoren:
		 $f(X)=(X-i)(X+i)$.
		
		\begin{framed}
			\textbf{Satz:} Für einen Körper $K$ sind äquivalent:
			\begin{compactitem}
				\item Jedes Polynom $f \in K[X]$ mit $deg(f)>0$ hat eine Nullstelle in $K$.
				\item Jedes Polynom $f \in K[X]$ zerfällt in Linearfaktoren, also $f(X)=a\cdot \prod \limits_{i=1}^n 
				(X-\lambda_i)$ mit $n=deg(f), a, \lambda_i \in K$
			\end{compactitem}
		\end{framed}
		\textit{Beweis: \\
		$1 \Rightarrow 2:$ Induktion nach $n=deg(f)$ \\
		Ist $n\le0$, so ist nichts zu zeigen. \\
		Ist $n>0$, so hat $f$ eine Nullstelle $\lambda_n \in K$, somit $f(X)=(X-\lambda_n)\cdot g(X)$ mit $g(X) \in K[X]$
		 und $deg(g)=n-1$, Nach IV ist $g(X)=a\cdot \prod \limits_{i=1}^n (X-\lambda_i)$. Somit ist $f(X)=a\cdot \prod 
		\limits_{i=1}^n (X-\lambda_i)$. \\
		$2 \Rightarrow 1:$ Sei $f \in K[X]$ mit $n=deg(f)>0$. Damit gilt $f(X)=a\cdot \prod \limits_{i=1}^n (X-\lambda_i)$.
		Da $n>0$, hat $f$ z.B. die Nullstelle $\lambda_1$.}
		
		\begin{framed}
			\textbf{Definition algebraisch abgeschlossen:} Ein Körper $K$ heißt algebraisch abgeschlossen, wenn er eine 
			der äquivalenten Bedingungen erfüllt. 
		\end{framed}
		
		\begin{framed}
			\textbf{Theorem (Fundamentalsatz der Algebra):} Der Körper $\mathbb C$ ist algebraisch abgeschlossen.
		\end{framed}
		
		\textbf{Bemerkung:} Wir werden das Theorem zwar benutzen, aber nicht beweisen.
		
\section{Vektorräume}
	In diesem Kapitel sei $K$ ein Körper.
	\subsection{Definition und Beispiele}
		\textbf{Beispiel:} Ist $K=\mathbb R$, so haben wir für $K^3=\mathbb R^3=\mathbb R \times \mathbb R \times \mathbb R=
		\{(a,b,c) | a,b,c \in \mathbb R\}$ eine geometrische Anschauung, nämlich den euklidischen Raum. Welche algebraische 
		Struktur können wir hierauf sinnvollerweise definieren? \\
		
		\begin{framed}
			\textbf{Definition $K$-Vektorraum:} Ein $K$-Vektorraum (auch Vektorraum über $K$) ist ein Tripel $(V,+,\cdot)$ 
			bestehend aus einer Menge $V$, einer Verknüpfung $+: V \times V \to V$, genannt Addition, und einer Abbildung 
			$\cdot: K \times V \to V$, genannt Skalarmultiplikation, für die gelten: \\
			(V1): $(V,+)$ ist eine abelsche Gruppe \\
			(V2): Addition und Skalarmultiplikation sind verträglich:
			\begin{compactitem}
				\item $\lambda(x+y)=(\lambda\cdot x)+(\lambda\cdot y)$
				\item $(\lambda+\mu)\cdot x = (\lambda\cdot x)+(\mu\cdot x)$
				\item $\lambda(\mu\cdot x)=(\lambda\cdot\mu)\cdot x$
				\item $1\cdot x = x$
			\end{compactitem}
		\end{framed}
		
		\textbf{Bemerkung:} Wir haben sowohl im Körper $K$ als auch im Vektorraum $V$ eine Addition definiert, die wir mit 
		dem selben Symbol $+$ notieren. Ebenso benutzen wir das Symbol $\cdot$ sowohl für die Multiplikation im Körper $K$ 
		als auch für die Skalarmultiplikation. Zur Unterscheidung nennt man die Elemente von $V$ Vektoren und die Elemente 
		von $K$ Skalare. Wir werden bald auch den Nullvektor mit 0 bezeichnen, also mit dem selben Symbol wie das neutrale 
		Element im Körper $K$. Auch für Vektorräume gibt es notationelle Konvektionen: So bindet die Skalarmultiplikation 
		stärker als die Addition und wird manchmal nicht notiert. \\
		$\newline$
		
		\textbf{Beispiel:} Für $n \in \mathbb N$ ist $V=K^n := \prod \limits_{i=1}^n K = \{(x_1,x_2,...,x_n) \mid x_1,x_2,..,
		x_n \in K\}$ mit komponentenweiser Addition und Skalarmultiplikation $\lambda(x_1,...,x_n)=(\lambda\cdot x_1,...,
		\lambda\cdot x_n)$ ein $K$-Vektorraum, genannt der (n-dimensionale) Standardraum über $K$. \\ 
		Insbesondere (Spezialfall $n=1$) ist $K$ ein $K$-Vektorraum. \\
		Für $n=0$ definiert man $K^0$ als Nullraum $V=\{0\}$, der einzig möglichen Addition und Skalarmultiplikation einen 
		$K$-Vektorraum bildet.
		
		\begin{framed}
			\textbf{Satz:} Ist $V$ ein $K$-Vektorraum, so gelten für $\lambda \in K$ und $x \in V$:
			\begin{compactitem}
				\item $0\cdot x =0$
				\item $\lambda\cdot =0$
				\item $(-\lambda)\cdot x = \lambda\cdot(-x) = -\lambda\cdot x$. Insbesondere $(-1)x=-x$
				\item Ist $\lambda\cdot x=0$, so ist $\lambda=0$ oder $x=0$
			\end{compactitem}
		\end{framed}
		\textit{Beweis: \\
		\begin{compactitem}
			\item Es ist $0\cdot x=(0+0)\cdot x=0\cdot x+0\cdot x$, woraus $0=0\cdot x$
			\item Es ist $\lambda\cdot 0=\lambda(0+0)=\lambda\cdot 0+0\cdot \lambda$, woraus $0=\lambda\cdot 0$
			\item Es ist $\lambda\cdot x+(-\lambda\cdot x)=(\lambda+(-\lambda))\cdot x=0\cdot x=0$, also $(-\lambda)x=-(\lambda 
			x)$
			\item Ist $\lambda\cdot x=0$ und $\lambda\neq 0$, so ist $0=\lambda^{-1}\cdot\lambda\cdot x=1\cdot x=x$ 
		\end{compactitem}}
		$\newline$
		
		\textbf{Beispiele:}
		\begin{compactitem}
			\item Schränkt man die Multiplikation im Polynomring $K[X] \times K[X] \to K[X]$ zu einer Abbildung $K \times K[X]
			\to K[X]$ ein, so wird $K[X]$ mit dieser Skalarmultipliaktion zu einem $K$-VR. Die Skalarmultiplikation ist also
			gegen $\lambda\cdot \sum \limits_{k\ge 0} a_k\cdot X^k = \sum \limits_{k\ge 0} \lambda\cdot a_k\cdot X^k$ ersetzt
			wurden.
			\item Schränkt man die komplexe MUltiplikation $\mathbb C \times \mathbb C \to \mathbb C$ zu einer Abbildung 
			$\mathbb R \times \mathbb C \to \mathbb C$ ein, so wird $\mathbb C$ mit dieser Skalarmultipliaktion zu einem
			$\mathbb R$-VR. Die Skalarmultipliaktion ist gegeben durch $\lambda(x+iy)=\lambda\cdot x + i\cdot\lambda\cdot y$.
			\item Verallgemeinerung von 1 und 2: Ist der Körper $K$ ein Unterring eines kommutativen Rings $R$ mit Einselement 
			$1_K \in K$, so wird $R$ durch Einschränkung der Multiplikation $R \times R \to R$ zu einer Abbildung $K \times R
			\to R$ zu einem $K$-VR.
			\item Ist $X$ eine Menge, so wird die Menge der Abbildungen $Abb(X,K)$ durch punktweise Addition $(f+g)(x)=f(x)+
			g(x)$ und die Skalarmultiplikation $(\lambda\cdot f)(x)=\lambda\cdot f(x)$ zu einem $K$-VR. Im Spezialfall
			$X=\{1,2,...,n\}$ erhält man den Standardraum $K^n$.
		\end{compactitem}
		
		\begin{framed}
			\textbf{Definition Untervektorraum:} Sei $V$ ein $K$-VR. Ein Untervektorraum (UVR) von $V$ ist eine nichtleere
			Teilmenge $W \subset V$ mit: \\
			(UV1): Für $x,y \in W$ ist $x+y\in W$ \\
			(UV2): Für $x \in W$ und $\lambda \in K$ ist $\lambda\cdot x\in W$
		\end{framed}
		
		\begin{framed}
			\textbf{Satz:} Sei $V$ ein $K$-VR und $W \subset V$. Genau dann ist $W$ ein UVR von $V$, wenn $W$ mit geeigneter
			Einschränkung der Addition und Skalarmultiplikation wieder ein $K$-VR ist.
		\end{framed}
		\textit{Beweis: \\
		Rückrichtung: Lassen sich $+$: $V \times V \to V$ und $\cdot$: $K \times V \to V$ einschränken zur Abbildung $+_w$: $W
		\times W \to W$, $\cdot_w$: $K \times W \to W$ so gilt für $x,y \in W$ und $\lambda \in K$: $x+y=x +_w y \in W$ und
		$\lambda\cdot x?\lambda \cdot_w x \in W$. ISt $(W,+_w,\cdot_w)$ ein $K$-VR, so ist insbesodere $W$ nicht leer. Somit
		ist $W$ ein UVR. \\
		Hinrichtung: Nach (UV1) und (UV2) lassen sich $+$ und $\cdot$ einchränken zu Abbildungen $+_w$: $W \times W \to W$ und 
		$\cdot_w$: $K \times W \to W$. Nach (UV1) ist abgeschlossen und unter der Addition und für $x \in W$ ist auch $-x=
		(-1)x \in W$ nach (UV2), $W$ ist somit Untergruppe von $(V,+)$. Insbesondere ist $(W,+)$ eine abelsche Gruppe, erfüllt 
		also (V1). Die Verträglichkeit (V2) ist für $\lambda,\mu \in K$ und $x,y \in W$ gegeben, da sie auch für $x,y \in V$ 
		erfüllt ist. Somit ist $(W,+_w,\cdot_w)$ ein $K$-VR.}
		$\newline$
		
		\textbf{Beispiele:}
		\begin{compactitem}
			\item Jder $K$-VR hat triviale UVR $W=\{0\}$ und $W=V$
			\item Ist $V$ ein $K$-VR und $x \in V$, so ist $W=K\cdot x=\{\lambda\cdot x \mid \lambda \in K\}$ ein UVR von $V$. 
			Insbesondere besitzt z.B. der $\mathbb R$-VR $\mathbb R^2$ unendlich viele UVR, nämlich alle Ursprungsgeraden. Hieran 
			sehen wir auch, dass die Vereinigung zweier UVR im Allgemeinen kein UVR ist. $\mathbb R\cdot (1,0) \cup \mathbb 
			R\cdot (1,0) \subset \mathbb R^2$ verletzt (UV1).
			\item Der $K$-VR $K[X]$ hat unter anderem die folgenden UVR: \\
			- Den Raum $K$ der konstanten Polynome \\
			- Den Raum $K[X]_{\le 1}=\{aX+b \mid a,b \in K\}$ der linearen (oder konstanten) Polynome \\
			- allgemeiner den Raum $K[X]_{\le n}=\{f \in K[X] \mid deg(f) \le n\}$ der Polynome von höchstens Grad $n$
			\item In der Analysis werden Sie verschiedene UVR des $\mathbb R$-VR $Abb(\mathbb R,\mathbb R)$ kennenlernen, etwa
			den Raum $\mathcal C(\mathbb R,\mathbb R)$ der stetigen Funktionen und den Raum $\mathcal C^{-1}(\mathbb R,\mathbb 
			R)$ der stetig differenzierbaren Funktionen. Die Menge der Polynofunktionen $\{\tilde f: f\in \mathbb R[X]\}$ bildet
			einen UVR des $\mathbb R$-VR $\mathcal C^{-1}(\mathbb R,\mathbb R)$
		\end{compactitem}
		
		\begin{framed}
			\textbf{Lemma:} Ist $V$ ein Vektorraum und $(W_i)_{i \in I}$ eine Familie von UVR von $V$, so ist auch $W=\bigcap W_i$ 
			ein UVR von $V$
		\end{framed}
		\textit{Beweis: \\
		Da $0 \in W_i$ ist auch $0 \in W$, insbesondere $W\neq\emptyset$.
		\begin{compactitem}
			\item (UV1): Sind $x,y \in W$, so ist auch $x,y \in W_i$ und deshalb $x+y\in \bigcap W_i = W$
			\item (UV2): Ist $x \in W$ und $\lambda \in K$, so ist auch $x \in W_i$ und somit $\lambda x\in \bigcap W_i=W$
		\end{compactitem}}
		
		\begin{framed}
			\textbf{Satz:} Ist $V$ ein $K$-VR und $X \subset V$, so gibt es einen eindeutig bestimmten kleinsten UVR $W$ von $V$
			mit $X \subset W$.
		\end{framed}
		\textit{Beweis: \\ Sei $\mathcal V$ die Menge aller UVR von $X$, die $X$ enthalten. Sei $W=\bigcap \mathcal V$. Damit ist 
		$W$ ein UVR von $V$ der $X$ enthält.}
		
		\begin{framed}
			\textbf{Definition Erzeugendensystem:} Ist $V$ ein $K$-VR und $X\subset V$, so nennt man den kleinsten UVR von 
			$V$, der $X$ enthält den von $X$ erzeugten UVR von $V$ und bezeichnet diesen mit $<X>$. Eine Mengen $X\subset V$ 
			mit $<X>=V$ heißt Erzeugendensystem von $V$. Der VR $V$ heißt endlich erzeugt, wenn er ein endliches Erzeugendensystem 
			besitzt.
		\end{framed}
		
	\subsection{Linearkombination und lineare Abhängigkeit}
		Sei $V$ ein $K$-VR.
		
		\begin{framed}
			\textbf{Definition Linearkombination:}
			\begin{compactitem}
				\item Sei $n \in \mathbb N_0$. Ein $x \in V$ ist eine Linearkombination eines n-Tupels $(x_1,...,x_n)$ von 
				Elementen von $V$, wenn es $\lambda_1,...,\lambda_n \in K$ gibt mit $x=\lambda_1\cdot x_1,...,\lambda_n \cdot
				x_n$. Der Nullvektor ist stets eine Linearkombination von $(x_1,...,x_n)$ auch wenn $n=0$.
				\item Ein $x\in V$ ist eine Linearkombination einer Familie $(x_i)$ von Elementen von $V$, wenn es $n \in \mathbb
				N_0$ und $i_1,...,i_n \in I$ gibt, für die x Linearkombination von $(x\cdot i_1,...,x\cdot i_n)$ ist.
				\item Die Menge aller $x \in V$, die Linearkombination von $\mathcal F=(x_i)$ sind, wird mit $span_K(\mathcal F)$ 
				bezeichnet.
			\end{compactitem}
		\end{framed}
		
		\textbf{Bemerkungen:}
		\begin{compactitem}
			\item Offenbar hängt die Menge der Linearkombinationen von $(x_1,...,x_n)$ nicht von der Reihenfolge der $x_i$ ab. 
			Wegen (V2)(ii) hängt sie sogar nur von der Menge $\{x_1,...,x_n\}$ ab.
			\item Deshalb stimmt 2. für endliche Familien $(x_1,...,x_n)$ mit 1. überein.
			\item Auch die Menge der Linearkombinationen einer Familie $\mathcal F=(x_1,...,x_n)$ hängt nur von der Menge $X=
			\{x_i \mid i \in I\}$ ab. Man sagt deshalb auch, $x$ ist Linearkombination von $X$ und schreibt $span_K(X)=span_K(
			\mathcal F)$, also $span_K(X)=\{\sum \limits_{i=1}^n \lambda_i\cdot n_i \mid n \in \mathbb N_0, x_i \in X, \lambda_1,
			...,\lambda_n \in K\}$. Nach Definition in $0 \in span_K(X)$ auch für $X=\emptyset$.
			\item Wie schon bei Polynomen schreibt man hier gerne formal unendliche Summen $x=\sum\limits_{i \in I} \lambda_i
			\cdot x_i$, bei denen nur endlich viele $\lambda_i$ von 0 verschieden sind.
		\end{compactitem}
		
		\begin{framed}
			\textbf{Lemma:} Für jede Teilmenge $X \subset V$ ist $span_K(X)$ ein UVR von $V$.
		\end{framed}
		\textit{Beweis: \\ 
		\begin{compactitem}
			\item Sei $W=span_K(X)$. Nach Definition ist $0 \in W$, insbesondere $W\neq\emptyset$
			\item (UV1): Sind $x,y \in W$, also $x=\lambda_1\cdot x+...+\lambda_n\cdot x_n$ und $y=\mu_1\cdot x+...+
			\mu_n\cdot x_n$, so ist $x+y=(\lambda_1+\mu_1)x_1+...+(\lambda_n+\mu_n)x_n \in W$
			\item (UV2): Ist $\lambda \in K$ und $x \in W$, so ist $\lambda x=\lambda\cdot\sum\limits_{i=1}^n \lambda_i\cdot x_i=
			\sum\limits_{i=1}^n (\lambda\cdot\lambda_i)x_i \in W$
		\end{compactitem}}
		
		\begin{framed}
			\textbf{Satz:} Für jede Teilmenge $X \subset V$ ist $span_K(X)=<X>$.
		\end{framed}
		\textit{Beweis: \\ 
		\begin{compactitem}
			\item $span_K(X)$ ist UVR von $V$, der wegen $x=x\cdot 1$ die Menge $X$ enthält, und $<X>$ ist der kleinste solche.
			\item Ist $W\subset V$ ein UVR von $V$, der $X$ enthält, so enthält er auch wegen (UV2) alle Elemente der Form 
			$\lambda\cdot x$, und wegen (UV1) dann auch alle Linearkombinationen aus $X$. Insbesondere gilt dies auch für $W=<X>$
		\end{compactitem}}
		$\newline$
		
		\textbf{Bemerkung:} Wir erhalten $span_K(X)=<X>$ auf 2 verschiedenen Wegen. Erstens "von oben" als Schnitt über alle UVR 
		von $V$, die $X$ enthalten und zweitens "von unten" als Menge der Linearkombinationen. Man nennt $span_K(X)$ auch den 
		von $X$ aufgespannten UVR oder die lineare Hülle von $X$. \\
		$\newline$
		
		\textbf{Beispiele:}
		\begin{compactitem}
			\item Sei $V=K^n$ der Standardraum. Für $i=1,...,n$ sei $e_i=(\delta_{i,1},...,\delta_{i,n})$, also $e_1=(1,0,...0)$, 
			$e_2=(0,1,0,...,0),...,e_n=(0,...,1)$. Für $x=(x_1,...,x_n) \in V$ ist $x=\sum\limits_{i=1}^n x_i\cdot e_1$, folglich 
			$span_K(_1,..,e_n)=V$. Insbesondere ist $K^n$ eindeutig erzeugt. Man nennt $(e_1,...,e_n)$ die Standardbasis des 
			Standardraums $K^n$.
			\item Sei $V=K[X]$ Polynomring über $K$. Da $f=\sum\limits_{i=1}^n a_i\cdot X^i$ ist $span_K((X^i)_{i \in I})=K[X]$. 
			Genauer ist $span_K(1,X,X^2,...,X^n)=K[X]_{\le n}$. Tatsächlich ist der $K$-VR $K[X]$ nicht endlich erzeugt. Sind 
			$f_1,...,f_r \in K[X]$ und ist $d=max\{deg(f_1),...,deg(f_r)\}$, so sind $f_1,...,f_r \in K[X]_{\le d}$ und somit 
			$span_K(f_1,...,f_r) \subset K[X]_{\le d}$, aber es gibt Polynome, deren Grad größer $d$ ist.
			\item Für $x \in V$ ist $<x>=span_K(x)=K\cdot x$. Im Fall $K=\mathbb R$, $V=\mathbb R^3$, $x\neq 0$ ist dies eine 
			Ursprungsgerade.
			\item Im $\mathbb R$-VR $\mathbb C$ ist $span_{\mathbb R}(1)=\mathbb R\cdot 1=\mathbb R$, aber im $\mathbb C$-VR 
			$\mathbb C$ ist $span_{\mathbb C}(1)=\mathbb C\cdot 1=\mathbb C$
		\end{compactitem}
		
		\begin{framed}
			\textbf{Definition linear (un)abhängig:}
			\begin{compactitem}
				\item Sei $n\in \mathbb N_0$. Ein $n$-Tupel $(x_1,...,x_n)$ von Elementen von $V$ ist linear abhängig, wenn es 
				$\lambda_1,...,\lambda_n \in K$ gibt, die nicht alle 0 sind und $\lambda_1\cdot x_1+...+\lambda_n\cdot x_n=0$ (*) 
				erfüllen. Andernfalls heißt das Tupel linear unabhängig.
				\item Eine Familie $(x_i)$ von Elementen von $V$ ist linear abhängig, wenn es $n\in \mathbb N_0$ und paarweise 
				verschiedene $i_1,...,i_n \in I$ gibt, für die $(x_{i_1},...,x_{i_n})$ linear abhängig ist. Andernfalls linear 
				unabhängig.
			\end{compactitem}
		\end{framed}
		
		\textbf{Bemerkungen:}
		\begin{compactitem}
			\item Offenbar hängt die Bedingung (*) nicht von der Reihenfolge der $x_1,...,x_n$ ab und ist $(x_1,...,x_k)$ linear 
			abhängig für ein $k \le n$, so ist auch $(x_1,...,x_n)$ linear abhängig. Deshalb stimmt die 2. Definition für 
			endliche Familien mit der 1. überein und $(x_i)$ ist genau dann linear abhängig, wenn es eine endliche Teilmenge 
			$J \subset I$ gibt, für die $(x_j)$ linear abhängig ist.
			\item Eine Familie ist genau dann linear unabhängig, wenn für jede endliche Teilmenge $J\subset I$ und für jede 
			Wahl an Skalaren $(\lambda_i)_{i\in J}$ aus $\sum \lambda_i\cdot x_i=0$ schon $\lambda_i=0$ folgt, also wenn sich 
			der Nullvektor nur trivial linear kombinieren lässt. 
		\end{compactitem}
		
		\begin{framed}
			\textbf{Satz:} Genau dann ist $(x_i)$ linear abhängig, wenn es $i_0 \in I$ gibt mit $x_{i_0} \in span_K((x_i)_{i\in 
			I\backslash\{i_0\}})$. In diesem Fall ist $span_K((x_i)_{i\in I})=span_K((x_i)_{i\in I\backslash\{i_0\}})$.
		\end{framed}
		\textit{Beweis: Es reicht, die Aussage für $I=\{1,...,n\}$ zu beweisen.\\
		Hinrichtung: Ist $(x_1,...,x_n)$ linear anhängig, so existieren $\lambda_1,...,\lambda_n$ mit $\sum\limits_{i=1}^n 
		\lambda_i\cdot x_i=0$. oBdA sei $\lambda_n\neq 0$. Dann ist $x_n=\lambda_n^{-1}\cdot\sum\limits_{i=1}^{n-1} \lambda_i
		\cdot x_i=\sum\limits_{i=1}^{n-1} \lambda_n^{-1}\cdot\lambda_i\cdot x_i \in span_K(x_1,...,x_n)$. \\
		Rückrichtung: oBdA. $i_0=n$, also $\sum\limits_{i=0}^{n-1} \lambda_i\cdot x_i$. Mit $\lambda_n=-1$ ist $\sum
		\limits_{i=1}^n \lambda_i\cdot x_i=0$, was zeigt, dass $(x_1,...,x_n)$ linear abhängig ist. \\
		Sei nun $x_n=\sum\limits_{i=1}^{n-1} \lambda_i\cdot x_i \in span_K(x_1,...,x_{n-1})$. Wir zeigen, dass $span_K(x_1,...,
		x_{n-1})=span_K(x_1,...,x_n)$
		\begin{compactitem}
			\item klar, da bei mehr Elementen die Anzahl der Linearkombinationen nicht abnimmt
			\item Ist $y=\sum\limits_{i=1}^n \mu_i\cdot x_i \in span_K(x_1,...,x_n)$, so ist $y=\sum\limits_{i=1}^{n-1} \mu_i+
			\mu_n\cdot \lambda_i\cdot x_i \in span_K(x_1,...,x_n)$
		\end{compactitem}}
		
		\begin{framed}
			\textbf{Satz:} Genau dann ist $(x_i)$ linear unabhängig, wenn sich jedes $x\in span_K((x_i))$ in eindeutiger Weise 
			als Linearkombination der $(x_i)$ schreiben lässt, d.h. $x=\sum\limits_{i\in I} \lambda_i\cdot x_i=\sum\limits_{i
			\in I} \lambda'_i\cdot x_i$, so ist $\lambda_i=\lambda'_i$
		\end{framed}
		\textit{Beweis: Es reicht, die Aussage für $I=\{1,...,n\}$ zu beweisen.\\
		Hinrichtung:  Ist $(x_,...,x_n)$ linear unabhängig und $x=\sum\limits_{i\in I} \lambda_i\cdot x_i=\sum\limits_{i\in I}
		 \lambda'_i\cdot x_i$, so folgt daraus $\sum\limits_{i\in I} (\lambda_i-\lambda'_i)x_i=0$ wegen der linearen 
		 Unabhängigkeit der $x_i$, dass $\lambda_i=\lambda'_i=0$\\
		Rückrichtung: Lässt sich jedes $x\in span_K(x_1,...,x_n)$ in eindeutiger Weise als Linearkombination der $x_i$ schreiben, 
		so gilt dies insbesondere für $x=0$. Ist also $\sum\limits_{i=1}^n \lambda_i\cdot x_i=0$, so folgt schon $\sum\limits_{
		i=1}^n 0\cdot x_i=0$ schon $\lambda_i=0$}
		$\newline$
		
		\textbf{Beispiele:}
		\begin{compactitem}
			\item Die Standardbasis $(e_1,...,e_n)$ des $K^n$ ist linear unabhängig. Es ist $\sum\limits_{i=1}^n \lambda_i\cdot 
			e_i=(\lambda_i,...,\lambda_n)$
			\item Im $K$-VR $K[X]$ sind die Monome $(X^i)$ linear unabhängig.
			\item Ein einzelner Vektor $x\in V$ ist genau dann linear abhängig, wenn $x=0$.
			\item Ein Paar $(x_1,x_2)$ von Elementen von $V$, wenn es ein skalares Vielfaches des anderen ist, also z.B. $x_1=
			\lambda\cdot x_2$.
			\item Im $\mathbb R$-VR $\mathbb R^2$ sind die beiden Vektoren $(1,2)$ und $(2,1)$ linear unabhängig. \\
			Im $\mathbb Z\backslash 3\mathbb Z$-VR $(\mathbb Z\backslash 3\mathbb Z)^2$ sind diese Vektoren linear unabhängig, da 
			$x_1+x_2=(1,2)+(2,1)=(3,3)=(0,0)=0$. 
			\item Im $\mathbb R$-VR $\mathbb C$ ist $(1,i)$ linear unabhängig, aber im $\mathbb C$-VR $\mathbb C$ ist $(1,i)$ 
			linear abhängig, denn $\lambda_1\cdot 1+\lambda_2\cdot i =0$ für $\lambda_1=1$ und $\lambda_2=i$.
		\end{compactitem}
		$\newline$
		
		\textbf{Bemerkungen:}
		\begin{compactitem}
			\item Ist $x_{i_0}=0$, ist $(x_i)$ linear abhängig: $1\cdot x_{i_0}=0$
			\item Gibt es $i,j\in I$ mit $i\neq j$, aber $x_i=x_j$, so ist $(x_i)$ linear abhängig: $x_i-x_j=0$
			\item Dennoch sagt man auch "die Teilmenge $X\subset V$ ist linear abhängig" und meint damit, dass die Familie $(x_x)
			_{x\in X}$ linear abhängig ist, d.h. es gibt ein $n\in \mathbb N_0$, $x_1,...,x_n \in X$ paarweise verschieden, mit 
			$\sum\limits_{i=1}^n \lambda_i\cdot x_i=0$.
		\end{compactitem}
		
	\subsection{Basis und Dimension}
\end{document}
