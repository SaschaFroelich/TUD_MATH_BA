\setcounter{dummy}{16}
\addtocounter{section}{15}
\addtocounter{chapter}{4}

\chapter{Differentiation}
	Differentiation ist lokale Linearisierung.

\section{Wiederholung und Motivation}
	\begin{ueberblick}
	$K^n$ ist ein $n$-dimensionaler VR über dem vollständigen Körper $K=\real$ 
	oder $K=\comp$. Die Elemente sind $x=(x_1,...,x_n)\in K^n$ mit 
	$x_1,...,x_n\in K$. Basis ist die Standardbasis $(e_1,...,e_n)$. \\
	
	
	Alle Normen sind auf $K^n$ äquivalent $\Rightarrow$ Konvergenz ist 
	unabhängig von der Norm. Trotzdem verwenden wir die euklidische Norm: 
	$|x|=\sqrt{\sum\limits_{j=1}^n |x_j|^2}$. \\
	
	
	\underline{Skalarprodukt:} $\langle x,y \rangle=\sum\limits_{j=1}^n x_j\cdot y_j$ in 
	$\real$ bzw. $\langle x,y \rangle=\sum\limits_{j=1}^n \overline{x_j}
	\cdot y_j$ in $\comp$. \\
	
	
	\underline{\person{Cauchy}-\person{Schwarz}-Ungleichung:} $|\langle x,y \rangle| \le
	|x|\cdot |y|$. \\

	
	lineare Abbildung: $A:K^n \to K^m$, Darstellung mittels $m\times n$-Matrix 
	bezüglich Standardbasen in $K^n$ und $K^m$. Beachte: $A$ steht für die 
	lineare Abbildung und die Matrix, die die lineare Abbildung beschreibt. 
	Lineare Abbildungen sind stets stetig (unabhängig von der Norm). Hinweis: 
	$x=(x_1,...,x_n)$ in der Regel als Zeilenvektor geschrieben, aber bei 
	Matrixmultiplikation ist $x$ Spaltenvektor und $x^t$ Zeilenvektor, d.h. \\
	$x^t\cdot y=\langle x,y \rangle$, falls $m=n$ \\
	$x\cdot y^t=x\otimes y$, sogenanntes Tensor-Produkt \\
	
	
	$L(K^n,K^m)=\{A: K^n \to K^m \mid A \text{ linear}\}$ Menge aller 
	linearen Abbildungen mit $||A||=\sup\{|Ax| \mid |x|\le 1\} \to$ Norm 
	hängt im Allgemeinen von Normen auf $K^n$ und $K^m$ ab. \\
	$L(K^n,K^m)$ ist isomorph zu $Mat_{m\times n}(K)$ ist isomorph zu $K^{mn}$ 
	jeweils als VR $\Rightarrow$ $L(K^n,K^m)$ ist ein $m\cot n$-dimensionaler 
	VR $\Rightarrow$ alle Normen sind äquivalent $\Rightarrow$ Konvergenz von 
	$\{A_n\}$ in $L(K^n,K^m)$ unabhängig von Norm, nehme in der Regel statt 
	$||A||$ die euklidische Norm $|A|=\sqrt{\sum\limits_{k=1}^n \sum\limits_
	{l=1}^n |a_{kl}|^2} \Rightarrow$ es gilt: $|Ax|\le ||A||\cdot |x|$ und 
	$|Ax|\le |A|\cdot |x|$. \\
	
	
	Abbildung $f:K^n\to K^m$ heißt affin linear falls $f(x)=Ax+a$ für eine 
	lineare Abbildung $A:K^n\to K^m$. \\
	
	\underline{\person{Landau}-Symbole}: Sei $f:D\subset K^n \to K^m$, $g:D\subset K^n\to K$, 
	$x_0\in \overline{D}$
	\begin{compactitem}
		\item $f(x)=o(g(x))$ für $x\to x_0$ genau dann, wenn $\lim\limits_{\substack{x\to x_0 \\ x\neq x_0}} \frac{|f(x)|}{g(x)}=0$
		\item $f(x)=O(g(x))$ für $x\to x_0$ genau dann, wenn $\exists\delta>0$, $0\le c<\infty$ mit 
		$\frac{|f(x)|}{|g(x)|}\le c \quad \forall x\in (B_{\delta}(x_0)\backslash \{x_0\})\cap D$
	\end{compactitem}
	\end{ueberblick}

	%TODO was soll der wichtige Spezialfall im Skript? Ist der wichtig?

	\begin{beispiel}[$f: D\subset K^n \to K^m$]
		$x_0\in D$, $x_0$ Häufungspunkt von $D$. Dann: $f$ stetig in $x_0 \iff \lim\limits_{x\to x_0} f(x)
		=f(x_0)\iff \lim\limits_{x\to x_0} \frac{|f(x)-f(x_0)|}{1}=0 \iff f(x)=f(x_0)+o(1)$ für $x\to x_0$ \\
		Interpretation: Setze $r(x)=f(x)-f(x_0)\Rightarrow r(x)=o(1)$ für $x\to x_0\Rightarrow r(x)\to 0$, 
		d.h. $o(1)$ ersetzt die Restfunktion $f(x)-f(x_0)$. Wegen $o(1)=o(|x-x_0|^0)$ sagt man auch, 
		dass $f(x)=f(x_0)+o(1)$ die Approximation 0-ter Ordnung der Funktion $f$ in der Nähe von $x_0$.
	\end{beispiel}

	\begin{beispiel}[$f:D\subset \real^n \to \real$]
		$x_0\in D$, $D$ offen, das bedeutet: $f(x)=f(x_0)+o(|x-x_0|)$, $x\to x_0 \quad (*)$
		\begin{compactitem}
			\item betrachte $f$ auf Strahl $x=x_0+ty$, $y\in \real^n$ fest, $|y|=1$, $t\in \real$ \\
			$(*)\Rightarrow 0=\lim\limits_{\substack{x\to x_0 \\ x\neq x_0}} \frac{|f(x)-f(x_0)|}{|x-x_0|}=
			\lim\limits_{\substack{t\to 0 \\ t\neq 0}} \frac{|f(x_0+ty)-f(x_0)|}{|t|} \Rightarrow \frac
			{|\Delta f|}{|t|}=|\text{Anstieg der Sekante}|\to 0$
			\item $(*)\Rightarrow f(x)=f(x_0)+\underbrace{\frac{o(|x-x_0|)}{|x-x_0|}}_{o(1)}|x-x_0|
			\Rightarrow f(x)=f(x_0)+o(1)|x-x_0| \Rightarrow f(x)=f(x_0)+r(x)|x-x_0|\Rightarrow 
			|f(x)-f(x_0)| \le \varrho(t)|x-x_0|$ falls $|x-x_0|\le t$ mit $\varrho(t)=\sup\limits_{|x-x_0|\le t} 
			|r(x)|\to 0$ \\
			Graph von $f$ liegt nahe $x_0$ in "'immer flacheren kegelförmigen Mengen"' $\Rightarrow$ 
			Graph "'schmiegt sich"' an horizontale Ebene durch Punkt $(x_0,f(x_0))$
			\item $(*)$ erfüllt offenbar nicht die Beobachtung: horizontale Ebene ist Graph einer affin 
			linearen Funktion $\tilde A: \real^n \to \real$
		\end{compactitem}
	\end{beispiel}

	\textbf{zentrale Frage:} Gibt es zur Funktion $f:D\subset K^n \to K^m$, $x_0\in D$, eine affin 
	lineare Funktion $\tilde A:K^n\to K^m$, so dass sich in der Nähe von $x_0$ der Graph von $f$ 
	an den Graph von $\tilde A$ "'anschmiegt"'? \\
	\textbf{Antwort:} Ja, wegen $f(x_0)=\tilde A|x_0|$ folgt $\tilde Ax=A(x-x_0)+f(x_0)$
	
	\begin{definition}[Anschmiegen]
		$f(x_0)-(f(x_0)+A(x-x_0))=o(|x-x_0|)$ \\
		d.h. die Abweichung wird schneller kleiner als $|x-x_0|$! \\
	\end{definition}

	\smiley{} Vielleicht hatten Sie bisher eine andere Vorstellung von "'anschmiegen"', aber wir machen hier Mathematik! \smiley{}

\section{Ableitung}
	Sei $f:D\subset K^n \to K^m$, $D$ offen.
	
	\begin{definition}[differenzierbar im Punkt]
		$f$ heißt differenzierbar im Punkt $x_0\in D$ falls es eine lineare Abbildung $A\in L(K^n,K^m)$ gibt,
		mit der Eigenschaft $f(x)=f(x_0)+A(x-x_0)+o(|x-x_0|)$ , $x\to x_0$.
	\end{definition}

	\begin{definition}[Ableitung]
		$A$ heißt Ableitung von $f$ an der Stelle $x=x_0$ und wird mit $f'(x_0)=A$ bzw. $Df(x_0)$ 
		bezeichnet. Man kann auch totales Differential, Fréchet-Ableitung, Jacobimatrix oder 
		Funktionalmatrix sagen. \\
		Andere Bezeichnungen sind: $\frac{\partial f}{\partial x}(x_0)$, $\frac{\partial f(x)}{\partial x}\vert_
		{x=x_0}$, d$f(x_0)$,... \\
		Somit gilt: $f(x)=f(x_0)+f'(x_0)(x-x_0)+o(|x-x_0|)$, $x\to x_0$
	\end{definition}

	\begin{bemerkung}
		$f'(x_0)$ ist im Allgemeinen eine von $x_0$ abhängige Matrix! \\
		$\Rightarrow$ lineare Funktion $\tilde A(x)=f(x_0)+f'(x_0)(x-x_0)$ appromximiert Funktion $f$ 
		in der Nähe von $x_0$ und heißt Linearisierung von $f$ in $x_0$.
	\end{bemerkung}

	\begin{satz}\label{satz:diffbar_abb}
		Sei $f:D\subset K^n \to K^m$, $D$ offen. $f$ ist differenzierbar in $x_0\in D$ mit Abbildung $f'(x_0)\in L(K^n,K^m)$ genau dann, wenn die folgenden Bedingungen erfüllt sind:
		\begin{compactitem}
			\item für ein $r:D\to K^m$ mit $\lim\limits_{\substack{x\to x_0 \\ x\neq x_0}} 
			\frac{r(x)}{|x-x_0|}=0$ \\
			$f(x)=f(x_0)+f'(x_0)(x-x_0)+r(x)\quad\forall x\in D$
			\item für ein $R:D\to L(K^n,K^m)$ mit $\lim\limits_{x\to x_0} R(x)=0$ \\
			$f(x)=f(x_0)+f'(x_0)(x-x_0)+R(x)(x-x_0)\quad\forall x\in D$
			\item für ein $Q:D\to L(K^n,K^m)$ mit $\lim\limits_{x\to x_0} Q(x)=f'(x_0)$ \\
			$f(x)=f(x_0)+Q(x)(x-x_0)\quad\forall x\in D$
		\end{compactitem}
	\end{satz}
	\begin{beweis}
		\begin{compactitem}
			\item offenbar ist $r(x)=o(|x-x_0|)$, $x\to x_0$, folglich ist dies äquivalent zu: $f$ 
			differenzierbar in $x_0$ mit Abbildung $f'(x_0)$
			\item $1\Rightarrow 2$: Sei $R:D\to K^{m\times n}$ gegeben durch $R(x_0)=0$, $R(x)=
			\frac{r(x)}{|x-x_0|^2}\cdot (x-x_0)^t$, $x\neq x_0 \Rightarrow R(x)(x-x_0)=\frac{r(x)}
			{|x-x_0|^2}\langle x-x_0,x-x_0\rangle=r(x)$ \\
			wegen $0=r(x_0)=R(x_0)(x-x_0)$ folgt $r(x)=R(x)(x-x_0)\quad\forall x\in D\Rightarrow 2$ \\
			wegen $|r(x)(x-x_0)^t|=|r(x)||x-x_0|$ folgt $\lim\limits_{x\to x_0} |R(x)|=\lim\limits_
			{\substack{x\to x_0 \\ x\neq x_0}} \frac{|r(x)\cdot (x-x_0)^t|}{|x-x_0|^2}=\lim\limits_
			{\substack{x\to x_0 \\ x\neq x_0}} \frac{|r(x)||x-x_0|}{|x-x_0|^2}=0\Rightarrow 2$
			\item $2\Rightarrow 3$: setze $Q(x)=f'(x_0)+R(x)\quad\forall x\in D\Rightarrow 3$ \\
			wegen $\lim\limits_{x\to x_0} Q(x)=f'(x_0)$ folgt 3
			\item $3\Rightarrow 1$: setze $r(x)=(Q(x)-f'(x))(x-x_0)$ wegen $|r(x)|\le |Q(x)-f'(x)||x-x_0|$ 
			folgt $\lim\limits_{\substack{x\to x_0 \\ x\neq x_0}} \frac{|r(x)|}{|x-x_0|}=\lim\limits_{x\to x_0} 
			|Q(x)-f'(x_0)|=0\Rightarrow$ Definition Ableitung
		\end{compactitem}
	\end{beweis}

	\begin{satz}\label{satz:eindeutig_x}
		Sei $f:D\subset K^n \to K^m$, $D$ offen, $f$ differenzierbar in $x_0\in D$. Dann:
		\begin{compactitem}
			\item $f$ ist stetig in $x_0$.
			\item Ableitung $f'(x_0)$ ist eindeutig bestimmt.
		\end{compactitem}
	\end{satz}
	\begin{beweis}
		\begin{compactitem}
			\item $\lim\limits_{x\to x_0} f(x)=\lim\limits_{x\to x_0} (f(x_0)+f'(x_0)(x-x_0)+R(x)(x-x_0))=f(x_0)
			\Rightarrow$ Behauptung
			\item angenommen $A_1,A_2\in L(K^n,K^m)$ sind Ableitungen von $f$ in $x_0$. Seien $R_1,R_2$ 
			zugehörige Terme. Dann gilt für $x=x_0+ty$: $|(A_1-A_2)(ty)|=|R_1(x_0+ty)(ty)|+|R_2(x_0+ty)
			(ty)| \le |R_1(x+ty)||ty|+|R_2(x_0+ty)||ty|\Rightarrow 0\le |(A_1-A_2)(y)|\le (|R_1(x_0+ty)|+|R_2
			(x_0+ty)|)|y|\to 0\Rightarrow (A_1-A_2)(y)=0\Rightarrow A_1=A_2\Rightarrow$ Behauptung
		\end{compactitem}
	\end{beweis}

\subsection{Spezialfälle für $K=\real$:}
	\begin{compactitem}
		\item $m=1$, $f:D\subset \real^n\to \real$ \\
		$f'(x_0)\in \real^{1\times n}$ ist Zeilenvektor, $f'(x_0)$ betrachtet als Vektor in $\real^n$ heißt auch 
		Gradient. Offenbar $f'(x_0)y=\langle f'(x_0),y\rangle \quad\forall y\in \real^n\Rightarrow f(x)=
		f(x_0)+\langle f'(x_0),x-x_0 \rangle + o(|x-x_0|)$
		\item $n=1$, $f:D\subset \real\to \real^m$, z.B. $D=(a,b)$ \\
		$f$ bzw. Bild $D(f)$ ist Kurve in $\real^m$, $f'(x_0)$ ist Spaltenvektor im $\real^m$. Man kann 
		schreiben: $f(x_0+t)=f(x_0)+tf'(x_0)+o(|t|)$ \\
		$\iff \underbrace{\frac{f(x_0+t)-f(x_0)}{t}}_{\text{heißt Differenzenquotient von
		 }f\text{ in }x_0}=f'(x_0)+o(1)$, $t\to 0\quad \frac{o(t)}{t}=o(1)$ \\
	 	$\iff \underbrace{\lim\limits_{t\to 0}\frac{f(x_0+t)-f(x_0)}{t}}_{\text{heißt Differentialquotient von
	 		}f\text{ in }x_0}=f'(x_0)$ \\
 		\textbf{Bemerkungen:} $f$ differentierbar $\iff$ Diffentialquotient existiert in $x_0$, aber nicht 
 		erklärt für den Fall $n>1$! \\
 		\textbf{Interpretation für $m>1$:} \begin{compactitem}
 			\item Tangente an Kurve: Bild von $\tilde A(\real)$ ist Gerade und heißt Tangente an Kurve 
 			$f(x_0)$
 			\item Tangentenvektor an Kurve in $f(x_0)$ ist $f'(x)$ \\
 			Falls $f$ nicht differenzierbar in $x_0$ bzw. $x_0$ Randpunkt von $D$ und $f(x_0)$ 
 			definiert, betrachtet man einseitige Grenzwerte.
 			\item rechtsseitige Ableitung: $\lim\limits_{t\downarrow 0}\frac{f(x_0+t)-f(x_0)}{t}=f'_r(x_0)$ 
 			heißt rechtsseitige Ableitung von $f$ in $x_0$ (falls existent), analog linksseitige Ableitung
 		\end{compactitem}
 		\item $n=m=1$, $f:D\subset \real\to \real$ \\
 		$f'(x_0)\in \real$ ist Zahl und es gilt: \begin{compactitem}
 			\item Graph von $f$ ist Kurve in $\real^2$
 			\item Graph von $\tilde{A}$ ist Tangente an Graph von $f$ in $(x_0,f(x_0))$ und hat Anstieg 
 			$f'(x_0)$
 		\end{compactitem}
	\end{compactitem}

	\begin{folgerung}
		Sei $f:D\subset K\to K^m$, $D$ offen. Dann: \\
		$f$ ist differenzierbar in $x_0\in D$ mit Ableitung $f'(x_0)\in L(K,K^m)\iff \exists f'(x_0)\in 
		L(K,K^m):\lim\limits_{y\to 0} \frac{f(x_0+t)-f(x_0)}{y}=f'(x_0)$.
	\end{folgerung}

\subsection{einfache Beispiele für Ableitungen}
	\begin{beispiel}[$f:K^n\to K^m$ affin linear]
		Für beliebige $x_0\in K^n$ gilt: $f(x)=Ax_0+a+A(x-x_0)=f(x_0)+A(x-x_0)+0\Rightarrow f$ ist 
		differenzierbar in $x_0$ mit $f'(x_0)=A$
	\end{beispiel}

	\begin{beispiel}[$f:\real^n\to \real$ mit $f(x)=|x|^2$]
		$|x-x_0|^2=\langle x-x_0,x-x_0\rangle=|x|^2-2\langle x_0,x\rangle+2\langle x_0,x_0\rangle-|x_0|^2=
		|x|^2-2\langle x_0,x-x_0\rangle-|x_0|^2\Rightarrow f(x)=f(x_0)+2\langle x_0,x-x_0\rangle+
		\underbrace{|x-x_0|^2}_{o(|x-x_0|)}$ \\
		wegen $2x_0\in L(\real^n,\real)$ folgt $f=|\cdot |^2$ ist differenzierbar in $x_0$ mit $f'(x_0)=2x_0
		\quad\forall x_0\in \real^n$
	\end{beispiel}

	\begin{beispiel}[$f:K\to K$ mit $f(x)=x^k$]
		\begin{compactitem}
			\item $k=0$: $f(x)=1\Rightarrow f'(x)=0$
			\item $k=1$: $f(x_0+y)=(x_0+y)^k=\sum\limits_{j=0}^{k} \binom{k}{j} x_0^{k-j}y^j=x_0^k+
			kx_0^{k-1}y+o(y)=f(x_0)+k\cdot f(x_0)y+o(y)$, $y\to 0\Rightarrow f'(x_0)=kx_0^{k-1} 
			\quad\forall x_0\in K$
		\end{compactitem}
	\end{beispiel}

	\begin{beispiel}[$f:\real^n\to\real$ mit $f(x)=|x|$]
		$f$ ist nicht differenzierbar in $x_0=0$, denn, angenommen Ableitung $f'(0)\in \real^n$ existiert, 
		fixiere $x\in \real^n$ mit $|x|=1\Rightarrow |tx|=0+\langle f'(0),tx\rangle+o(t)$, $t\to 0\Rightarrow
		\frac{|t|}{t}=\langle f'(x),x \rangle + \frac{o(t)}{t}=\pm 1 \Rightarrow$ Widerspruch \\
		anschaulich: es gibt keine Tangentialebene an Graph von $f$ in $(0,|0|)\in \real^{n+1}$ \\
		folglich: $f$ ist stetig in $x_0\not\Rightarrow f$ ist differenzierbar in $x_0$.
	\end{beispiel}

	\begin{bemerkung}
		Es gibt stetige Funktionen $f:\real\to \real$ die in keinem Punkt differenzierbar sind! \\
		z.B. $\sum\limits_{k=1}^{\infty} f_n$
	\end{bemerkung}

	\begin{beispiel}[$f:K\to K$ mit $f(x)=e^x$]
		$f$ ist differenzierbar mit $f'(x_0)=e^{x_0}\quad\forall x_0\in K$. Denn es ist $\lim\limits_{y\to 0} 
		\frac{e^y-1}{y}=1$ in $\comp \Rightarrow \lim\limits_{y\to 0} \frac{e^{x_0+y}-e^{x_0}}{y}=
		\lim\limits_{y\to 0} e^{x_0}\frac{e^y-1}{y}=e^{x_0}$
	\end{beispiel}

	\begin{beispiel}[$\sin,\cos:K\to K$ für $\real$ und $\comp$]
		$\sin'(x_0)=\cos(x_0)$ und $\cos'(x_0)=-\sin(x_0)$ \\
		Denn: $\frac{\sin y}{y}=\frac{e^{iy}-e^{-iy}}{2iy}=\frac{1}{2}\left( \frac{e^{iy}-1}{iy}+
		\frac{e^{iy}-1}{-iy}\right) \to 1$ \\
		$\Rightarrow \lim\limits_{y\to 0} \frac{\sin(x_0+y)-\sin(x_0)}{y}=\lim\limits_{y\to 0} \left(
		 \frac{1}{y}2\sin(\frac{y}{2})\cos(x_0+\frac{y}{2}) \right) =\cos(x_0)$ \\
		 analog für $\cos$
	\end{beispiel}

	\textbf{Schwierigkeit:}
	\begin{compactitem}
		\item Spezialfälle 1 und 2 sind häufig ungeeignet zur Bestimmung von $f'(x_0)$
		\item Spezialfall 3 ist nützlich bei $m=n=1 \Rightarrow$ Zurückführung auf diese einfachen Fälle 
		durch Rechenregeln und Reduktion
	\end{compactitem}

	\begin{satz}[Rechenregeln]
		Sei $D\subset K^n$ offen, $f,g:D\to K^m$, $\lambda:D\to K$ differenzierbar in $x_0\in D
		\Rightarrow (f\pm g):D\to K^m$ und $(\lambda\cdot f):D\to K^m$ und $(f\cdot g):D\to K^m$ sind 
		differenzierbar in $x_0$ und $\frac{1}{\lambda}:D\to K$ ist differenzierbar in $x_0$ falls 
		$\lambda(x_0)\neq 0$ mit:
		\begin{compactitem}
			\item $(f\pm g)'(x_0)=f'(x_0)\pm g'(x_0)$
			\item $(\lambda\cdot f)'(x_0)=\lambda(x_0)f'(x_0)+\lambda'(x_0)f(x_0)$
			\item $(f\cdot g)'(x_0)=f(x_0)^tg'(x_0)+f'(x_0)g(x_0)^t$
			\item $\left( \frac{1}{y}\right)'(x_0)=-\frac{1}{\lambda(x)^2}\cdot\lambda'(x_0) $
		\end{compactitem}
	\end{satz}
	\begin{beweis}
		Nach Satz 17.2 existieren $P,Q:D\to L(K^n,K^m), \Lambda:D\to L(K^n,K)$ mit \\
		$f(x)=f(x_0)+P(x)(x-x_0)$, $\lim\limits_{x\to x_0} P(x)=f'(x_0)$ \\
		$g(x)=g(x_0)+Q(x)(x-x_0)$, $\lim\limits_{x\to x_0} Q(x)=g'(x_0)$ \\
		$\lambda(x)=\lambda(x_0)+\Lambda(x)(x-x_0)$, $\lim\limits_{x\to x_0} \Lambda(x)=\lambda'(x_0)$ \\
		mit Satz 17.2 ergibt sich die Behauptung wie folgt:
		\begin{compactitem}
			\item $f(x)\pm g(x)=f(x_0)\pm g(x_0)+\underbrace{(P(x)\pm Q(x))}_{\to f'(x_0)\pm g(x_0) \in 
			L(K^n,K^m)}(x-x_0)\Rightarrow$ Behauptung
			\item $\lambda(x)\cdot f(x)=\lambda(x_0)f(x_0)+\underbrace{\left(\lambda(x_0)P(x)+
			f(x_0)\Lambda(x)+\Lambda(x)(x-x_0)P(x) \right)}_{\to \lambda(x_0)f'(x_0)+\lambda'(x_0)
			f(x_0)\in L(K^n,K^m)}(x-x_0)\Rightarrow$ Behauptung
			\item analog
			\item $\frac{1}{\lambda(x)}=\frac{1}{\lambda(x_0)}-\frac{\lambda(x)-\lambda(x_0)}
			{\lambda(x)\lambda(x_0)}=\frac{1}{\lambda(x_0)}+\underbrace{\left( -\frac{1}
			{\lambda(x_0)\lambda(x)}\cdot\Lambda(x) \right)}_{\to -\frac{1}{\lambda(x_0)^2}\lambda'(x_0)}
			(x-x_0)\Rightarrow$ Behauptung
		\end{compactitem}
	\end{beweis}

	\begin{folgerung}
		Seien $\lambda, \mu:D\to K$ differenzierbar in $x_0\in K$, $D\subset K^n$ offen, $\lambda(x_0)
		\neq 0$ \\
		$\Rightarrow \left( \frac{\mu}{\lambda} \right):D\to K$ differenzierbar in $x_0$ mit $\left( 
		\frac{\mu}{\lambda}\right)'(x_0)=\frac{\lambda(x_0)\mu'(x_0)-\lambda'(x_0)-\mu(x_0)}
		{\lambda(x_0)^2}$
	\end{folgerung}
	\begin{beweis}
		Setze in 17.12 $f=\mu$ (d.h. $m=1$) und betrachte das Produkt $\frac{1}{\lambda}\cdot \mu$.
	\end{beweis}

	\begin{beispiel}[Konstanten]
		$f:D\subset K^n\to K^m$, $c\in K$, $f$ differenzierbar in $x_0\in D$ \\
		$\Rightarrow (cf)'(x_0)=cf'(x_0)$
	\end{beispiel}

	\begin{beispiel}[Polynome]
		$f:K\to K$ Polynom $f(x)=\sum\lim\limits_{l=0}^k a_kx^l \Rightarrow f$ differenzierbar 
		$\forall x\in K$ mit $f'(x_0)=\sum\limits_{l=1}^k la_lx^{l-1}$
	\end{beispiel}

	\begin{beispiel}[rationale Funktionen]
		Sei $f=\frac{f_1}{f_2}$ rationale Funktion auf $K \Rightarrow f$ ist differenzierbar auf 
		$K\backslash${Nullstellen von $f_2$}
	\end{beispiel}

	\begin{beispiel}[$\tan$ und $\cot$]
		$\tan:K\backslash\left\lbrace \frac{\pi}{2} + k\pi \mid k\in\whole \right\rbrace\to K$ \\
		$\cot:K\backslash\left\lbrace k\pi \mid k\in\whole\right\rbrace\to K$ \\
		$\Rightarrow \tan'(x_0)=\frac{\sin'(x_0)-\cos(x_0)\sin(x_0)}{\cos^2(x_0)}=\frac{\cos^2(x_0)+
		\sin^2(x_0)}{\cos^2(x_0)}=\frac{1}{\cos^2(x_0)}$ \\
		$\Rightarrow \cot'(x_0)=-\frac{1}{\sin^2(x_0)}$
	\end{beispiel}

	\begin{satz}[Kettenregel]
		Sei $f:D\subset K^n\to K^m$, $g:\tilde{D}\subset K^n\to K^m$, $D,\tilde D$ offen. Sei $f$ 
		differenzierbar in $x_0\in D$ und $g$ differenzierbar in $f(x_0)\subset \tilde D$ \\
		$\Rightarrow g\circ f:D\to K^l$ differenzierbar in $x_0$ mit $(g\circ f)'(x_0)=g'(f(x_0))\cdot 
		f'(x_0)$. 
	\end{satz}
	\begin{beweis}
		INach Satz 17.2 existieren $P:D\to L(K^n,K^m)$ und $Q:\tilde{D}\to L(K^m,K^l)$ mit \\
		$f(x)=f(x_0)+P(x)(x-x_0)$, $\lim\limits_{x\to x_0}P(x)=f'(x_0)$ \\
		$g(x)=g(x_0)+Q(x)(x-x_0)$, $\lim\limits_{x\to x_0}Q(x)=g'(x_0)$ \\
		$(g\circ f)(x)=g(f(x))=g(f(x_0))+Q(f(x))(f(x)-f(x_0))=(g\circ f)(x_0)+\underbrace{Q(f(x))\cdot P(x)}
		_{\to g'(f(x_0))\cdot f'(x_0)}(x-x_0)\Rightarrow$ Behauptung
	\end{beweis}

	\begin{beispiel}[$f:\real\to\real$ mit $f(x)=a^x$]
		$a\in\real_{>0}, a\neq 1$ \\
		offenbar $a^x=\left( e^{\ln a} \right)^x=e^{x\ln a}\Rightarrow f(x)=g(h(x))$ mit $g(y)=e^y$ und 
		$h(x)=x\ln a$ \\
		Satz 17.18 liefert: $f'(x_0)=g'\left( e^{x_0\ln a}\right)h'(x)=e^{x_0\ln a}\cdot \ln a=a^{x_0}\ln a$
	\end{beispiel}

	\begin{beispiel}[$f:\real_{>0}\to \real$ mit $f(x)=\log_a x$]
		$a\in\real_{>0}, a\neq 1$ \\
		fixiere $x_0\in \real_{>0}$, sei $\{x_n\}$ beliebige Folge in $\real_{>0}$ mit $x_n\to x_0\Rightarrow
		y_n = \log_a x_n\to \log_a x_0 = y_0$ \\
		$\Rightarrow \lim\limits_{n\to \infty} \frac{f(x_n)-f(x_0)}{x_n-x_0}=\lim\limits_{n\to\infty} 
		\frac{\log_a x_n - \log_a x_0}{a^{\log_a x_n}-a^{\log_a x_0}}=\lim\limits_{n\to\infty}\frac{1}
		{\frac{a^{y_n}-a^{y_0}}{y_n-y_0}}=\frac{1}{a^{y_0}\ln a}$ \\
		$f'(x_0)=\frac{1}{x_0\ln a}$ \\
		\textbf{Spezialfall:} $(\ln x)'=\frac{1}{x}$
	\end{beispiel}

	\begin{beispiel}[$f:\real_{>0}\to\real$ mit $f(x)=x^r$]
		$r\in \real$ \\
		wegen $x^r=e^{r\ln x}$ liefert Kettenregel $f'(x_0)=\frac{re^{r\ln x_0}}{x_0}=\frac{rx_0^r}{x_0}=
		rx_0^{r-1}$ \\
		\textbf{Spezialfall:} $f(x)=\frac{1}{x^k}\Rightarrow f'(x)=-\frac{k}{x^{k+1}}$
	\end{beispiel}

	\begin{satz}[Reduktion]
		Sei $f=(f_1,f_2):D\subset K^n \to K^k\times K^l$, $D$ offen, $x_0\in D$. Dann: \\
		$f$ differenzierbar in $x_0\iff f_1:D\to K^k$ und $f_2:D\to K^l$ differenzierbar in $x_0$. Dann gilt:
		\begin{equation}
			f'(x_0)=\begin{pmatrix}f'_1(x_0) \\ f'_2(x_0)\end{pmatrix} 
		\end{equation}
	\end{satz}
	\smiley{} Wenn Sie das nächste mal aus der Disko kommen, zuviel getrunken haben und den Namen 
	ihrer Freundin nicht mehr kennen, sollten sie sich daran aber noch erinnern: \smiley{} \\
	\begin{beweis}
		\begin{compactitem}
			\item Hinrichtung: man hat $f(x)=f(x_0)+f'(x_0)(x-x_0)+R(x)(x-x_0)$ mit $R(x)\to 0$, da 
			$f'(x_0),R(x)\in L(K^n,K^k\times K^l) \Rightarrow f'(x_0)y=(A_1y,A_2y)$, $R(x)y=(R_1(x)y,
			R_2(x)y)$ mit $A_1,R_1\in L(K^n,K^k)$, $A_2,R_2\in L(K^n,K^l)$ \\
			$\Rightarrow f_j(x)=f_j(x_0)+A_j(x-x_0)+R_j(x-x_0)$ mit $R_j\to 0$ und $j=\{1,2\}\quad (*)$ \\
			$\Rightarrow  f_j$ ist differenzierbar in $x_0$ it $f'_j(x_0)=A_j\Rightarrow$ Behauptung
			\item Rückrichtung: es gilt $(*)$ mit $A_j=f'_j(x_0)$. Setze $A=\begin{pmatrix}f'_1(x_0) \\ f'_2(x_0)\end{pmatrix}$ und $R(x)=\begin{pmatrix}R_1(x) \\ R_2(x)\end{pmatrix} \Rightarrow
			AR(x)\in L(K^n,K^k\times K^l)$ \\
			$\Rightarrow f(x)=f(x_0)+A(x-x_0)+R(x)(x-x_0)$, $R(x)\to 0\Rightarrow f$ differenzierbar in 
			$x_0\Rightarrow$ Behauptung
		\end{compactitem}
	\end{beweis}

	\begin{folgerung}
		Sei $f=(f_1,...,f_m):D\subset K^n\to K^m$, $D$ offen, $x_0\in D$. Dann: \\
		$f$ differenzierbar in $x_0\iff f_j:D\to K$ differenzierbar in $x_0$ $\forall j=1,...,m$. Dann gilt:
		\begin{equation}
			f'(x_0)=\begin{pmatrix}f'_1(x_0) \\ \vdots \\ f'_m(x_0)\end{pmatrix}
		\end{equation}
	\end{folgerung}
	\begin{beweis}
		mehrfache Anwendung von Satz 17.22
	\end{beweis}

	\begin{bemerkung}
		Mit Folgerung 17.23 kann man Berechnungen der Ableitung stets auf Funktion $\tilde f:D\subset
		K^n\to K$ zurückführen!
	\end{bemerkung}

	\begin{beispiel}[$f:\real\to\real^2$ mit $f(t)=\begin{pmatrix}t\cos (2\pi t) \\ t\sin(2\pi t) \end{pmatrix}$]
		$f'(t)=\begin{pmatrix}\cos(2\pi t)-t(\sin(2\pi t)2\pi) \\ \sin(2\pi t)-t(\cos(2\pi t)2\pi)\end{pmatrix}$ \\
		Reduktion, Kettenregel, Produktregel, $f'(0)=(1,0)^t$, $f'(1)=(1,2\pi)^t$
	\end{beispiel}

	\begin{definition}[differenzierbar auf $D$, Ableitung, stetig differenzierbar]
		Sei $f:D\subset K^n\to K^m$, $D$ offen. Falls $f$ differenzierbar in allen $x_0\in D$, dann 
		heißt $f$ differenzierbar bzw. differenzierbar auf $D$ und die Funktion $f':D\to L(K^n,K^m)$ 
		heißt Ableitung von $f$. \\
		Ist die Funktion $f':D\to L(K^n,K^m)$ stetig auf $D$, dann heißt $f$ stetig differenzierbar auf 
		$D$ bzw. $C^1$-Funktion auf $D$.
	\end{definition}

	\begin{ueberblick}
		\begin{compactitem}
			\item $f'$ stetig in $x_0\iff \lim\limits_{x\to x_0}f'(x)=f'(x_0)$
			\item Konvergenz von Matrix $\iff$ alle Einträge konvergieren
			\item $C^1(D,K^m)=\{f:D\to K^m \mid f \text{ stetig differenzierbar auf }D\}$
		\end{compactitem}
	\end{ueberblick}

	\begin{beispiel}
		\begin{compactitem}
			\item $f(x)=x^k\Rightarrow f'(x)=kx^{k-1}\Rightarrow f\in C^1(\real,\real)$
			\item $f(x)=e^x\Rightarrow f'(x)=e^x\Rightarrow f\in C^1(\comp,\comp)$
			\item $f(x)=|x|^2\Rightarrow f'(x)=2x\Rightarrow f\in C^1(\real^n,\real)$
		\end{compactitem}
	\end{beispiel}

	\begin{beispiel}[zusammengesetze Funktion]
		$\newline$ %TODO: Funktion etwas, aber nicht zu viel nach oben schieben
		$f:\real\to\real$ mit $f(x)=\begin{cases}x^2\sin(\frac{1}{x}) & x\neq 0 \\ 0 & x=0\end{cases}$ \\
		wegen $\frac{|x^2\sin(\frac 1 x)|}{|x|}\le |x|\to 0$ folgt $f(x)=o(|x|)$, $x\to 0$ \\
		$\Rightarrow f(x)=f(0)+0\cdot (x-0)+o(|x-0|)$, $x\to 0 \Rightarrow f$ ist differenzierbar in 
		$x=0$ mit $f'(0)=0$ \\
		Rechenregeln liefern für $x\neq 0$: $f'(x)=2x\sin(\frac 1 x)-\cos x$ \\
		für $x_k=\frac{1}{k\pi}$ gilt: $\lim\limits_{k\to\infty} 2x_k\sin(\frac{1}{x_k})=0$ und 
		$\lim\limits_{x\to\infty} \cos(\frac{1}{x_k})\pm 1\Rightarrow \lim\limits_{x\to 0} f'(x)$ existiert nicht 
		$\Rightarrow f\notin C^1(\real,\real)$! \\
		\textbf{Das heißt, dass die Ableitung nicht stetig sein muss!}
	\end{beispiel}

\section{Richtungsableitung und partielle Ableitung}

Sei $f:D \subset K^n \to K^m$, $D$ offen, $x\in D$.\\
\textbf{Ziel:} Zurückführung der Berechnung der Ableitung $f^{'}(x)$ auf Berechnung der Ableitung der Funktion $\tilde{f} : \tilde{D} \subset \mathbb{K} \to \mathbb{K}$. Bisher:

\begin{compactitem}
    \item Reduktionsansatz $\Longrightarrow$ man kann sich bereits auf $m=1$ beschränken
    \item für Berechnung der Ableitung von $\tilde{f}$ ist dann neben Rechenregeln auch Differentialquotient (mit leistungsfähigen Grenzwertkalkül!) verfügbar
\end{compactitem}

\textbf{Idee:} Betrachte Funktion $f$ auf Gerade $t \to x + tz$ durch $x$ ($z$ Richtungsvektor) $\Longrightarrow$ skalares Argument $t \in \mathbb{K} \longrightarrow$ Differentialquotient\\
\textbf{Spezialfälle:} $z=e_j \Rightarrow$ partielle Ableitung
Sei $f:D \subset K^n \to K^m$, $D$ offen, $x \in D$, $z \in K^n$. Falls $a \in \LinAbb(K,K^m)\;(\sim K^m)$ existiert mit
\begin{align}
f(x+tz) = f(x) +ta + o(t), t \to 0, t \in K\\
\end{align}

dann heißt $f$ differenzierbar in $x$ in Richtung $z$ und $\Diff_z f(x):= a$ heißt \begriff{Richtungsableitung} $f$ in $x$ in Richtung $z$ andere Bezeichnungen $\partial_z f(x), \frac{\partial f(x)}{\partial_z}(x), \delta f(x;z), f^{'}(x;z), \dots$

\begin{bemerkung}
    \begin{compactitem}
        \item wegen $B_{\epsilon}(x) \subset D$ für ein $\epsilon > 0$ existiert ein $\tilde{\epsilon} > 0$ mit $x+tz \in D \forall t \in B_{\epsilon}(0) \in K$
        \item $\Diff_z f(x)$ existiert offenbar stets für $z=0$ mit $\Diff_0 f(x) = 0$
    \end{compactitem}
\end{bemerkung}

\begin{folgerung}{\label{folg:äquiv_richtungsableit}}
    Sei $f: D \subset K^n \to K^m$, $D$ offen, $x\in D$, $z \in K^n$. Dann
    \begin{align} %TODO Add numbering!
    &f \text{ ist differenzierbar in } x \text{ in Richtung } z \text{ mit } \Diff_z f(x) \in \LinAbb(K, K^m)\;(\sim K^m)\\
    &\Leftrightarrow \text{ für } \varphi(t) = f(x + tz) \text{ existiert } \varphi^{\prime}(0) \text{ und } \Diff_z f(x) = \varphi^{\prime}(0)\\
    &\Leftrightarrow \lim_{t \to 0} \frac{f(x + tz) - f(x)}{t} = a \in \LinAbb(K,K^m) \text{ existiert und } \Diff_z f(x) = a
    \end{align}
\end{folgerung}

\begin{beispiel}
    Sei $f: \mathbb{R}^2 \to \mathbb{R}, f(x_1,x_2) = x_1^2 + \vert x_2\vert$. Existiert Richtungsableitung in $x=(x_1,0)$? Sei $\phi(t) = f(x + tz) = (x_1 + tz_1)^2 + \vert tz_2\vert = \underbrace{x_1^2 + 2tx_1 z_1 +  t^2 z_1^2}_{:= \varphi_1(t)} + \underbrace{\vert t \vert \vert z \vert}_{=: \varphi_2(t)} \Rightarrow \varphi^{\prime}(0) = 2x_1z_1\;\forall x_1, z_1 \in \mathbb{R}, \varphi(\prime)(0) = 0$ existiert \textbf{nur} für $z_2 = 0$ (vgl. Bsp 5.1.4) %TODO set ref.\\
    $\Rightarrow \varphi^{\prime}(0) = 2x_1 z_1$ existiert \textbf{nur} für $x_1, z_1 \in \mathbb{R}, z_2 = 0 \overset{5.8}{\Rightarrow}$ Richtungsableitung von $f$ existiert für alle $x=(x_1,0)$ \textbf{nur} in Richtung $z=(z_1,0)$ mit $\Diff_z f(x) = 2x_1 z_1$
\end{beispiel}

\textbf{Frage:} Existiert $\Diff_z f(x)\; \forall z$ falls $f$ differenzierbar in $x$?

\begin{satz}\label{satz:Richtungsableitung_linear}
    Sei $f : D \subset K^m \to K^m$, $D$ offen, $f$ differenzierbar in $x \in D \Rightarrow$ Richtungsableitung $\Diff_z f(x)$ existiert $\forall z \in K^n$ und 
    \begin{align}
    \Diff_z f(x) = f^{\prime}(x)\cdot z
    \end{align}
\end{satz}

\begin{proof}
    $f$ differenzierbar in $x \Rightarrow f(y) = f(x) + f^{\prime}(x)(y-x) + o(\vert y-x\vert) \overset{y=x+tz}{\Rightarrow} f(x+tz) = f(x) t(f^{\prime}(x)z + o(t), t \to 0, y \to x \overset{5.7}{\Rightarrow}$ Behauptung.
\end{proof}

\begin{bemerkung}
	Richtungsableitung ist \textbf{linear} in $z$!
\end{bemerkung}

\begin{beispiel}
    Betrachte $f: \mathbb{R}^n \to \mathbb{R}$ mit $f(x) = \vert x \vert^2$
    \begin{compactitem}
        \item[a)] (5.8) liefert $\varphi(t) = \vert x + tz\vert^2 = \sum_{i=1}^{n} (x_i t z_i)^2 = \sum_{i=1}^{n} x_i^2 + 2t x_i z_i + t^2 z_i^2 \Rightarrow \varphi^{\prime}(t) = \sum_{i=1}^{n} 2x_i z_i + 2t z_i^2 \overset{(5.8)}{\Rightarrow} \varphi^{\prime}(0) = 2 \sum_{i=1}^{n} x_i z_i = \langle x,z \rangle = \Diff_z  f(x)\; \forall x,z \in \mathbb{R}^n$
        \item[b)] Beispiel 5.1.2 liefert $f^{\prime}(x) = 2x \forall x \in \mathbb{R}^n \overset{(5.10)}{\Rightarrow} \Diff_z f(x) = 2x \cdot z = 2 \langle x,z \rangle \forall x,z \in \mathbb{R}^n$ folglich gilt für $\vert z \vert = 1$ und $x \in \mathbb{R}^n$ fest:
        \begin{compactitem}[\textbullet]
            \item $\Diff_z f(x) \Longleftrightarrow x \perp z$
            \item $\Diff_z f(x)$ maximal $\Longleftrightarrow z = \frac{x}{\vert x \vert}$
        \end{compactitem}
    \end{compactitem}
\end{beispiel}

\subsection{Anwendung: Eigenschaft des Gradienten}

Sei $f: D \subset \mathbb{R}^n \to \mathbb{R}$, $D$ offen, $f$ differenzierbar in $x\in D$.\\

\begin{definition}
    $N_c := \{x \in D \mid f(x) = c\}$  heißt \begriff{Niveaumenge} von f.\\
    Sei $\gamma := (-\delta, \delta) \to N_c(\delta > 0)$ Kurve mit $\gamma(0) = x$ (*), $\gamma$ differenzierbar in $0$.\\
    Ein $z \in \mathbb{R}^n\setminus\{0\}$  mit $z = \gamma^{\prime}$ für eine Kurve $\gamma$ gemäß (*) heißt \begriff{Tangentialvektor} an $N_c$ in $x_0$.
\end{definition}

Offenbar $\varphi(t) := f(\gamma(t)) = c \forall t \in (-\delta, \delta)\\ \overset{Kettenregel}{\Longrightarrow} \varphi^{\prime}(0) = f^{\prime}(\gamma(0))\cdot \gamma^{\prime}(0) = 0 \overset{Satz \ref{satz:Richtungsableitung_linear}}{\Longrightarrow} \Diff_{\gamma^{\prime}(0)}f(x) = \langle f^{\prime}(x),\gamma^{\prime}(0)\rangle =0$ (**)

\begin{satz}[Eigenschaften Gradienten]\label{satz:egs_grad}
    Sei $f: D \subset \mathbb{R}^n \to \mathbb{R}$, $D$ offen, $f$ differenzierbar in $x \in D$. Dann
    \begin{compactitem}
        \item[1)] Gradient $f^{\prime}(x)$ steht senkrecht auf Niveaumenge $N_{f(x)}$, d.h. $\langle f^{\prime}(x), z\rangle = 0 \quad\forall$ Tangentialebenen $z$ an $N_{f(x)}$ in $x$.
        \item[2)] Richtungsableitung $\Diff_z f(x) = 0 \forall$ Tangentialebenen $z$ an $N_{f(x)}$ in $x$.
        \item[3)] Gradient $f^{\prime}(x)$ zeigt in Richtung des ``steilsten Anstiegs'' von $f$ in $x$, d.h. falls $f^{\prime}(x) \neq 0$ gilt für die Richtung $\bar{z} = \frac{f(x)}{\vert f(x) \vert} \Diff_z f(x) = \max\{\Diff_z f(x) \in \mathbb{R} \mid z \in \mathbb{R}^n \text{ und } \vert z \vert = 1\} = \vert f^{\prime}(x)\vert.$
    \end{compactitem}
\end{satz}

\begin{proof}
    1), 2) folgen direkt aus (**) und 5.10\\
    zu 3) für $\vert z \vert = 1$ gilt $\Diff_z f(x) \overset{5.10}{=} \langle f^{\prime}(x), z \rangle$ $\overset{\text{Def. } \bar{z}}{=} \vert f^{\prime}(x)\vert \langle \tilde{z}, z\rangle \overset{\text{CSU}}{\leq} \vert f^{\prime}(x)\vert \vert \tilde{z}\vert \vert z\vert = \vert f^{\prime}(x)\vert = \frac{\langle f^{\prime}(x),f^{\prime}(x)}{\vert f^{\prime}(x) \vert} = \langle f^{\prime}(x), \tilde{z}\rangle \Diff_z f(x) \Rightarrow$ Behauptung. %TODO validate proof!
\end{proof}

    \underline{Feststellung:} für $f: D \subset K^n \to K^m$:
    \begin{definition}[partiell differenzierbar und partielle Ableitung]
        lineare Abbildung $f^{\prime}(x): K^n \to K^m$ durch Kenntnis für $n$ lineare unabhängiger Vektoren bestimmt $\overset{5.10}{\Rightarrow} f^{\prime}(x)$ eindeutig bestimmt durch Kenntnis von $\Diff_{e_j}f(x) = f^{\prime}(x)\cdot e_j (\subset K^{^m\times n})$ für $j = 1,\dots,n$. Sei $f: D\subset K^n \to K^m$, $D$ offen, $x \in D$ (nicht notwendigerweise differenzierbar in $x$!).\\
        Falls Richtungsabbleitung $\Diff_{e_j}f(x)$ existiert heißt $f$ \highlight{partiell differenzierbar bzgl.} $x_j$ \highlight{im Punkt} $x$ und $D_{e_j}f(x)$ heißt \begriff{partielle Ableitung} \highlight{von} $f$ bzgl. $x_j$ in $x$.
        Andere Bezeichnungen: $\frac{\partial}{\partial x_j}f(x),\frac{\partial f}{\partial x_j}(x), \Diff_j f(x),f_{x_j}(x),\dots$
    \end{definition}

    Wegen $f(x+te_j) = f(x_1,\dots,x_{j-1},x_j+t,x_{j+1},\dots,x_n)$ liefert Folgerung \ref{folg:äquiv_richtungsableit}:
    
    \begin{folgerung}
        Sei $f: D\subset K^n \to K^m$, $D$ offen. Dann 
        \begin{align}
        &f \text{ partiell differenzierbar bzgl. } x_j \text{ in } x \text{ mit Ableitung } \frac{\partial}{\partial x_j}f(x) \nonumber\\ 
        &\Longleftrightarrow \lim_{t\to 0} \frac{f(x_1,\dots,x_{j-1},x_j+t),\dots,x_n)-f(x_1,\dots,x_{j}+t,\dots,x_n)}{t}\label{eq:equiv_richtungsabl}\\ 
        &a \in K^{m\times n} \text{ existiert und } \frac{\partial}{\partial x_j}f(x) = a.
        \end{align} 
    \end{folgerung}
    \begin{beispiel}\label{beis:beispiel_1}
        $f: \mathbb{R}^3 \to \mathbb{R}, f(x_1,x_2,x_3) = x_1^{^2}\sin x_2^2 + e^{x_3-x_1}$
        \begin{compactitem}
            \item $\frac{\partial}{\partial x_1}f(x) = 2x_1 \sin x_2 - e^{x_3 -x_1}$
            \item $\frac{\partial}{\partial x_2}f(x) = x_1^2 \cos x_2$
            \item $\frac{\partial}{\partial x_3}f(x) = e^{x_3 -x_1}$
        \end{compactitem}
    \end{beispiel}
    \begin{folgerung}\label{folg:diffbar_x}
        Sei $f: D \subset K^n \to K^m$, $D$ offen, $f$ differenzierbar in $x \in D$.
        \begin{align}
            \Rightarrow D: zf(x) = \sum_{j=1}^{n} z_j \frac{\partial}{\partial x_j}f(x)\quad \forall z \in (z_1,\dots, z_n) \in \mathbb{R}^n \label{eq:diffbar_x}
        \end{align}
    \end{folgerung}
    \begin{proof}
        Folgerung \ref{satz:Richtungsableitung_linear} liefert: $\Diff_z f(x) = f^{\prime}(x) = \sum_{j=1}^{n}z_je_j = \sum_{j=1}^{n}z_j(f^{\prime}(x)\cdot e_j) = \sum_{j=1}^{n} z_j \frac{\partial}{\partial x_j}f(x).$
    \end{proof}
    \begin{beispiel}%TODO fix equationref!
        $f: \mathbb{R}^n \to \mathbb{R}, f(x) = \vert x \vert^2 = \sum_{j=1}^{n}x_j^2, f$ differenzierbar nach Beispiel \ref{beis:beispiel_1} $\frac{\partial f(x)}{\partial x_j}= 2x_j, j = 1, \dots,n \overset{\text{\eqref{eq:diffbar_x}}}{\Longrightarrow} \Diff_z f(x) = \sum_{j=!}^{n}2 x_j \cdot z_j = 2 \langle x,z \rangle \; \forall x,z \in \mathbb{R}^n$ (vgl. Beispiel \ref{beis:beispiel_1})
    \end{beispiel}
    \begin{theorem}[vollständige Reduktion]\label{theo:voll_redukt}
        Sei $f = (f_1,\dots,f_m): D \subset K^n \to K^m$, $D$ offen, $f$ differenzierbar in $x \in D$. Dann
        \begin{align}%TODO check indices!!!
            f^{\prime}(x) \overset{\text{(a)}}{=} 
            \begin{pmatrix}
                f_1^{\prime}(x) \\ \vdots \\ f_m^{\prime}(x)
            \end{pmatrix}
            \overset{\text{(b)}}{=}
            (\sfrac{\partial}{\partial x_1}f(x), \dots, \sfrac{\partial}{\partial x_n}f(x)) \overset{\text{(c)}}{=}
            \begin{pmatrix}
                \frac{\partial}{\partial x_1}f_1(x) & \hdots & \frac{\partial}{\partial x_n}f_1(x) \\ \vdots & & \vdots \\ \frac{\partial}{\partial x_1}f_m(x) & \hdots & \frac{\partial}{\partial x_n}f_m(x)
            \end{pmatrix} \in K^{m\times n}
        \end{align}
        (Jacobimatrix)
    \text{Bemerkung:} Falls $f$ differenzierbar in $x$, dann reduziert Theorem \ref{theo:voll_redukt} die Berechung von $f^{\prime}(x)$ auf Ableitung von skalaren Funktionen $\tilde{f}: D\subset K \to K$!
    \end{theorem}
    \begin{proof}
        \begin{compactitem}
            \item[a)] Folgerung 5.1.8
            \item[b)] benutze $f^{\prime}(x)\cdot z = \Diff_z f(x)$ und Folgerung \ref{folg:diffbar_x}
            \item[c)] entweder $\frac{\partial}{\partial x_j}f(x) 
            \begin{pmatrix}
            \sfrac{\partial}{\partial x_j}f_1(x) \\ \hdots \\ \sfrac{\partial}{\partial x_j}f_n(x)
            \end{pmatrix}^T$ analog zu a) oder $f^{\prime}(x) = (\sfrac{\partial}{\partial x_1}f_j(x)) \dots \sfrac{\partial}{\partial x_n}f_j(x))^T$
        \end{compactitem}
    \end{proof}
    \textbf{Frage:} Gilt Umkehrung von Theorem \ref{theo:voll_redukt} und Satz \ref{satz:egs_grad}? D.h. falls alle partiellen Ableitungen $\sfrac{\partial}{\partial x_j}f_i(x)$ bzw. alle Richtungsableitungen $\Diff_zf(x)$ existieren, ist dann $f$ differenzierbar in $x$? Nein!
    \begin{beispiel}
        $f: \mathbb{R}^2 \to \mathbb{R}, f(x_1,x_2) = 
        \begin{cases}
            \frac{x_2^2}{x_1} & \text{, } x_1 \neq 0 \\
            0 & \text{, } x_1 = 0
        \end{cases}$\\
        Brechne alle Richtungsableitungen in $x=0$ mittels \ref{folg:äquiv_richtungsableit}:\\
        $\Diff_zf(0) = \lim_{t \to 0} \frac{f(0 + tz) - f(0)}{t} = \lim_{t \to 0}\frac{f(tz)}{t} \Rightarrow \Diff_z f(0) = \lim_{t\to 0} \frac{t^2 z_2^2}{t^2 z_1} = \frac{z_2^2}{z_1} \forall z \in \mathbb{R}^2, z_1 \neq 0$\\
        $\Diff_{0,z_2}f(0) = \lim_{t\to 0} \frac{0}{t} = 0 \Rightarrow \Diff_z f(0)$ existiert $\forall z \in \mathbb{R}^2$\\
        \textbf{aber:} $\lim_{n\to \infty} f\Big(\frac{1}{n^2}\frac{1}{n}\Big) = \lim_{n\to \infty} \frac{\frac{1}{n^2}}{\frac{1}{n^2}}=1 \neq 0 f(0) \Rightarrow f$ stetig in $0 \overset{\text{Satz \ref{satz:eindeutig_x}}}{\Rightarrow} f$ nicht differenzierbar in $x = 0$.
    \end{beispiel}
    \begin{folgerung}
        Sei $f: D\subset K^n \to K^m$, $D$ offen, $f$ differenzierbar in $x \in D$
            \begin{align}
                \Rightarrow \Diff_z f(x) = \sum_{j=1}^{n}z_j\frac{\partial}{\partial x_j}f(x) \quad \forall z = (z_1,\dots, z_m) \in \mathbb{R}^n
            \end{align}
    \end{folgerung}
\subsection{$\mathbb{R}$-differenzierbar und $\mathbb{C}$-differenzierbar}
    $\mathbf{A}(x_1+x_2) = \mathbf{A}(x_1) + \mathbf{A}(x_1), \mathbf{A}(\alpha x) = \alpha\mathbf{A}(x)$
    \begin{definition}[$K$-differenzierbar]
        $f: D \subset K^n \to K^m$ ist differenzierbar in $z_0 \in D$ (offen) gdw. $\exists K$-lineare Abbildung $\mathbf{A} : K^n \to K^m$ die Funktion $f$ in $z_0$ ``lokal approximieren'' (d.h. Satz \ref{satz:diffbar_abb} gilt). Man müsste genauer sagen: $f$ ist \begriff{$K$-differenzierbar} in $z_0$.
    \end{definition}
    Wegen $\mathbb{R} \subset \mathbb{C}$: jeder Vektorraum über $\mathbb{C}$ kann als Vektorraum über $\mathbb{R}$ betrachtet werden (nicht umgekehrt!) und jede $\mathbb{C}$-lineare Abbildung zwischen $\mathbb{C}$-Vektorraum kann als $\mathbb{R}$-linear betrachtet werden $\Rightarrow$ jede $\mathbb{C}$-differenzierbare Abbildung $f: D \subset \mathbb{C}^n \to \mathbb{C}^m$ ist auch $\mathbb{R}$-differenzierbar, Umkehrung gilt i.A. nicht!
    \begin{beispiel}
        Sei $f: \mathbb{C} \to \mathbb{C}$ mit $f(z) = \bar{z}$
        \begin{compactitem}
            \item[a)] $f$ ist additiv (d.h. $f(z_1 + z_2) = f(z_1) + f(z_2))$ und $f(tz) = tf(z)\forall t \in \mathbb{R} \Rightarrow f$ ist $\mathbb{R}$-linear wegen $f(z) = \bar{z} = \bar{z}_0 + \overline{z - z_0} = f(z_0) + f(z-z_0) \Rightarrow f$ $\mathbb{R}$-differenzierbar in $z_0 \forall z_0 \in \mathbb{C}$
            \item[b)] angenommen $f$ $\mathbb{C}$-differenzierbar in $z_0 \in \mathbb{C} \Rightarrow f^{\prime}(z_0) = \lim_{z\to 0}\frac{\overline{z_0 + z} - \bar{z}_0}{z} = \lim_{z\to 0} \frac{\bar{z}}{z}$ (``$=$''$\{1,-1\}$) existiert nicht! $f$ nicht $\mathbb{C}$-differenzierbar
        \end{compactitem}
    \end{beispiel}
    \textbf{Allgemein:} $f: D \subset X \to Y$, $D$ offen, $(X,Y) = (\mathbb{R}^n,\mathbb{C}^m)$ oder $(\mathbb{C}^n,\mathbb{R}^n)$ oder $(\mathbb{C}^n,\mathbb{C}^m)$ heißt $\mathbb{R}$-differenzierbar in $z_0$ falls \ref{satz:eindeutig_x} mit entsprechender $\mathbb{R}$-linearen Abbildung $\mathbf{A}: X \to Y$ gilt (beachte: falls $X,Y$ nur Vektorraum über $\mathbb{R}$, dann $\mathbb{C}$-differenzierbar nicht erklärt!)
    \textbf{Spezialfall:} $f: D \subset \mathbb{C} \to \mathbb{C}$, $D$ offen, $z_0 \in D$, vergleiche $\real$-differenzierbar und $\comp$-differenzierbar:
    \begin{compactitem}
        \item Sei $f$ $\real$-differenzierbar in $z_0$, d.h. $\exists \real$-lineare Abbildung $\mathbf{A}: \comp \to \comp$ mit
            \begin{align}
                f(z_0 + z) = f(z_0) + \mathbf{A}z + o(\vert z \vert), z \to z_0
            \end{align}
            \begin{align}
                \begin{rcases}
                    &\text{für } z = x,x \in \real\colon \mathbf{A}(1) = \lim\limits_{\substack{x\to 0 \\ x\in \real}} \frac{f(z_0 + x) - f(z_0)}{x} =: f_x(z_0)\\
                    &\text{für } z = iy,y \in \real\colon \mathbf{A}(i) = \lim\limits_{\substack{y\to 0 \\ y\in \real}} \frac{f(z_0 + x) - f(z_0)}{x} =: f_y(z_0) \label{eq:R-diffbar}
                \end{rcases}
                \text{nenne } f_x(z_0),f_y(z_0) \text{ \highlight{partielle Ableitung} von } f \text{ in } x_0
            \end{align}
            \item Sei $f$ $\comp$-differenzierbar in $z_0$, d.h. $f(z_0 +z) = f(z_0) +\underbrace{}$
    \end{compactitem}