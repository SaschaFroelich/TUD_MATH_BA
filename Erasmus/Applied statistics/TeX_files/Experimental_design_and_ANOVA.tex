Recap: statistical analysis with linear models. Selecting the right model is a key challenge. Ideally, data collection and model building go hand in hand. We can analyse \begriff{observational data} (data observed in natural setting) or \begriff{experimental data} (we control the explanatory variables). The former finds correlations, the latter can establish causal links. 

\subsection{Designing an experiment}

\begin{proposition}
	The study of experimental design originated with \person{R. A. Fischer}'s work in the UK in the 1900s.
\end{proposition}

In an experiment, we collect data in a structured way. We decide on:
\begin{itemize}
	\item what to measure - \textbf{response}
	\item what to measure the response on - \textbf{experimental unit}
	\item the independent variables whose effect we study - \textbf{factors}
	\item the combinations of factors we want to study - \textbf{treatments}
	\item how many data points to collect  - \textbf{sample size}
	\item how to assign treatments to experimental units 
\end{itemize}

\begin{example}
	Compare the range of three electric car models. Range is the response, car model is a factor with three levels. With only one factor, there are no further treatments. Experimental units are cars and we can decide how many of each model we want to test.
\end{example}

The more data we collect, the more certain we can be about trends we find. However, collecting data is often expensive. Measurement errors, environmental variation or other effects lead to \begriff{noise} in data. Noise-reducing experimental design can be used to counter this. Once we have identified factors we want to investigate, we have to think carefully about which treatment to test, to get the most out of our experiment (volume-increasing design).

\subsubsection{Noise-reducing design}

Noise-reducing designs assign treatments to experimental units in such a way that extraneous noise is reduced. The simplest approach: \begriff{completely randomised design} - treatments assigned randomly to experimental units.

\begin{example}
	Length of time to assemble a watch using three different methods A, B and C. Select 15 workers and assign them randomly to A, B or C.
	
	But: assembly times could vary substantially between workers. This could skew our findings. To avoid this, we could get 5 workers to each use A, B or C in turn (randomised block design).
\end{example}

In \begriff{randomised block design}, we compare $p$ treatments by $b$ blocks. Each block contains $p$ relatively homogeneous (or identical) experimental units. The $p$ treatments are assigned randomly to experimental units in each block (one experimental unit assigned per treatment).

These experimental designs can be captured in linear models to investigate differences in the mean response across treatments. For the watch example:
\begin{itemize}
	\item Mode for completely randomised design: $Y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + \epsilon_i$,
	\begin{align}
		x_{1i} &= \begin{cases}
		1 & \text{if worker $i$ uses method A} \\ 0 & \text{if not}
		\end{cases} \notag \\
		x_{2i} &= \begin{cases}
		1 & \text{if worker $i$ uses method B} \\ 0 & \text{if not}
		\end{cases} \notag
	\end{align}
	... selected method C as the base level.
	\item Model for randomised block design:
	\begin{align}
		Y_ i = \beta_0 + \underbrace{\beta_1x_{1i} + \beta_2x_{2i}}_{\text{treatment effects}} + \underbrace{\beta_3x_{3i} + \beta_4x_{4i} + \beta_5x_{5i} + \beta_6x_{6i}}_{\text{block effects}} + \epsilon_i \notag
	\end{align}
	... $x_{3i}$ up to $x_{6i}$ are dummy variables for which worker assembles.
\end{itemize}

We can use the usual methods to test hypothesis on our data (e.g. t-test for individual parameters, F-test, Likelihood-ratio test for nested models).

\subsubsection{Volume-increasing design}

Volume-increasing designs combine factors in experiments into treatments that are maximally informative.

\begin{example}
	An electricity company wants to measure customer satisfaction for two levels of peak time price increase, $x_1$, and two different peak period lengths, $x_2$ (2 levels). How should the levels of factors $x_1$ and $x_2$ be combined into treatments?
	\begin{itemize}
		\item Option 1: keep one factor fixed and vary the other. This is consistent with block designs. However, it misses interactions between factors.
		\item Option 2: consider all possible combinations of factor levels (\begriff{complete factorial design}). For this example, we call it a $2\times 2$ factorial design.
	\end{itemize}
\end{example}

\textbf{Warning:} if many factors are tested, complete factorial designs require a lot of treatments.

Complete factorial designs can be captured in linear models with interaction terms. For this example the model is
\begin{align}
	Y_i = \beta_0 + \underbrace{\beta_1x_{1i} + \beta_2x_{2i}}_{\text{main effects}} + \underbrace{\beta_3x_{1i}x_{2i}}_{\text{interaction}} + \epsilon_i \notag
\end{align}
... $x_{1i}$ and $x_{2i}$ are dummy variables for peak time price increase levels and peak period length levels, respectively. The number of parameters is the same as the number of treatments. This is always the case for complete factorial designs. Thus, we need replicate measurements for each treatment.

Aside: this also works for quantitative predictors.

\subsection{Selecting the sample size}

Deciding how many data points to collect is important: On the one hand, the more data we have, the more certain we can be about observed trends (e.g. standard errors for parameter estimates in lecture 6). On the other hand, collecting data is expensive, so we only want to collect what's necessary.

Power analysis allows us to determine the sample size required to detect an effect of a given size with a given degree of confidence. In general, the smaller the effect and the more confident we want to be, the more replicates we need.

\subsection{Introduction to ANOVA}

\subsubsection{One-way ANOVA}

\subsubsection{Two-way ANOVA}

\subsection{Observational data - sampling}