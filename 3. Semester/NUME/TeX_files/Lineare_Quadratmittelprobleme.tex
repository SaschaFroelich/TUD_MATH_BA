\section{Lineare Quadratmittelprobleme}

Das lineare Gleichungssystem $Ax=b$ mit $A\in\real^{m\times n}$ und $b\in\real^m$ besitzt genau dann eine Lösung, wenn $\rang(A)=\rang((A,b))$. Falls $m>n$, so heißt das Gleichungssystem \begriff[lineares Gleichungssystem!]{überbestimmt}. Im Allgemeinen gilt dann $\rang(A)\le n<\rang((A,b))$, so dass das Gleichungssystem keine Lösung besitzt. Der Fall der Nichtlösbarkeit kann auch für $m\le n$ eintreten, falls $\rang(A)<m$. Anstelle des Systems $Ax=b$ betrachtet man folgende \begriff{Ersatzaufgabe}:
\begin{align}
	\label{3.8}
	\Vert Ax-b\Vert_2\to\min
\end{align}
die als \begriff{lineares Quadraturmittelproblem} bezeichnet wird. Kurz schreibt man dafür auch $Ax\cong b$.

\begin{proposition}
	\proplbl{3_3_1}
	Seien $A\in\real^{m\times n}$ und $b\in\real^m$ gegeben. Da ist das lineare Quadraturmittelproblem \cref{3.8} lösbar.
\end{proposition}
\begin{proof}
	Die restringierte Optimierungsaufgabe 
	\begin{align}
		\label{3.9}
		f(y) = \Vert y-b\Vert_2\to\min\quad\text{mit } y\in L=\{Ax\mid x\in\real^n\}
	\end{align}
	ist offenbar genau dann lösbar, wenn \cref{3.8} eine Lösung besitzt. Wegen $f(0)=\Vert b\Vert_2$ und $0\in L$ hat
	\begin{align}
		\label{3.10}
		f(y)\to\min\quad\text{mit } y\in L, \, \Vert y-b\Vert_2\le \Vert b\Vert_2
	\end{align}
	dieselbe Lösungsmenge wie \cref{3.9}. Der zulässige Bereich $\{x\in L\mid \Vert y-b\Vert_2\le \Vert b\Vert_2\}$ dieser Optimierungsaufgabe ist nicht-leer, abgeschlossen und beschränkt. Da zudem $f:\real^m\to\real$ stetig ist, besitzt \cref{3.10} nach dem Satz von \person{Weierstrass} eine Lösung. Also sind auch \cref{3.9} und \cref{3.8} lösbar.
\end{proof}

\begin{example}
	Seien
	\begin{align}
		A = \begin{henrysmatrix}
		1 \\1
		\end{henrysmatrix}\quad\text{und}\quad b=\begin{henrysmatrix}
		2 \\0
		\end{henrysmatrix}\notag
	\end{align}
	Dann ist der lineare Teilraum $L$ gegeben durch $L=\left\lbrace \begin{henrysmatrix}1\\1\end{henrysmatrix}x\Bigg| x\in\real\right\rbrace$. Anschaulich ergibt sich, dass eine Lösung $y^*\in L$ von \cref{3.9} der Bedingung $(y^*-b)\perp L$ genügen muss. Daraus folgt
	\begin{align}
		\left(\begin{henrysmatrix}
		 y_1^* \\ y_2^*
		\end{henrysmatrix} - \begin{henrysmatrix}
		2 \\ 0
		\end{henrysmatrix}\right)^T\begin{henrysmatrix}
		1\\1
		\end{henrysmatrix} x=0\quad\text{und}\quad \begin{henrysmatrix}
		y_1^* \\ y_2^*
		\end{henrysmatrix} = \begin{henrysmatrix}
		1\\1
		\end{henrysmatrix} x\notag
	\end{align}
	für alle $x\in\real$. Einzige Lösung von \cref{3.9} ist damit $y^*=(1,1)^T$. Somit ist $x^*=1$ die einzige Lösung von \cref{3.8}.
	\begin{center}
		\begin{tikzpicture}
		\draw[->] (-3,0) -- (3,0);
		\draw[->] (0,-3) -- (0,3);
		
		\draw (-3,-3) -- (3,3);
		\node at (3.5,3.5) (L) {$L$};
		
		\draw[fill=black] (2,0) circle (0.1);
		\node at (2,-0.5) (b) {$b$};
		\draw[dashed] (1,1) -- (2,0);
		\draw[fill=black] (1,1) circle (0.05);
		\node at (1,1.5) (y) {$y^*$};
		\node at (3.2,0.5) (k) {kleinster Abstand};
		\end{tikzpicture}
	\end{center}
\end{example}

\subsection{Die \person{Gauss}'schen Normalgleichungen}

\begin{proposition}
	\proplbl{3_3_3}
	Seien $A\in\real^{m\times n}$ und $b\in\real^m$ gegeben. Dann gilt:
	\begin{enumerate}[label=(\alph*)]
		\item Jede Lösung des linearen Quadraturmittelproblems \cref{3.8} löst die \\ \begriff{\person{Gauss}'schen Normalgleichungen}
		\begin{align}
			\label{3.11}
			A^TAx = A^Tb
		\end{align}
		und umgekehrt.
		\item Falls $\rang(A)=n$ (dies impliziert $m\ge n$), so ist $A^TA$ positiv definit und \cref{3.8} besitzt genau eine Lösung, nämlich $x^*=(A^TA)^{-1}A^Tb$.
		\item Falls $\rang(A)<n$, so ist $A^TA$ positiv semidefinit und singulär und \cref{3.8} besitzt unendlich viele Lösungen.
	\end{enumerate}
\end{proposition}
\begin{proof}
	\begin{enumerate}[label=(\alph*)]
		\item Die Zielfunktion $\phi:\real^n\to\real$ der zu \cref{3.8} äquivalenten Aufgabe
		\begin{align}
			\label{3.12}
			\phi(x) = \frac{1}{2}\Vert Ax-b\Vert_2^2\to\min
		\end{align}
		lässt sich schreiben als
		\begin{align}
			\phi(x) &= \frac{1}{2}(Ax-b)^T(Ax-b) \notag \\
			&= \frac{1}{2} (x^TA^TAx - 2b^TAx+b^Tb)\notag
		\end{align}
		Die notwendige Optimalitätsbedingung für \cref{3.12} lautet $\nabla\phi(x)=0$, das heißt
		\begin{align}
			A^TAx = A^Tb\notag
		\end{align}
		Also ist jede Lösung von \cref{3.8} auch eine Lösung der \person{Gauss}'schen Normalgleichungen \cref{3.11}. Da $\phi$ eine konvexe Funktion ist (wegen $\nabla^2\phi(x)=A^TA$ positiv semidefinit), ist \cref{3.11} zugleich eine hinreichende Optimalitätsbedingung, das heißt jede Lösung von \cref{3.11} löst \cref{3.8}.
		\item Sei $\rang(A)=n$. Dann hat $A$ vollen Spaltenrang und $Ax\neq 0$ für alle $x\neq 0$. Folglich gilt $x^TA^TAx=(x^TA^T)(Ax)=\Vert Ax\Vert_2^2>0$ für alle $x\neq 0$. Also ist $A$ positiv definit und damit regulär. Somit sind die \person{Gauss}'schen Normalgleichungen \cref{3.11} eindeutig lösbar, ihre Lösung ist $x^*=(A^TA)^{-1}A^Tb$. Wegen Teil (a) ist dies auch die einzige Lösung von \cref{3.8}.
		\item Sei $\rang(A)>n$. Dann gibt es $\hat{x}\neq 0$ mit $A\hat{x}=0$. Folglich ist einerseits $A$ positiv semidefinit (denn $x^TA^TAx=\Vert Ax\Vert_2^2\ge 0$) aber andererseits $A^TA\hat{x}=0$ und $A^TA$ daher singulär. Da nach \propref{3_3_1} das lineare Quadraturmittelproblem \cref{3.8} eine Lösung besitzt, muss nach Teil (a) auch \cref{3.11} lösbar sein. Aufgrund der Singularität von $A^TA$ hat \cref{3.11} unendlich viele Lösungen.
	\end{enumerate}
\end{proof}

Sei $x^*$ eine Lösung von \cref{3.8}. Dann gilt wegen \propref{3_3_3} 
\begin{align}
	0 = A^TAx^* - A^Tb = A^T(Ax^*-b)\notag
\end{align}
Dies ist äquivalent zu folgenden Aussagen
\begin{itemize}
	\item $0=x^TA^T(Ax^*-b)$
	\item $(Ax^*-b)\perp Ax$
	\item $(Ax^*-b)\perp L$
\end{itemize}

\begin{algorithm}[Prinzip des Normalgleichungsverfahrens]
	Input: $A\in\real^{m\times n}$ mit $\rang(A)=n$, $b\in\real^m$
	\begin{lstlisting}
G = transpose(A) * A
c = transpose(A) * b
compute L ! als Cholesky-Faktor von G
solve Lz=c
solve transpose(L)x = z
	\end{lstlisting}
	Output: $x$, $L$
\end{algorithm}

\begin{remark}
	Der Aufwand beträgt etwa $mn^2$ Operationen zur Berechnung der unteren Hälfte von $G$, $\frac{n^3}{3}$ für die \person{Cholesky}-Faktorisierung sowie je $n^2$ für die Lösung der Dreieckssysteme. Offenbar ist der Aufwand für kleine $n$ günstig. Nachteilig bezüglich numerischer Fehler kann sich beim Normalgleichungsverfahren die schlechte Kondition (siehe später) der Matrix $A^TA$ auswirken. Abhilfe schaffen geeignete Nachiterationen oder andere Verfahren (\person{Householder}, SVD) zur Lösung des linearen Quadraturmittelproblems.
\end{remark}

\subsection{Orthonormalisierungsverfahren nach \person{Householder}}

Ziel ist zunächst die Beschreibung eines Verfahrens zur sogenannten $QR$-Faktorisierung einer Matrix $A\in\real^{m\times n}$, das heißt es sollen Matrizen $Q\in\real^{m\times n}$ und $R\in\real^{m\times n}$ bestimmt werden, so dass
\begin{align}
	A = QR\notag
\end{align}
gilt, wobei $Q$ eine orthogonale Matrix ($Q^{-1}=Q^T$) und $R$ eine verallgemeinerte obere Dreiecksmatrix der Form
\begin{align}
	R &= \begin{henrysmatrix}
	R_1 \\ 0
	\end{henrysmatrix} \quad\text{(falls $m\ge n$)} \notag \\
	R &= (R_1,R_2) \quad\text{(falls $m < n$)} \notag
\end{align}
mit einer oberen Dreiecksmatrix $R_1\in\real^{n\times n}$ bzw. einer oberen Dreiecksmatrix $R_1\in\real^{m\times m}$ und einer Matrix $R_2\in\real^{m\times (n-m)}$ ist. Später wird die $QR$-Zerlegung zur Lösung von Quadraturmittelproblemen (für den Fall $\rang(A)=n$) eingesetzt.

\begin{proposition}
	\proplbl{1_3_6}
	Sei $w\in\real^m$ gegeben mit $w^Tw=1$. Dann ist die \begriff{\person{Householder}-Matrix}
	\begin{align}
		H = \mathbbm{1} - 2ww^T\notag
	\end{align}
	symmetrisch und orthogonal, das heißt es gilt $H=H^T=H^{-1}$.
\end{proposition}
\begin{proof}
	Offenbar gilt $H^T=\mathbbm{1}-2ww^T=H$. Weiter erhält man
	\begin{align}
		H^TH=(\mathbbm{1}-2ww^T)(\mathbbm{1}-2ww^T) = \mathbbm{1} - 4ww^T + 4w(w^Tw)w^T = 1\notag
	\end{align}
\end{proof}

Die Wirkung einer \person{Householder}-Matrix $H$ auf einen Vektor $a\in\real^m$ (bei Multiplikation mit diesem Vektor) lässt sich wie folgt veranschaulichen. Zunächst hat man
\begin{align}
	Ha=(\mathbbm{1}-2ww^T)a = a-2ww^Ta = a-(2w^Ta)w\notag
\end{align}
Wegen $(a-w^Taw)^Tw=a^Tw-w^Ta=0$ (beachte $w^Tw=1$) liegt $a-w^Taw$ auf der Ebene $\mathcal{E}=\{y\in\real^m\mid y^Tw=0\}$ und $Ha$ liegt bezüglich dieser Ebene (als Spiegelebene) spiegelbildlich zu $a$.

\begin{proposition}
	\proplbl{1_3_7}
	Es seien $a\in\real^m$ mit $a\notin\Span(e_1)$ und 
	\begin{align}
		w = \frac{a+pe_1}{\Vert a+pe_1\Vert_2}\quad\text{mit } p\in\{\Vert a\Vert_2,\, -\Vert a\Vert_2\}\notag
	\end{align}
	gegeben. Dann gilt
	\begin{align}
		Ha = -pe\notag
	\end{align}
\end{proposition}
\begin{proof}
	Wegen $a\notin\Span(e_1)$ folgt $a+pe_1\neq 0$. Also ist $w$ wohldefiniert mit $w^Tw=1$ und man erhält
	\begin{align}
		\label{3.13}
		Ha = (\mathbbm{1}-2ww^T)a = a-(2w^Ta)w = a-2\frac{a^T(a+pe_1)}{\Vert a+pe_1\Vert}\frac{a+pe_1}{\Vert a+pe_1\Vert_2}
	\end{align}
	Da $p\in\{\Vert a\Vert_2,\, -\Vert a\Vert_2\}$, gilt
	\begin{align}
		\Vert a+pe_1\Vert_2^2 = a^Ta+2pa^Te_1+p^2 = 2a^T(a+pe_1)\notag
	\end{align}
	Deshalb liefert \cref{3.13} $Ha = a-(a+pe_1) = -pe_1$.
\end{proof}

\propref{1_3_7} wird für die schrittweise \person{Householder}-Transformation einer Matrix $A\in\real^{n\times m}$ in eine verallgemeinerte obere Dreiecksmatrix ausgenutzt. Dazu sei $A^{(1)}=A$ eine Matrix von Rang $n$. Ohne Beschränkung der Allgemeinheit gelte $m>n$. Weiter sei $A^{(k)}$ für ein $k\in\{1,...,n+1\}$ in der Form
\begin{align}
	A^{(k)} = \begin{pmatrix}
	a_{11}^{k} & \dots & a_{1k}^{(k)} & \dots & a_{1n}^{(k)} \\
	& \ddots & \vdots & & \vdots \\
	&& a_{kk}^{(k)} &  \dots & a_{kn}^{(k)} \\
	&& \vdots & & \vdots \\
	&& a_{mk}^{(k)} & \dots & a_{mn}^{(k)} 
	\end{pmatrix}\notag
\end{align}
gegeben. Der Vektor $a^k=(0,...,0a_{kk}^{(k)},...,a_{mk}^{(k)})\in\real^m$ übernimmt die Rolle von $a$. Er soll durch Multiplikation mit $H_k\in\real^{m\times m}$ auf $p_ke_k$ transformiert werden, wobei
\begin{align}
	H_k &= \mathbbm{1} - 2w_kw_k^T \notag \\
	w_k &= \frac{a^k+p_ke_k}{\Vert a^k+p_ke_k\Vert_2} \notag \\
	p_k &\in \{\Vert a^k\Vert_2,-\Vert a^k\Vert_2\} \notag
\end{align}
Zur Vermeidung von Stellenauslöschung in $a^k+p_ke_k$ wird man
\begin{align}
	p_k = \begin{cases}
	\Vert a_k\Vert_2 & \text{falls } a_{kk}^{(k)}\ge 0 \\
	-\Vert a_k\Vert_2 & \text{falls } a_{kk}^{(k)}<0
	\end{cases}\notag
\end{align}
wählen. Die Operation $A^{(k)}\mapsto H_kA^{(k)}$ lässt die ersten $k-1$ Zeilen und Spalten der Matrix $A^{(k)}$ unverändert und es gilt:
\begin{align}
	H_kA^{(k)} = A^{(k+1)}  = \begin{pmatrix}
	a_{11}^{(k)} & \dots & a_{1,k-1}^{(k)} & a_{1k}^{(k+1)} & a_{1,k+1}^{(k+1)} & \dots & a_{1n}^{(k+1)} \\
	& \ddots & \vdots  & \vdots & \vdots & & \vdots \\
	&& a_{k-1,k-1}^{(k)} & a_{k-1,k}^{(k+1)} & a_{k-1,k+1}^{(k+1)} & \dots & a_{k-1,n}^{(k+1)} \\
	&&& a_{kk}^{(k+1)} & a_{k,k+1}^{(k+1)} & \dots & a_{kn}^{(k+1)} \\
	&&&& a_{k+1,k+1}^{(k+1)} & \dots & a_{k+1,n}^{(k+1)} \\
	&&&& a_{m,k+1}^{(k+1)} & \dots & a_{mn}^{(k+1)}
	\end{pmatrix} \notag
\end{align}
speziell mit $a_{kk}^{(k+1)}=-p_k$. Dabei garantiert die Bedingung $\rang\left(A^{(k)}\right)=n$ dasselbe für den Rang von $A^{(k+1)}$. Die Hintereinanderausführung von \person{Householder-Transformationen} liefert
\begin{align}
	\label{3.14}
	R = A^{(n+1)} = H_nH_{n-1}\dots H_1A
\end{align}
Dabei ist $R$ eine verallgemeinerte obere Dreiecksmatrix. Wegen \propref{1_3_6} existiert
\begin{align}
	\label{3.15}
	Q = (H_n\dots H_1)^{-1}
\end{align}
und es gilt
\begin{align}
	Q &= H_1^{-1}\dots H_n^{-1} = H_1\dots H_n \notag \\
	Q^TQ &= (H_n^T\dots H_1^T)(H_1\dots H_n) = \mathbbm{1}\notag
\end{align}
das heißt $Q$ ist orthogonal. Wegen \cref{3.14} und \cref{3.15} folgt schließlich noch $A=QR$.

\begin{proposition}
	Sei $A\in\real^{m\times n}$ mit $m\ge n=\rang(A)$ gegeben. Dann gibt es eine orthogonale Matrix $Q\in\real^{m\times m}$ und eine verallgemeinerte Dreiecksmatrix
	\begin{align}
		R = \begin{henrysmatrix}
			R_1 \\ \mathbb{0}
		\end{henrysmatrix}\in\real^{m\times n}\notag
	\end{align}
	mit einer regulären oberen Dreiecksmatrix $R_1\in\real^{n\times n}$, so dass $A=QR$.
\end{proposition}

\begin{proposition}
	Seien $A\in\real^{m\times n}$ mit $m\ge n=\rang(A)$ und $b\in\real^m$ gegeben. Weiter seien Matrizen $Q$ und $R$ bzw. $R_1$ aus der $QR$-Zerlegung von $A$ bekannt und Vektoren $y_1\in\real^n$ und $y_2\in\real^{m-n}$ so gegeben , dass
	\begin{align}
		\begin{henrysmatrix}
			y_1 \\ y_2
		\end{henrysmatrix} = Q ^Tb\notag
	\end{align}
	gilt. Dann ist das lineare Quadraturmittelproblem \cref{3.8} äquivalent zum linearen Gleichungssystem
	\begin{align}
		R_1x=y_1\notag
	\end{align}
\end{proposition}
\begin{proof}
	Wegen $A=QR$ und $QQ^T=\mathbbm{1}$ gilt
	\begin{align}
		\Vert Ax-b\Vert_2^2 = \Vert QRx-QQ^Tb\Vert_2^2 = \Vert Q(Rx-Q^Tb)\Vert_2^2\notag
	\end{align}
	Da $\Vert Qz\Vert_2^2 = z^TQ^TQz=z^Tz=\Vert z\Vert_2^2$ für beliebige $z\in\real^m$ ist, folgt
	\begin{align}
		\Vert Ax-b\Vert_2^2 = \left\Vert \begin{henrysmatrix}
			R_1x \\ \mathbb{0}
		\end{henrysmatrix} - \begin{henrysmatrix}
			y_1 \\ y_2
		\end{henrysmatrix}\right\Vert_2^2 = \Vert R_1x-y_1\Vert_2^2 + \Vert y_2\Vert_2^2 \notag
	\end{align}
	Also nimmt $\Vert Ax-b\Vert_2^2$ sein Minimum genau dann an, wenn $x$ das lineare Gleichungssystem $R_1x=y_1$ löst.
\end{proof}

\subsection{Anwendung in der Ausgleichsrechnung}

Gegeben seien Messpunkte $(t_i,y_i)\in\real\times\real$ für $i=1,...,m$ mit $t_i\neq t_j$ für $i\neq j$. Weiter seien sogenannte \begriff{Basisfunktionen} $\phi_j:\real\to\real$ und die Funktion $f:\real\times\real^n\to\real$ durch
\begin{align}
	f(t,x) = \sum_{j=1}^{n} x_j\phi_j(t)\quad\text{für } (t,x)\in\real\times\real^n\notag
\end{align}
gegeben. Gesucht ist ein  Parametervektor $x^\ast=(x_1,...,x_n)^T$, so dass
\begin{align}
	f(t_i,x^\ast) \approx y_i\quad\text{für } i=1,...,m\notag
\end{align}
Eine Möglichkeit ein solches $x^\ast$ zu bestimmen ist die Lösung des Optimierungsproblems (Ausgleichsproblems)
\begin{align}
	\label{3.16}
	\sum_{i=1}^{m} (y_i - f(t_i,x))^2\to\min
\end{align}
Mit 
\begin{align}
	A = \begin{pmatrix}
		\phi_1(t_1) & \dots & \phi_n(t_1) \\
		\vdots && \vdots \\
		\phi_1(t_m) & \dots & \phi_n(t_m)
	\end{pmatrix} \quad\text{und}\quad b= \begin{henrysmatrix}
		y_1 \\ \vdots  \\  y_m
	\end{henrysmatrix}\notag
\end{align}
gilt $r(x)=\Vert ax-b\Vert_2^2$, man beachte $y_i-f(t_i,x)=y_i-\sum_{j=1}^n x_j\phi_j(t_i)=y_i-A_ix$, wobei $A_i$ die $i$-te Zeile von $A$ bezeichnet. Also ist \cref{3.16} ein lineares Quadraturmittelproblem.

\begin{example}[Ausgleichsgerade]
	Seien $m=3$ und $n=2$. Es seien $(t_1,y_1)=(0,1)$, $(t_2,y_2)=(3,8)$, $(t_3,y_3)=(4,10)$ und $\phi_1(t)=1$, $\phi_2(t)=t$ für $t\in\real$. Dann ist $f(t,x)=x_1+tx_2$, 
	\begin{align}
		A = \begin{pmatrix}
			1 & 0 \\ 1 & 3 \\ 1 & 4
		\end{pmatrix}\quad\text{und}\quad b = \begin{henrysmatrix}
			1 \\ 8 \\ 10
		\end{henrysmatrix} \notag
	\end{align}
	und das Ausgleichsproblem \cref{3.16} hat die Lösung $x^\ast=(1.0385..., 2.2692...)^T$.
\end{example}
