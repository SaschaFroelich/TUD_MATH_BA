\section{\person{Gauss}'scher Algorithmus für quadratische Systeme}

\subsection{Grundform des \person{Gauss}'schen Algorithmus}

\begin{example}
	\begin{align}
		\sysdelim{.}{.}\systeme{2x_1-2x_2+4x_3=10@E_{*},x_1+3x_2+6x_3=25,-x_1+2x_2+x_3=6}\notag
	\end{align}
	$E_1$ behalten $\to E_1'$, $E_2-\frac{1}{2}E_1\to E_2'$, $E_3+\frac{1}{2}E_1\to E_3'$
	\begin{align}
		\sysdelim{.}{.}\systeme{2x_1-2x_2+4x_3=10@E'_{*},4x_2+4x_3=20,x_2+3x_3=11}\notag
	\end{align}
	$E_1'$ behalten $\to E_1''$, $E_2'$ behalten $\to E_2''$, $E_3'-\frac{1}{4}E_2'\to E_3''$
	\begin{align}
		\sysdelim{.}{.}\systeme{2x_1-2x_2+4x_3=10@E''_{*},4x_2+4x_3=20,2x_3=6}\notag
	\end{align}
	$\Rightarrow x_3=3$, $x_2=2$, $x_1=1$
\end{example}

Alle drei Systeme sind äquivalent, das heißt ihre Lösungsmengen sind gleich. Das letzte System wird \begriff{Dreieckssystem} oder System in \begriff{Zeilenstufenform} oder \begriff{gestaffeltes System} genannt.

Gegeben seien $A=(a_{ij})\in\real^{n\times n}$ und $b=(b_i)\in\real^n$. Gesucht ist, falls vorhanden, eine Lösung des linearen Gleichungssystems
\begin{align}
	\begin{array}{ccccccc}
		a_{11}x_1 & + & ... & + & a_{1n}x_n & = & b_1 \\
		\vdots & && & \vdots & \vdots & \vdots \\
		a_{n1}x_1 & + & ... & + & a_{nn}x_n & = & b_n
	\end{array}\notag
\end{align}
bzw. in Matrix-Schreibweise: $Ax=b$.

\subsubsection*{Prinzipielles Vorgehen}

\begin{enumerate}[label=\textbf{\arabic*.}]
	\item Vorwärtselimination (unter Voraussetzung der Durchführbarkeit): Schrittweise Transformation der erweiterten Koeffizientenmatrix
	\begin{align}
		(A,b) = (A^{(1)},b^{(1)})\to (A^{(2)},b^{(2)})\to ...\to (A^{(n)},b^{(n)})=(U,z)\notag
	\end{align}
	wobei $U$ eine obere Dreiecksmatrix ist. Der Eliminationsschritt $(A^{(k)},b^{(k)})\to(A^{(k+1)},b^{(k+1)})$ für $k=1,...,n-1$ verwendet die Eliminationsfaktoren
	\begin{align}
		l_{ik} = \frac{a_{ik}^{(k)}}{a_{kk}^{(k)}}\notag
	\end{align}
	um die $i$-te Zeile der neuen Matrix aus der alten Matrix zu bestimmen
	\begin{align}
		\text{neue Zeile }i &= \text{alte Zeile }i &\text{für } i=1,...,k \notag \\
		\text{neue Zeile }i &= \text{alte Zeile }i - l_{ik}\cdot\text{neue Zeile }k &\text{für } i=k+1,...,n\notag
	\end{align}
	\item Rücksubstitution (unter Voraussetzung der Durchführbarkeit): Lösung des Gleichungssystems $Ux=z$ nach $x$ für gegebenes $U,z$
\end{enumerate}

\begin{algorithm}[Vorwärtselimination]
	\proplbl{3_1_2}
	Input: $n$, $A$, $b$
\begin{lstlisting}
do k= 1, n-1
 do i = k+1, n
  %$l_{ik}$% = %$a_{ik}$% / %$a_{kk}$%
  %$b_i$% = %$b_i$% - %$l_{ik}b_k$%
  do j = k+1, n 
   %$a_{ij}$% = %$a_{ij}$% - %$l_{ik}a_{kj}$%
  end do
 end do
end do
\end{lstlisting}
	Output: $(U,z)$ und $l_{ik}$ für $i>k$. $U$ steht in der oberen Hälfte von $A$ mit Hauptdiagonale, $b$ enthält $z$, die Zahlen $l_{ik}$ lassen sich in der unteren Hälfte von $A$ abspeichern.
\end{algorithm}

\begin{algorithm}[Rücksubstitution]
	\proplbl{3_1_3}
	Input: $n$, $U$, $z$
\begin{lstlisting}
do i = n, 1, -1
 s = 0
 do j = i+1, n
  s = s + %$u_{ij}x_j$%
 end do
end do
\end{lstlisting}
	Output: $x$
\end{algorithm}

Der Aufwand bei uneingeschränkter Durchführbarkeit von \propref{3_1_2} ist $\sim \frac{2}{3}n^3$ und \propref{3_1_3} ist $\sim n^2$

\subsubsection*{Durchführbarkeit}

Der \propref{3_1_2} ist genau dann durchführbar, wenn $a_{kk}^{(k)}\neq 0$ für alle $k=1,...,n-1$ gilt. Gilt auch $a_{nn}^{(n)}\neq 0$, so folgt $u_{ii}\neq 0$ für $i=1,...,n$ und damit die Durchführbarkeit von \propref{3_1_3}.

\begin{definition}[streng diagonaldominant]
	Eine Matrix $A=(a_{ij})\in\real^{n\times n}$ heißt \begriff{streng diagonaldominant}, wenn
	\begin{align}
		\vert a_{ii}\vert > \sum_{\substack{j=1\\ j\neq i}}^{n}\vert a_{ij}\vert\quad\text{für alle } i=0,...,n\notag
	\end{align}
\end{definition}

\begin{lemma}
	Ist die Matrix $A\in\real^{n\times n}$ streng diagonaldominant, so sind \propref{3_1_2} und \propref{3_1_3} durchführbar
\end{lemma}
\begin{proof}[nicht in der Vorlesung]
	Die Matrix $A^{(1)}$ sei streng diagonaldominant. Weiter seien die Matrizen $A^{(k)}$ für ein $k\in\{1,...,n-1\}$ durch Vorwärtselimination erzeugt und streng diagonaldominant. Dies zieht $\vert a_{kk}^{(k)}\vert >0$ nach sich, so dass die Erzeugung von $A^{(k+1)}$ durch Vorwärtselimination wohldefiniert ist. Es wird nun gezeigt, dass $A^{(k+1)}$ wieder streng diagonaldominant ist. Da $A^{(1)}=A$ als streng diagonaldominant vorausgesetzt wurde, folgt dann die Durchführbarkeit der gesamten Vorwärtselimination durch vollständige Induktion. Sei $i>k$ eine Zeile der Matrix $A^{(k+1)}$. Dann hat man
	\begin{align*}
		\sum_{\substack{j=1\\ j\neq i}}^n \vert a_{ij}^{(k+1)}\vert \sum_{\substack{j=k+1\\ j\neq i}}\vert a_{ij}^{(k+1)}\vert &= \sum_{\substack{j=k+1\\ j\neq i}}^n \left|a_{ij}^{(k)} - \frac{a_{kj}^{(k)} a_{ik}^{(k)}}{a_{kk}^{(k)}}\right| \\
		&\le \sum_{\substack{j=k+1\\ j\neq i}}^n \vert a_{ij}^{(k)}\vert + \left|\frac{a_{ik}^{(k)}}{a_{kk}^{(k)}}\right| \sum_{\substack{j=k+1\\ j\neq i}}^n \vert a_{kj}^{(k)}\vert \\
		&< \vert a_{ii}^{(k)}\vert - \vert a_{ik}^{(k)}\vert + \left|\frac{a_{ik}^{(k)}}{a_{kk}^{(k)}}\right| \left( \vert a_{kk}^{(k)}\vert - \vert a_{ki}^{(k)}\vert  \right) \\
		&= \vert a_{ii}^{(k)}\vert  - \left|\frac{a_{ik}^{(k)} a_{ki}^{(k)}}{a_{kk}^{(k)}}\right| \\
		&\le \left| a_{ii}^{(k)} - \frac{a_{ik}^{(k)} a_{ki}^{(k)}}{a_{kk}^{(k)}} \right| \\
		&= \vert a_{ii}^{(k+1)}\vert
	\end{align*}
	Falls $i\le k$, so ändert sich $A^{(k+1)}$ gegenüber $A^{(k)}$ bezüglich der Zeile $i$ nicht. Also ist $A^{(k+1)}$ streng diagonaldominant und man schließt auf die Durchführbarkeit der Vorwärtselimination für $k=1,...,n-1$ und insbesondere auf $\vert a_{ii}^{(n)}\vert >0$ für $i=1,...,n$. DIe Matrix $A^{(n)}$ enthält die Matrix $U$ im oberen Dreieck, deren Diagonalelemente sind gerade $a_{11}^{(n)},...,a_{nn}^{(n)}$, also ist auch die Rücksubstitution wohldefiniert.
\end{proof}

\subsection{Pivotisierung}

Die Regularität der Matrix $A\in\real^{n\times n}$ ist zwar äquivalent zur Lösbarkeit des linearen Gleichungssystems $Ax=b$, für jeden beliebigen Vektor $b\in\real^n$, jedoch sichert die Regularität nicht die Durchführbarkeit der Grundform des \person{Gauss}'schen Algorithmus. Um die Durchführbarkeit bei regulärem $A$ zu erzwingen, kann man eine \begriff[Pivotisierung!]{Spaltenpivotisierung} der Matrix durchführen. Dabei werden in jedem Durchlauf der Vorwärtselimination auf bestimmte Weise Zeilen der Matrix $(A,b)$ vertauscht:
\begin{itemize}
	\item Bestimme $p=p(k)\in\{k,...,n\}$, sodass $\vert a_{pk}^{(k)}=\max\limits_{k\le i\le n}\vert a_{ik}^{(k)}\vert$. \\
	$k$-te Spalte von $A^{(k)}$ heißt \begriff{Pivotspalte}, $a_{pk}^{(k)}$ heißt \begriff{Pivotelement}, die Regularität von $A$ sichert dann $a_{pk}^{(k)}\neq 0$
	\item Vertausche die Zeilen $p$ und $k$ in der Matrix $(A^{(k)},b^{(k)})$. \\
	\emph{praktisch:} Zeilentausch nicht ausführen, sondern einen Permutationsvektor mitführen. \\
	\emph{formal:} Beschreibung der Zeilen- und Spaltenvertauschungen durch Permutationsmatrizen. Dazu sei $\pi:\{1,...,n\}\to\{1,...,n\}$ eine Permutation und $e_i$ bezeichne den $i$-ten kanonischen Einheitsvektor. Dann heißt $P_\pi=(e_{\pi(1)},...,e_{\pi(n)})$ \begriff{Permutationsmatrix}.
\end{itemize}

\begin{proposition}
	\proplbl{3_1_6}
	Ist die Matrix $A$ regulär, so ist der \person{Gauss}'sche Algorithmus mit Spaltenpivotisierung (bei exakter Arithmetik) durchführbar.
\end{proposition}

Weitere Pivotisierungstechniken sind insbesondere die \begriff[Pivotisierung!]{Zeilenpivotisierung} (in Analogie zur Spaltenpivotisierung) und die \begriff[Pivotisierung!]{vollständige Pivotisierung}.

\subsection{LU-Faktorisierung}

Der $k$-te Schritt von \propref{3_1_2} (ohne Pivotisierung) lässt sich schreiben als 
\begin{align}
	\label{3.1}
	\begin{split}
	A^{(k+1)} &= L_kA^{(k)} \\
	b^{k+1} &= L_kb^{(k)}
	\end{split}
\end{align}
mit der \person{Gauss}'schen Eliminationsmatrix
\begin{align}
	L_k = \begin{blockarray}{cccccccc}
	 &  &  & k &  &  &  &\\
	\begin{block}{(ccccccc)c}
	1 &  &  &  &  &  &  &  \\
	 & 1 &  &  &  &  &  &  \\
	 &  & \ddots &  &  &  &  &  \\
	 &  &  & 1 &  &  &  & k\text{-te Zeile} \\
	 &  &  & -l_{k+1,k} & 1 &  &  &  \\
	 &  &  & \vdots &  & \ddots &  &  \\
	 &  &  & -l_{n,k} &  &  & 1 &  \\
	\end{block}
	\end{blockarray}\notag
\end{align}

\begin{proposition}
	Es gelten
	\begin{align}
		L_k^{-1} = 
		\begin{pmatrix}
			1 &  &  &  &  &  &  \\
			& 1 &  &  &  &  &  \\
			&  & \ddots &  &  &  &  \\
			&  &  & 1 &  &  &   \\
			&  &  & l_{k+1,k} & 1 &  &  \\
			&  &  & \vdots &  & \ddots &  \\
			&  &  & l_{n,k} &  &  & 1  \\
		\end{pmatrix} \notag \\
		L_1^{-1}\cdot ...\cdot L_{n-1}^{-1} = 
		\begin{pmatrix}
			1 & & & & \\
			l_{21} & 1 & & & \\
			l_{31} & l_{32} & 1 & & \\
			\vdots & \vdots & & \ddots & \\
			l_{n1} & l_{n2} & l_{n3} & \dots & 1 \\
		\end{pmatrix}= L \notag
	\end{align}
\end{proposition}
\begin{proof}
	\begin{enumerate}[label=(\alph*)]
		\item Zunächst erkennt man, dass $L_k=\mathbbm{1}-l_ke_k^T$, wobei $\mathbbm{1}\in\real^{n\times n}$ die Einheitsmatrix und $e_k\in\real^n$ den $k$-ten kanonischen Einheitsvektor bezeichnen. Damit erhält man
		\begin{align}
		L_k(\mathbbm{1}+l_ke_k^T) &= (\mathbbm{1}-l_ke_k^T)(\mathbbm{1}+l_ke_k^T) \notag \\
		&= \mathbbm{1} - l_ke_k^T + l_ke_k^T - l_ke_k^Tl_ke_k^T \notag \\
		&\overset{(\ast)}{=} \mathbbm{1} \notag
		\end{align}
		$(\ast)$ $l_ke_k^T=0$, da $l_k$ erst an der $k+1$-ten Stelle einen Wert hat, aber $e_k$ nur an der $k$-ten Stelle eine 1 hat
		\item Es wird durch vollständige Induktion gezeigt, dass
		\begin{align}
			\label{3.2}
			L_1^{-1}\cdot ...\cdot L_{n-1}^{-1} = \mathbbm{1} + \sum_{i=1}^{k} l_ie_i^T
		\end{align}
		für $k=1,...,n-1$ gilt. Daraus ergibt sich unmittelbar die zweite Aussage des Satzes. Für $k=1$ folgt \cref{3.2} direkt aus Teil (a). Sei nun \cref{3.2} für ein $k<n-1$ erfüllt. Dann folgt mit $e_i^Tl_{k+1}=0$ für $i<k$, dass
		\begin{align}
			L_1^{-1}\cdot ...\cdot L_{k+1}^{-1} &= \left(\mathbbm{1} + \sum_{i=1}^k l_ie_i^T\right)L_{k+1}^{-1} \notag \\
			&= \left(\mathbbm{1} + \sum_{i=1}^k l_ie_i^T \right) \left( \mathbbm{1} + l_{k+1}e_{k+1}^T\right) \notag \\
			&= \mathbbm{1} + \sum_{i=1}^k l_ie_i^T + l_{k+1}e_{k+1}^T + \sum_{i=1}^k l_ie_i^Tl_{k+1}e_{k+1}^T \notag \\
			&= \mathbbm{1} + \sum_{i=1}^{k+1} l_ie_i^T \notag 
		\end{align}
	\end{enumerate}
\end{proof}

Aus $A^{(k+1)}=L_kA^{(k)}$ nach \cref{3.1} folgt
\begin{align}
	A=A^{(1)} = L_1^{-1}A^{(2)} = ... = L_1^{-1}\cdot ...\cdot L^{-1}_{n-1} A^{(n)} = L\cdot U\notag
\end{align}
und analog $b=Lz$.

\begin{proposition}
	\proplbl{3_1_8}
	Seien $A\in\real^{n\times n}$, $b\in\real^n$ gegeben. Falls \propref{3_1_2} ohne Pivotisierung durchführbar ist, dann gilt $A=LU$ mit der oberen Dreiecksmatrix $U=A^{(n)}$ und der unteren Dreiecksmatrix $L=(l_{ik})$ mit
	\begin{align}
		l_{ik} = \begin{cases}
			0 & i<k \\ 1 & i=k \\ l_{ik} & i>k
		\end{cases}\notag
	\end{align}
\end{proposition}

\begin{algorithm}[LU-Version der Grundform des \person{Gauss}'schen Algorithmus]
	Input: $A,b$
	\begin{lstlisting}
compute L,U
solve Lz=b
solve Ux=z
	\end{lstlisting}
	Output: $x,L,U$
\end{algorithm}

Der Aufwand an Rechenoperationen bei uneingeschränkter Durchführbarkeit: $\frac{2}{3}n^3 + 2n^2$.

Ein Vorteil der LU-Version besteht darin, dass man mit einer ermittelten LU-Faktorisierung von $A$ das Gleichungssystem $Ax=b$ für mehrere rechte Seiten $b$ mit dem Aufwand von je $2n^2$ lösen kann.

\begin{proposition}
	Sei $A\in\real^{n\times n}$ regulär. Dann gibt es eine durch Zeilenvertauschungen aus $A$ hervorgegangene Matrix $\tilde{A}$, für die \propref{3_1_2} ohne Pivotisierung durchführbar ist und $\tilde{A}=\tilde{L}\tilde{U}$.
\end{proposition}
\begin{proof}
	Nach \propref{3_1_6} ist der \person{Gauss}'sche Algorithmus mit Spaltenpivotisierung durchführbar. Wendet man die dabei vorkommenden Zeilenvertauschungen vor Beginn von \propref{3_1_2} auf $A$ an, entsteht die Matrix $\tilde{A}$. Für $A=\tilde{A}$ liefert \propref{3_1_8} die Darstellung $\tilde{A}=\tilde{L}\tilde{U}$. Die Regularität von $U$ folgt aus der Regularität von $A$ mit dem Determinantenmultiplikationssatz.
\end{proof}

\subsection{\person{Gauss}'scher Algorithmus für trigonale Systeme}

Sei $A\in\real^{n\times n}$ trigonal, das heißt
\begin{align}
	\label{3.3}
	A = \begin{pmatrix}
		\alpha_1 & \beta_1 & & & & \\
		\gamma_2 & \alpha_2 & \beta_2 & & & \\
		& \gamma_3 & \alpha_3 & \beta_3 & & \\
		& & \ddots & \ddots & \ddots & \\
		& & & \gamma_{n-1} & \alpha_{n-1} & \beta_{n-1} \\
		& & & & \gamma_n & \alpha_n \\
	\end{pmatrix}
\end{align}

Die Speicherung kann mittels geeigneter Vektoren, etwa
\begin{align}
	\label{3.4}
	\alpha = (\alpha_1,...,\alpha_n)^T\quad \beta=(\beta_1,...,\beta_{n-1},0)^T\quad \gamma =(0,\gamma_2,...,\gamma_n)^T
\end{align}
erfolgen. Angenommen \propref{3_1_2} ist ohne Pivotisierung durchführbar. Dann gibt es eine LU-Faktorisierung von $A$. Aus der Trigonalität von $A$ und aus $A=LU$ ergibt sich die folgende Gestalt für $L$ und $U$
\begin{align}
	\label{3.5}
	L = \begin{pmatrix}
		1 & & & & \\
		l_2 & 1 & & & \\
		& l_3 & 1 & & \\
		& & \ddots & \ddots & \\
		& & & l_n & 1 \\
	\end{pmatrix}\quad\text{und}\quad U=\begin{pmatrix}
		d_1 & \beta_1 & & & \\
		& d_2 & \beta_2 & & \\
		& & \ddots & \ddots & \\
		& & & \ddots & \beta_{n-1} \\
		& & & & d_n \\ 
	\end{pmatrix}
\end{align}
mit $d_1=\alpha_1$ und $l_k=\frac{\gamma_k}{d_{k-1}}$, $d_k=\alpha_k-l_k\beta_k$ für $k=2,...,n$.

\begin{algorithm}[LU-Faktorisierung einer trigonalen Matrix ohne Pivotisierung]
	\proplbl{3_1_11}
	Input: $\alpha, \beta, \gamma$ entsprechend \cref{3.3} und \cref{3.4}
	\begin{lstlisting}
%$d_1$% = %$\alpha_1$%
do k = 2, n
 %$l_k$% = %$\gamma_k$% / %$d_{k-1}$%
 %$d_k$% = %$\alpha_k$% - %$l_k\beta_k$%
end do
	\end{lstlisting}
	Output: $l=(0,l_2,...,l_n)^T$, $d=(d_1,...,d_n)^T$ für \cref{3.5}
\end{algorithm}

\begin{remark}
	Der Aufwand für \propref{3_1_11} beträgt etwa $3n$ Operationen. Auch das Lösen der Dreieckssysteme $Lz=b$ und $Ux=z$ ist billig (je etwa $2n^2$). Bei Spaltenpivotisierung kommt in $U$ im Allgemeinen eine zweite Nebendiagonale hinzu. Die dargestellte Verfahrensweise lässt sich auf Systeme mit Bandmatrizen erweitern, die mehr als je eine untere bzw. obere Nebendiagonale besitzen.
\end{remark}